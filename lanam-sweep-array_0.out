wandb: Currently logged in as: xinyu-zhang. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165559-kdj5ey0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-planet-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/kdj5ey0l
wandb: \ 1 of 3 files downloaded...wandb:   3 of 3 files downloaded.  
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: üöÄ View run lemon-planet-114 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/kdj5ey0l
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165559-kdj5ey0l/logs
wandb: Agent Starting Run: tvngxn3q with config:
wandb: 	activation_cls: gelu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165638-tvngxn3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/tvngxn3q
Create sweep with ID: 2qal8f2u
Sweep URL: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='gelu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8191518  0.819103   0.81909186 0.8273471 ], sigma noise: [0.81882054 0.8188212  0.8188212  0.8188186 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7422268  0.74205506 0.74201715 0.77938896], sigma noise: [0.7411497  0.74115217 0.74115217 0.74114275]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6733554  0.6729669  0.6728833  0.76601326], sigma noise: [0.671115  0.6711204 0.6711204 0.6710981]
[Epoch=100, n_hypersteps=5]: prior precision: [0.61184925 0.6111355  0.6109853  0.7789291 ], sigma noise: [0.6080932  0.6081033  0.6081033  0.60805947]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5570461  0.5558892  0.55565053 0.80967987], sigma noise: [0.5515487  0.55156565 0.5515655  0.55148816]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50831556 0.50659335 0.50624406 0.85332644], sigma noise: [0.50103724 0.5010641  0.5010636  0.50093544]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46506312 0.4626542  0.4621724  0.9068643 ], sigma noise: [0.45621365 0.45625502 0.45625356 0.45604998]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42673388 0.42352095 0.42288572 0.9677241 ], sigma noise: [0.41684413 0.41690677 0.41690353 0.4165889 ]
[Epoch=100, n_hypersteps=10]: prior precision: [0.39281395 0.3886866  0.38787824 1.0326581 ], sigma noise: [0.3828181  0.38291207 0.3829057  0.3824284 ]
[Epoch=100, n_hypersteps=11]: prior precision: [0.36283073 0.35768792 0.35668826 1.0968868 ], sigma noise: [0.35414875 0.3542887  0.3542773  0.35356358]
[Epoch=100, n_hypersteps=12]: prior precision: [0.33635363 0.3301041  0.3288966  1.153999  ], sigma noise: [0.33093894 0.331145   0.331126   0.33007514]
[Epoch=100, n_hypersteps=13]: prior precision: [0.31299326 0.305555   0.30412513 1.1974045 ], sigma noise: [0.3132874  0.3135854  0.3135549  0.31203926]
[Epoch=100, n_hypersteps=14]: prior precision: [0.29239902 0.2836988  0.28203383 1.2228794 ], sigma noise: [0.3011494  0.30156922 0.30152306 0.2993944 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.27425525 0.26422992 0.26231903 1.229955  ], sigma noise: [0.29423586 0.2948089  0.29474288 0.29184318]
[Epoch=100, n_hypersteps=16]: prior precision: [0.2582807  0.24687596 0.24470948 1.2212157 ], sigma noise: [0.29203236 0.2927906  0.29270023 0.2888685 ]
[Epoch=100, n_hypersteps=17]: prior precision: [0.2442245  0.23139447 0.22896495 1.2007883 ], sigma noise: [0.29391128 0.29488748 0.2947684  0.28983852]
[Epoch=100, n_hypersteps=18]: prior precision: [0.23186629 0.21757102 0.21487227 1.1731918 ], sigma noise: [0.29923594 0.3004652  0.30031255 0.29410776]
[Epoch=100, n_hypersteps=19]: prior precision: [0.22101007 0.20521605 0.2022435  1.1426743 ], sigma noise: [0.3074051  0.3089258  0.30873436 0.3010624 ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.21148446 0.19416241 0.1909135  1.1128461 ], sigma noise: [0.3178479  0.31970146 0.3194653  0.31011915]
[Epoch=100, n_hypersteps=21]: prior precision: [0.20313972 0.18426308 0.18073645 1.0864525 ], sigma noise: [0.32999855 0.33222833 0.33194134 0.3207062 ]
[Epoch=100, n_hypersteps=22]: prior precision: [0.1958428  0.17538889 0.17158335 1.065232  ], sigma noise: [0.3432746  0.34592292 0.34557867 0.33224696]
[Epoch=100, n_hypersteps=23]: prior precision: [0.1894791  0.16742623 0.16334148 1.0499312 ], sigma noise: [0.35706902 0.36017287 0.3597661  0.34415787]
[Epoch=100, n_hypersteps=24]: prior precision: [0.18394782 0.16027528 0.1559112  1.0404445 ], sigma noise: [0.37076032 0.37434626 0.37387264 0.3558613 ]
[Epoch=100, n_hypersteps=25]: prior precision: [0.17916161 0.15384832 0.14920478 1.0360222 ], sigma noise: [0.38373864 0.38781765 0.38727525 0.36681065]
[Epoch=100, n_hypersteps=26]: prior precision: [0.1750443  0.14806849 0.14314543 1.0354996 ], sigma noise: [0.39544126 0.40000486 0.3993942  0.3765208 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.17152944 0.14286824 0.13766506 1.0375009 ], sigma noise: [0.4053901  0.41040868 0.4097332  0.38459703]
[Epoch=100, n_hypersteps=28]: prior precision: [0.1685594  0.13818812 0.13270387 1.0406308 ], sigma noise: [0.41322285 0.41864654 0.41791302 0.39075565]
[Epoch=100, n_hypersteps=29]: prior precision: [0.16608293 0.133976   0.12820958 1.0436605 ], sigma noise: [0.41871288 0.42447525 0.4236931  0.3948343 ]
[Epoch=200, n_hypersteps=0]: prior precision: [0.16405666 0.13018574 0.12413584 1.0456963 ], sigma noise: [0.4217755  0.42779893 0.42697862 0.3967911 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.1580161  0.12595499 0.11988326 0.9873296 ], sigma noise: [0.4223419  0.42853078 0.42766723 0.39661464]
[Epoch=200, n_hypersteps=2]: prior precision: [0.14950778 0.12142103 0.11553419 0.91329515], sigma noise: [0.4205993  0.42686155 0.42595136 0.39448074]
[Epoch=200, n_hypersteps=3]: prior precision: [0.13963433 0.11670537 0.11115872 0.8334879 ], sigma noise: [0.41683382 0.42308673 0.42212743 0.3906409 ]
[Epoch=200, n_hypersteps=4]: prior precision: [0.1291833  0.11191221 0.10681497 0.7534887 ], sigma noise: [0.41140243 0.41757718 0.41656706 0.38540024]
[Epoch=200, n_hypersteps=5]: prior precision: [0.11870711 0.10712824 0.10255039 0.6766696 ], sigma noise: [0.40470618 0.4107506  0.4096876  0.3790963 ]
[Epoch=200, n_hypersteps=6]: prior precision: [0.10857926 0.10242345 0.09840219 0.604998  ], sigma noise: [0.39716533 0.40304506 0.4019256  0.37208068]
[Epoch=200, n_hypersteps=7]: prior precision: [0.09903789 0.0978524  0.09439885 0.53949064], sigma noise: [0.38919884 0.39489704 0.39371598 0.36470276]
[Epoch=200, n_hypersteps=8]: prior precision: [0.09022001 0.09345609 0.09056045 0.48051816], sigma noise: [0.3812067  0.386723   0.38547355 0.35729632]
[Epoch=200, n_hypersteps=9]: prior precision: [0.08218911 0.08926364 0.08690168 0.4280245 ], sigma noise: [0.37355578 0.3789046  0.37757725 0.3501679 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.07495715 0.08529409 0.0834307  0.3816869 ], sigma noise: [0.36656877 0.371777   0.3703591  0.34358728]
[Epoch=200, n_hypersteps=11]: prior precision: [0.06850145 0.08155856 0.08015147 0.34103075], sigma noise: [0.36051443 0.36561882 0.36409518 0.33777905]
[Epoch=200, n_hypersteps=12]: prior precision: [0.06277793 0.07806145 0.07706472 0.30551007], sigma noise: [0.35560048 0.3606456  0.35899746 0.33291584]
[Epoch=200, n_hypersteps=13]: prior precision: [0.05773021 0.0748021  0.07416812 0.27456146], sigma noise: [0.35196897 0.35700455 0.35520992 0.3291136 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.05329674 0.07177603 0.07145713 0.24763824], sigma noise: [0.34969357 0.3547722  0.35280606 0.32642928]
[Epoch=200, n_hypersteps=15]: prior precision: [0.0494153  0.06897596 0.06892528 0.22423051], sigma noise: [0.3487804  0.35395598 0.3517902  0.32486132]
[Epoch=200, n_hypersteps=16]: prior precision: [0.04602589 0.06639249 0.0665656  0.2038752 ], sigma noise: [0.3491718  0.35449734 0.35210168 0.32435334]
[Epoch=200, n_hypersteps=17]: prior precision: [0.04307248 0.06401516 0.06437023 0.18615985], sigma noise: [0.35075277 0.35627797 0.35362104 0.32479998]
[Epoch=200, n_hypersteps=18]: prior precision: [0.04050388 0.06183246 0.06233099 0.1707221 ], sigma noise: [0.3533584  0.35912815 0.35617876 0.32605568]
[Epoch=200, n_hypersteps=19]: prior precision: [0.03827422 0.05983277 0.06043933 0.15724668], sigma noise: [0.356784   0.36283645 0.35956448 0.32794428]
[Epoch=200, n_hypersteps=20]: prior precision: [0.03634268 0.05800437 0.05868633 0.14546126], sigma noise: [0.3607957  0.36716014 0.3635386  0.33027017]
[Epoch=200, n_hypersteps=21]: prior precision: [0.03467346 0.05633583 0.05706337 0.1351318 ], sigma noise: [0.36514327 0.37183842 0.36784577 0.33282992]
[Epoch=200, n_hypersteps=22]: prior precision: [0.03323527 0.05481615 0.05556227 0.12605791], sigma noise: [0.3695733  0.37660548 0.37222776 0.33542368]
[Epoch=200, n_hypersteps=23]: prior precision: [0.03200093 0.05343471 0.0541753  0.11806824], sigma noise: [0.37384254 0.381205   0.37643564 0.33786613]
[Epoch=200, n_hypersteps=24]: prior precision: [0.03094689 0.05218145 0.05289453 0.11101655], sigma noise: [0.37773123 0.38540432 0.38024577 0.33999625]
[Epoch=200, n_hypersteps=25]: prior precision: [0.03005265 0.05104724 0.05171312 0.10477793], sigma noise: [0.38105574 0.38900742 0.3834721  0.34168485]
[Epoch=200, n_hypersteps=26]: prior precision: [0.02930061 0.05002327 0.05062453 0.09924576], sigma noise: [0.3836775  0.39186573 0.38597494 0.34283966]
[Epoch=200, n_hypersteps=27]: prior precision: [0.02867558 0.04910144 0.04962268 0.09432888], sigma noise: [0.38550922 0.3938848  0.38766673 0.3434079 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.02816423 0.04827421 0.0487013  0.08994933], sigma noise: [0.38651776 0.3950281  0.38851753 0.34337592]
[Epoch=200, n_hypersteps=29]: prior precision: [0.02775518 0.04753472 0.04785495 0.08604024], sigma noise: [0.38672262 0.39531493 0.38854915 0.34276652]
[Epoch=300, n_hypersteps=0]: prior precision: [0.02743848 0.04687659 0.04707837 0.08254413], sigma noise: [0.38619038 0.39481533 0.38783038 0.34163454]
[Epoch=300, n_hypersteps=1]: prior precision: [0.02697404 0.0457626  0.04606339 0.07869323], sigma noise: [0.3851062  0.39371157 0.38656121 0.34011424]
[Epoch=300, n_hypersteps=2]: prior precision: [0.02638933 0.0442897  0.04485875 0.07463834], sigma noise: [0.38359433 0.39213797 0.38486913 0.338297  ]
[Epoch=300, n_hypersteps=3]: prior precision: [0.02571161 0.04255389 0.04351144 0.07050546], sigma noise: [0.3817952  0.39024627 0.3828962  0.33628365]
[Epoch=300, n_hypersteps=4]: prior precision: [0.02496671 0.04064382 0.04206477 0.06639528], sigma noise: [0.3798554  0.38819385 0.38079077 0.334178  ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.02417816 0.03863705 0.04055689 0.06238477], sigma noise: [0.3779179  0.38613522 0.37869573 0.33208033]
[Epoch=300, n_hypersteps=6]: prior precision: [0.02336673 0.03659821 0.0390211  0.05852985], sigma noise: [0.37611407 0.38421187 0.37674245 0.3300819 ]
[Epoch=300, n_hypersteps=7]: prior precision: [0.02255002 0.03457859 0.03748519 0.05486854], sigma noise: [0.37455684 0.38254517 0.3750439  0.3282603 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.02174255 0.03261708 0.0359715  0.05142428], sigma noise: [0.37333515 0.3812308  0.3736891  0.32667568]
[Epoch=300, n_hypersteps=9]: prior precision: [0.02095585 0.03074169 0.03449784 0.04820896], sigma noise: [0.37251016 0.3803345  0.37273768 0.3253685 ]
[Epoch=300, n_hypersteps=10]: prior precision: [0.02019881 0.028971   0.03307764 0.04522573], sigma noise: [0.37211362 0.37989113 0.37222147 0.3243586 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.01947798 0.02731611 0.03172015 0.04247128], sigma noise: [0.372148   0.37990424 0.37214193 0.32364553]
[Epoch=300, n_hypersteps=12]: prior precision: [0.01879783 0.02578236 0.03043166 0.03993778], sigma noise: [0.3725886  0.38034767 0.37247384 0.32321003]
[Epoch=300, n_hypersteps=13]: prior precision: [0.01816119 0.02437056 0.02921622 0.03761442], sigma noise: [0.37338609 0.3811706  0.37316748 0.32301685]
[Epoch=300, n_hypersteps=14]: prior precision: [0.01756959 0.02307836 0.02807579 0.03548853], sigma noise: [0.37447196 0.3823006  0.3741532  0.32301843]
[Epoch=300, n_hypersteps=15]: prior precision: [0.01702344 0.02190115 0.02701039 0.03354658], sigma noise: [0.37576368 0.38365078 0.3753481  0.32315895]
[Epoch=300, n_hypersteps=16]: prior precision: [0.01652234 0.02083294 0.0260188  0.03177469], sigma noise: [0.37717134 0.38512594 0.3766635  0.32337868]
[Epoch=300, n_hypersteps=17]: prior precision: [0.01606528 0.01986698 0.02509889 0.03015921], sigma noise: [0.37860313 0.38662937 0.3780074  0.32361847]
[Epoch=300, n_hypersteps=18]: prior precision: [0.01565087 0.01899611 0.02424825 0.02868694], sigma noise: [0.37997216 0.38806954 0.3792952  0.32382366]
[Epoch=300, n_hypersteps=19]: prior precision: [0.01527738 0.01821307 0.02346348 0.02734542], sigma noise: [0.3812021  0.38936564 0.38045096 0.3239473 ]
[Epoch=300, n_hypersteps=20]: prior precision: [0.01494285 0.01751081 0.02274101 0.02612294], sigma noise: [0.38223195 0.39045173 0.38141313 0.32395294]
[Epoch=300, n_hypersteps=21]: prior precision: [0.01464526 0.01688265 0.0220776  0.02500867], sigma noise: [0.3830188  0.39128312 0.38213977 0.32381597]
[Epoch=300, n_hypersteps=22]: prior precision: [0.01438253 0.01632222 0.0214697  0.02399267], sigma noise: [0.3835396  0.39183635 0.3826068  0.32352442]
[Epoch=300, n_hypersteps=23]: prior precision: [0.01415263 0.01582364 0.02091417 0.02306582], sigma noise: [0.38379192 0.3921084  0.3828121  0.32307863]
[Epoch=300, n_hypersteps=24]: prior precision: [0.01395349 0.01538156 0.02040729 0.02221983], sigma noise: [0.38379171 0.392116   0.3827735  0.32249004]
[Epoch=300, n_hypersteps=25]: prior precision: [0.01378312 0.01499097 0.01994604 0.02144719], sigma noise: [0.38357162 0.39189368 0.38252205 0.32177964]
[Epoch=300, n_hypersteps=26]: prior precision: [0.01363961 0.01464736 0.01952718 0.02074108], sigma noise: [0.3831767  0.39148876 0.38210315 0.32097536]
[Epoch=300, n_hypersteps=27]: prior precision: [0.01352116 0.01434664 0.0191479  0.02009535], sigma noise: [0.38266045 0.390959   0.38156912 0.32010978]
[Epoch=300, n_hypersteps=28]: prior precision: [0.01342597 0.014085   0.01880533 0.01950445], sigma noise: [0.38208053 0.39036697 0.38097805 0.3192174 ]
[Epoch=300, n_hypersteps=29]: prior precision: [0.01335237 0.01385907 0.01849693 0.01896338], sigma noise: [0.38149387 0.38977128 0.3803862  0.31833187]
[Epoch=400, n_hypersteps=0]: prior precision: [0.01329872 0.01366573 0.01821995 0.01846761], sigma noise: [0.3809523  0.38922745 0.37984556 0.31748372]
[Epoch=400, n_hypersteps=1]: prior precision: [0.01321601 0.01347056 0.01791138 0.01796439], sigma noise: [0.38050812 0.3887791  0.37940708 0.31667313]
[Epoch=400, n_hypersteps=2]: prior precision: [0.01310835 0.01327568 0.01757889 0.01745936], sigma noise: [0.38019413 0.38846242 0.37910149 0.3159214 ]
[Epoch=400, n_hypersteps=3]: prior precision: [0.01297988 0.01308275 0.0172292  0.01695732], sigma noise: [0.3800313  0.38830033 0.37894934 0.31524312]
[Epoch=400, n_hypersteps=4]: prior precision: [0.01283463 0.0128933  0.0168684  0.01646216], sigma noise: [0.38002807 0.3883031  0.37895903 0.31464493]
[Epoch=400, n_hypersteps=5]: prior precision: [0.01267644 0.01270846 0.0165019  0.01597711], sigma noise: [0.38018072 0.38846812 0.3791281  0.3141257 ]
[Epoch=400, n_hypersteps=6]: prior precision: [0.01250892 0.01252933 0.01613442 0.01550467], sigma noise: [0.38047397 0.38877648 0.37943923 0.313678  ]
[Epoch=400, n_hypersteps=7]: prior precision: [0.01233535 0.01235684 0.01576977 0.01504676], sigma noise: [0.38088343 0.38920557 0.37986884 0.3132892 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.01215869 0.01219148 0.01541127 0.01460487], sigma noise: [0.38137805 0.3897219  0.38038513 0.31294286]
[Epoch=400, n_hypersteps=9]: prior precision: [0.01198156 0.01203381 0.0150617  0.01418007], sigma noise: [0.38192275 0.39028874 0.38095465 0.3126207 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.01180622 0.01188436 0.01472331 0.01377295], sigma noise: [0.38248163 0.39086866 0.38154083 0.31230363]
[Epoch=400, n_hypersteps=11]: prior precision: [0.01163462 0.01174303 0.01439765 0.01338381], sigma noise: [0.38302046 0.39142486 0.38211122 0.31197396]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.202 MB of 0.202 MB uploaded (0.000 MB deduped)wandb: \ 0.202 MB of 0.202 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                       Metrics ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.5347
wandb:                       Metrics 0.52946
wandb:  Negative_marginal_likelihood 1223.40186
wandb: Predictive_posterior_std_mean 0.73842
wandb:                   Sigma_noise 0.7361
wandb: 
wandb: üöÄ View run crimson-sweep-1 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/tvngxn3q
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165638-tvngxn3q/logs
wandb: Agent Starting Run: b1byv9my with config:
wandb: 	activation_cls: gelu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165757-b1byv9my
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/b1byv9my
[Epoch=400, n_hypersteps=12]: prior precision: [0.01146837 0.01161009 0.014086   0.01301275], sigma noise: [0.38350976 0.39192545 0.3826406  0.31161717]
[Epoch=400, n_hypersteps=13]: prior precision: [0.01130881 0.01148564 0.0137892  0.01265957], sigma noise: [0.38392547 0.39234605 0.38310283 0.31122157]
[Epoch=400, n_hypersteps=14]: prior precision: [0.011157   0.01136976 0.01350784 0.01232409], sigma noise: [0.38425177 0.39266893 0.38348213 0.3107805 ]
[Epoch=400, n_hypersteps=15]: prior precision: [0.01101376 0.01126219 0.0132423  0.01200593], sigma noise: [0.38448086 0.39288723 0.38377008 0.3102915 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.01087967 0.01116281 0.01299274 0.01170454], sigma noise: [0.38461334 0.39300185 0.38396546 0.30975592]
[Epoch=400, n_hypersteps=17]: prior precision: [0.01075518 0.01107133 0.01275902 0.01141927], sigma noise: [0.38465732 0.3930222  0.3840795  0.30917966]
[Epoch=400, n_hypersteps=18]: prior precision: [0.01064051 0.01098773 0.01254097 0.01114955], sigma noise: [0.3846274  0.39296564 0.3841251  0.30857155]
[Epoch=400, n_hypersteps=19]: prior precision: [0.01053581 0.01091152 0.0123382  0.01089486], sigma noise: [0.38454232 0.39285064 0.38412058 0.307942  ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.01044104 0.01084244 0.01215031 0.01065458], sigma noise: [0.38442388 0.39269915 0.3840861  0.30730346]
[Epoch=400, n_hypersteps=21]: prior precision: [0.01035612 0.01078034 0.01197682 0.01042791], sigma noise: [0.38429433 0.392537   0.38404286 0.3066673 ]
[Epoch=400, n_hypersteps=22]: prior precision: [0.01028085 0.01072498 0.01181719 0.01021432], sigma noise: [0.38417444 0.3923844  0.3840135  0.30604455]
[Epoch=400, n_hypersteps=23]: prior precision: [0.01021497 0.01067602 0.01167099 0.01001308], sigma noise: [0.38408256 0.39226192 0.38401473 0.30544582]
[Epoch=400, n_hypersteps=24]: prior precision: [0.01015815 0.01063299 0.01153762 0.00982355], sigma noise: [0.38403273 0.3921862  0.38405842 0.30487782]
[Epoch=400, n_hypersteps=25]: prior precision: [0.01011004 0.01059539 0.01141639 0.00964502], sigma noise: [0.38403407 0.39216518 0.38415417 0.3043442 ]
[Epoch=400, n_hypersteps=26]: prior precision: [0.01007022 0.01056321 0.01130662 0.00947702], sigma noise: [0.38409042 0.39220122 0.3843088  0.30384693]
[Epoch=400, n_hypersteps=27]: prior precision: [0.01003826 0.01053607 0.01120778 0.00931884], sigma noise: [0.38419983 0.3922947  0.38451934 0.30338532]
[Epoch=400, n_hypersteps=28]: prior precision: [0.01001369 0.01051375 0.01111933 0.00917002], sigma noise: [0.38435635 0.39243603 0.38478023 0.3029549 ]
[Epoch=400, n_hypersteps=29]: prior precision: [0.00999605 0.01049594 0.01104072 0.00903006], sigma noise: [0.38454992 0.39261484 0.3850784  0.30255136]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='gelu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.81910986 0.8190908  0.8190797  0.8206011 ], sigma noise: [0.8188235  0.8188245  0.81882447 0.8188217 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7420796 0.7420135 0.7419761 0.7477887], sigma noise: [0.7411611  0.74116457 0.7411644  0.7411546 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.67302334 0.67287546 0.6727937  0.6870778 ], sigma noise: [0.671143   0.6711509  0.67115074 0.6711275 ]
[Epoch=100, n_hypersteps=5]: prior precision: [0.61124104 0.6109719  0.6108265  0.6390988 ], sigma noise: [0.6081499  0.60816485 0.6081649  0.6081195 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55606335 0.55563027 0.55540156 0.604111  ], sigma noise: [0.55165136 0.55167687 0.55167735 0.551598  ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.5068554  0.5062161  0.50588447 0.581662  ], sigma noise: [0.5012105 0.5012514 0.5012522 0.501123 ]
[Epoch=100, n_hypersteps=8]: prior precision: [0.4630226  0.46213594 0.46168184 0.570696  ], sigma noise: [0.45649296 0.45655584 0.4565566  0.45635527]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42401353 0.42284015 0.42224506 0.5697779 ], sigma noise: [0.41727918 0.41737396 0.41737378 0.41706875]
[Epoch=100, n_hypersteps=10]: prior precision: [0.3893181  0.38782302 0.38706973 0.5774857 ], sigma noise: [0.383477   0.38361815 0.3836157  0.38316143]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35846928 0.3566232  0.35569584 0.5925796 ], sigma noise: [0.35511953 0.3553274  0.35532016 0.3546526 ]
[Epoch=100, n_hypersteps=12]: prior precision: [0.3310435  0.32882196 0.32770604 0.6140378 ], sigma noise: [0.33232304 0.3326251  0.3326093  0.33164176]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30665842 0.30404142 0.3027233  0.64091736], sigma noise: [0.3151803  0.31561103 0.3155828  0.31420544]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28497168 0.28194228 0.2804107  0.67221934], sigma noise: [0.30361497 0.3042146  0.3041687  0.3022563 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26567295 0.2622207  0.26046482 0.70674837], sigma noise: [0.29729286 0.29810315 0.29803437 0.29545453]
[Epoch=100, n_hypersteps=16]: prior precision: [0.24849062 0.24460578 0.24261841 0.7429414 ], sigma noise: [0.29565924 0.2967237  0.29662654 0.29324445]
[Epoch=100, n_hypersteps=17]: prior precision: [0.23318349 0.22885709 0.22663333 0.77870476], sigma noise: [0.2980634  0.29942608 0.2992948  0.2949709 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.2195365  0.21476167 0.21229698 0.81146437], sigma noise: [0.30385557 0.30556464 0.30539367 0.29997766]
[Epoch=100, n_hypersteps=19]: prior precision: [0.20735799 0.20213032 0.19942401 0.83851284], sigma noise: [0.31242657 0.31453374 0.31431606 0.30764455]
[Epoch=100, n_hypersteps=20]: prior precision: [0.19648059 0.19079736 0.18784857 0.8574735 ], sigma noise: [0.32319376 0.32575577 0.32548484 0.3173806 ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.18675901 0.1806162  0.17742391 0.8668727 ], sigma noise: [0.33557704 0.33865312 0.33832163 0.32860222]
[Epoch=100, n_hypersteps=22]: prior precision: [0.17806308 0.1714584  0.16802235 0.8664671 ], sigma noise: [0.34897846 0.35262558 0.35222608 0.34071738]
[Epoch=100, n_hypersteps=23]: prior precision: [0.17028058 0.16321066 0.1595314  0.8571093 ], sigma noise: [0.36277813 0.36704513 0.36657143 0.3531247 ]
[Epoch=100, n_hypersteps=24]: prior precision: [0.16331016 0.15577331 0.15185131 0.8404172 ], sigma noise: [0.37634686 0.38126805 0.38071552 0.36522955]
[Epoch=100, n_hypersteps=25]: prior precision: [0.15706354 0.14905894 0.14489456 0.81841975], sigma noise: [0.38907486 0.3946635  0.3940293  0.37647113]
[Epoch=100, n_hypersteps=26]: prior precision: [0.15146512 0.1429905  0.13858435 0.79322594], sigma noise: [0.40041062 0.40665314 0.40593836 0.38635582]
[Epoch=100, n_hypersteps=27]: prior precision: [0.14644903 0.13749996 0.13285246 0.7668297 ], sigma noise: [0.40989566 0.41675    0.41596076 0.3944868 ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.1419531  0.132528   0.12764005 0.74098897], sigma noise: [0.41719493 0.424592   0.4237371  0.40058547]
[Epoch=100, n_hypersteps=29]: prior precision: [0.13792917 0.1280218  0.12289399 0.71716946], sigma noise: [0.42211318 0.42996204 0.42905173 0.4045013 ]
[Epoch=200, n_hypersteps=0]: prior precision: [0.13432895 0.12393522 0.1185678  0.6965041 ], sigma noise: [0.42459643 0.43279323 0.43183923 0.40620956]
[Epoch=200, n_hypersteps=1]: prior precision: [0.1310922  0.12012853 0.11458831 0.69113594], sigma noise: [0.42420712 0.43263823 0.43164617 0.40534198]
[Epoch=200, n_hypersteps=2]: prior precision: [0.12818617 0.11658592 0.11092617 0.69851756], sigma noise: [0.42121813 0.42977503 0.42875025 0.4021555 ]
[Epoch=200, n_hypersteps=3]: prior precision: [0.12558283 0.11329223 0.10755473 0.7167735 ], sigma noise: [0.4160061  0.42459267 0.4235409  0.39699152]
[Epoch=200, n_hypersteps=4]: prior precision: [0.12325644 0.11023284 0.1044485  0.74450654], sigma noise: [0.4090147  0.4175544  0.4164808  0.39024633]
[Epoch=200, n_hypersteps=5]: prior precision: [0.12118524 0.10739397 0.10158676 0.7806033 ], sigma noise: [0.40072447 0.40916237 0.4080707  0.38234442]
[Epoch=200, n_hypersteps=6]: prior precision: [0.11934923 0.10476262 0.09894915 0.8240032 ], sigma noise: [0.3916222  0.39992982 0.39882123 0.3737165 ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.11773028 0.10232618 0.09651882 0.87349534], sigma noise: [0.38218394 0.39035627 0.38922927 0.36478108]
[Epoch=200, n_hypersteps=8]: prior precision: [0.11630771 0.10007296 0.09427915 0.9275299 ], sigma noise: [0.37285468 0.3809099  0.37976065 0.3559299 ]
[Epoch=200, n_hypersteps=9]: prior precision: [0.11506721 0.09799143 0.09221435 0.98406965], sigma noise: [0.36403495 0.37201333 0.3708367  0.34751624]
[Epoch=200, n_hypersteps=10]: prior precision: [0.11399411 0.09607125 0.09031188 1.0404731 ], sigma noise: [0.35606945 0.36403215 0.36281845 0.33984464]
[Epoch=200, n_hypersteps=11]: prior precision: [0.11307646 0.09430217 0.08855927 1.0935801 ], sigma noise: [0.34923822 0.35726485 0.35600013 0.33316278]
[Epoch=200, n_hypersteps=12]: prior precision: [0.11230218 0.09267459 0.0869446  1.1400061 ], sigma noise: [0.3437527  0.35193717 0.35060644 0.3276543 ]
[Epoch=200, n_hypersteps=13]: prior precision: [0.11165763 0.09117936 0.08545795 1.1766106 ], sigma noise: [0.33974707 0.3481948  0.34678027 0.32343426]
[Epoch=200, n_hypersteps=14]: prior precision: [0.11113925 0.08980805 0.08408867 1.2010827 ], sigma noise: [0.33727875 0.34610417 0.34458584 0.32054755]
[Epoch=200, n_hypersteps=15]: prior precision: [0.11073396 0.08855285 0.08282827 1.2123262 ], sigma noise: [0.33632833 0.3456536  0.34400877 0.31897053]
[Epoch=200, n_hypersteps=16]: prior precision: [0.11044011 0.08740567 0.08166918 1.2106193 ], sigma noise: [0.33680907 0.3467582  0.34496313 0.31861666]
[Epoch=200, n_hypersteps=17]: prior precision: [0.11024362 0.08635946 0.08060259 1.1974237 ], sigma noise: [0.33856937 0.34926602 0.34729812 0.3193448 ]
[Epoch=200, n_hypersteps=18]: prior precision: [0.110139   0.08540676 0.07962143 1.1750039 ], sigma noise: [0.34140822 0.3529705  0.35080495 0.32096985]
[Epoch=200, n_hypersteps=19]: prior precision: [0.11011819 0.08454076 0.07872015 1.1460526 ], sigma noise: [0.34508365 0.35761863 0.35523456 0.32327515]
[Epoch=200, n_hypersteps=20]: prior precision: [0.11017139 0.08375564 0.07789294 1.113327  ], sigma noise: [0.34932688 0.36292392 0.3603029  0.32602522]
[Epoch=200, n_hypersteps=21]: prior precision: [0.11029799 0.08304495 0.07713319 1.0793915 ], sigma noise: [0.35385716 0.36858022 0.36570862 0.3289794 ]
[Epoch=200, n_hypersteps=22]: prior precision: [0.11048441 0.0824035  0.0764364  1.0464292 ], sigma noise: [0.35839438 0.37427768 0.3711467  0.3319055 ]
[Epoch=200, n_hypersteps=23]: prior precision: [0.1107257  0.08182622 0.07579727 1.0162048 ], sigma noise: [0.36267498 0.37971884 0.37632802 0.33459225]
[Epoch=200, n_hypersteps=24]: prior precision: [0.11101657 0.08130874 0.07521067 0.9900016 ], sigma noise: [0.36646685 0.38463593 0.3809926  0.33685997]
[Epoch=200, n_hypersteps=25]: prior precision: [0.11135066 0.08084638 0.07467289 0.9687005 ], sigma noise: [0.36958385 0.38880676 0.38492522 0.33856937]
[Epoch=200, n_hypersteps=26]: prior precision: [0.11172106 0.08043527 0.07418064 0.95278007], sigma noise: [0.37189287 0.39206785 0.3879693  0.33962604]
[Epoch=200, n_hypersteps=27]: prior precision: [0.11212634 0.08007175 0.07373133 0.94242984], sigma noise: [0.37331703 0.3943201  0.39002958 0.33998266]
[Epoch=200, n_hypersteps=28]: prior precision: [0.11256474 0.07975258 0.0733208  0.93758136], sigma noise: [0.3738392  0.39553383 0.3910817  0.3396374 ]
[Epoch=200, n_hypersteps=29]: prior precision: [0.11303457 0.07947426 0.0729475  0.9379477 ], sigma noise: [0.37350133 0.3957454  0.3911613  0.33862972]
[Epoch=300, n_hypersteps=0]: prior precision: [0.11352544 0.07923401 0.07260811 0.9430683 ], sigma noise: [0.37239063 0.3950504  0.3903634  0.33703423]
[Epoch=300, n_hypersteps=1]: prior precision: [0.11403535 0.07903024 0.07227718 0.96512353], sigma noise: [0.37011105 0.39297533 0.3882419  0.3345595 ]
[Epoch=300, n_hypersteps=2]: prior precision: [0.11456045 0.07886051 0.07195421 1.0020778 ], sigma noise: [0.3669009  0.3897929  0.385061   0.33138776]
[Epoch=300, n_hypersteps=3]: prior precision: [0.11509273 0.07872254 0.07164058 1.0523081 ], sigma noise: [0.3630287  0.3858215  0.38112664 0.32772413]
[Epoch=300, n_hypersteps=4]: prior precision: [0.1156335  0.07861441 0.07133552 1.1141877 ], sigma noise: [0.3587785  0.38139895 0.3767634  0.32378292]
[Epoch=300, n_hypersteps=5]: prior precision: [0.11617958 0.07853438 0.07103929 1.1857952 ], sigma noise: [0.3544318  0.3768615  0.37229472 0.3197747 ]
[Epoch=300, n_hypersteps=6]: prior precision: [0.11673024 0.07848033 0.07075235 1.2646337 ], sigma noise: [0.35025164 0.37252218 0.36802077 0.31589472]
[Epoch=300, n_hypersteps=7]: prior precision: [0.11728117 0.07845056 0.07047525 1.3473314 ], sigma noise: [0.346469   0.36865437 0.36420634 0.31231338]
[Epoch=300, n_hypersteps=8]: prior precision: [0.11782983 0.07844375 0.07020729 1.4296198 ], sigma noise: [0.34326956 0.36548015 0.36106536 0.30916777]
[Epoch=300, n_hypersteps=9]: prior precision: [0.11837503 0.07845819 0.06994955 1.5064055 ], sigma noise: [0.34078622 0.3631637  0.35875273 0.30655625]
[Epoch=300, n_hypersteps=10]: prior precision: [0.11891448 0.07849252 0.06970158 1.572388  ], sigma noise: [0.3390999  0.36180332 0.35736606 0.3045352 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.11944746 0.07854487 0.06946337 1.6227826 ], sigma noise: [0.338235   0.36143342 0.35693753 0.30311856]
[Epoch=300, n_hypersteps=12]: prior precision: [0.11997247 0.0786134  0.06923497 1.6542816 ], sigma noise: [0.33816198 0.36202484 0.35743874 0.3022801 ]
[Epoch=300, n_hypersteps=13]: prior precision: [0.12048362 0.07869621 0.06901581 1.6655989 ], sigma noise: [0.3388064  0.36349264 0.3587856  0.30195835]
[Epoch=300, n_hypersteps=14]: prior precision: [0.12099124 0.0787919  0.06880656 1.6576672 ], sigma noise: [0.34005272 0.36570323 0.3608484  0.30206355]
[Epoch=300, n_hypersteps=15]: prior precision: [0.12148462 0.07889905 0.06860647 1.6332067 ], sigma noise: [0.34175545 0.36848485 0.3634603  0.3024859 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.12196097 0.07901584 0.06841546 1.5960867 ], sigma noise: [0.34374878 0.37163934 0.3664334  0.30310482]
[Epoch=300, n_hypersteps=17]: prior precision: [0.12242319 0.07914045 0.06823348 1.5507003 ], sigma noise: [0.34586152 0.37495673 0.36956328 0.3037983 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.12286663 0.07927116 0.06805956 1.5013108 ], sigma noise: [0.3479282  0.37822935 0.37264708 0.3044514 ]
[Epoch=300, n_hypersteps=19]: prior precision: [0.12329018 0.07940707 0.06789434 1.4516579 ], sigma noise: [0.34979877 0.38126475 0.3755055  0.30496386]
[Epoch=300, n_hypersteps=20]: prior precision: [0.1236898  0.0795467  0.06773655 1.4048551 ], sigma noise: [0.35134834 0.3838993  0.3779804  0.30525535]
[Epoch=300, n_hypersteps=21]: prior precision: [0.12406421 0.07968869 0.0675858  1.3632888 ], sigma noise: [0.3524867  0.3860088  0.37995493 0.3052695 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.12441264 0.07983208 0.0674423  1.3285587 ], sigma noise: [0.35315847 0.38751566 0.38135573 0.30497527]
[Epoch=300, n_hypersteps=23]: prior precision: [0.1247409  0.07997568 0.06730603 1.3016262 ], sigma noise: [0.3533477  0.38839066 0.38215664 0.3043667 ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.199 MB of 0.288 MB uploaded (0.000 MB deduped)wandb: \ 0.210 MB of 0.288 MB uploaded (0.000 MB deduped)wandb: | 0.210 MB of 0.288 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.48637
wandb:                       Metrics 0.48359
wandb:  Negative_marginal_likelihood 1149.31458
wandb: Predictive_posterior_std_mean 0.70328
wandb:                   Sigma_noise 0.70128
wandb: 
wandb: üöÄ View run smart-sweep-2 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/b1byv9my
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165757-b1byv9my/logs
wandb: Agent Starting Run: lyfgdu6n with config:
wandb: 	activation_cls: gelu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.001
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165909-lyfgdu6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/lyfgdu6n
[Epoch=300, n_hypersteps=24]: prior precision: [0.12504303 0.08011937 0.06717586 1.2829319 ], sigma noise: [0.3530753  0.38865334 0.38237655 0.30346072]
[Epoch=300, n_hypersteps=25]: prior precision: [0.12532148 0.08026207 0.06705236 1.2725244 ], sigma noise: [0.35239094 0.38836583 0.38207543 0.3022938 ]
[Epoch=300, n_hypersteps=26]: prior precision: [0.12557535 0.08040317 0.06693532 1.2700657 ], sigma noise: [0.35137054 0.38762626 0.38134426 0.3009175 ]
[Epoch=300, n_hypersteps=27]: prior precision: [0.12580255 0.08054227 0.0668244  1.2749567 ], sigma noise: [0.35010856 0.38655645 0.3803005  0.2993934 ]
[Epoch=300, n_hypersteps=28]: prior precision: [0.12601076 0.08067928 0.0667196  1.2863703 ], sigma noise: [0.3487074  0.38529328 0.37907436 0.29778802]
[Epoch=300, n_hypersteps=29]: prior precision: [0.12620516 0.08081356 0.06662025 1.303276  ], sigma noise: [0.34727004 0.38397568 0.3777981  0.29616782]
[Epoch=400, n_hypersteps=0]: prior precision: [0.12638324 0.08094504 0.06652708 1.3244411 ], sigma noise: [0.34589547 0.38273558 0.37659538 0.29459423]
[Epoch=400, n_hypersteps=1]: prior precision: [0.1265438  0.0810768  0.06642674 1.3644794 ], sigma noise: [0.34463194 0.3816378  0.3755332  0.2930945 ]
[Epoch=400, n_hypersteps=2]: prior precision: [0.12668574 0.08120821 0.06632019 1.4211106 ], sigma noise: [0.3435524  0.38078043 0.374704   0.29171342]
[Epoch=400, n_hypersteps=3]: prior precision: [0.12680767 0.0813388  0.06620933 1.4919323 ], sigma noise: [0.3427101  0.38023537 0.37417623 0.29048285]
[Epoch=400, n_hypersteps=4]: prior precision: [0.12691604 0.08146781 0.06609453 1.5741965 ], sigma noise: [0.34213442 0.3800453  0.3739928  0.28942057]
[Epoch=400, n_hypersteps=5]: prior precision: [0.12701525 0.08159497 0.06597683 1.6643858 ], sigma noise: [0.3418318  0.38022244 0.3741634  0.28852993]
[Epoch=400, n_hypersteps=6]: prior precision: [0.12710318 0.08171929 0.06585644 1.7581257 ], sigma noise: [0.34178966 0.38074994 0.37467322 0.28780103]
[Epoch=400, n_hypersteps=7]: prior precision: [0.12717997 0.08184057 0.06573386 1.8501129 ], sigma noise: [0.34197715 0.381586   0.37548116 0.28721267]
[Epoch=400, n_hypersteps=8]: prior precision: [0.12724148 0.08195888 0.06561055 1.9345288 ], sigma noise: [0.34234682 0.38266787 0.37652767 0.28673515]
[Epoch=400, n_hypersteps=9]: prior precision: [0.12729163 0.08207369 0.06548589 2.0055418 ], sigma noise: [0.34284052 0.38391837 0.37773773 0.28633332]
[Epoch=400, n_hypersteps=10]: prior precision: [0.1273327  0.08218458 0.06536116 2.0582833 ], sigma noise: [0.34339622 0.385252   0.37902912 0.28596997]
[Epoch=400, n_hypersteps=11]: prior precision: [0.12736931 0.0822911  0.06523772 2.089584  ], sigma noise: [0.34395367 0.38658333 0.3803199  0.28560895]
[Epoch=400, n_hypersteps=12]: prior precision: [0.12740108 0.08239295 0.06511556 2.0985212 ], sigma noise: [0.34445775 0.3878329  0.38153493 0.28521815]
[Epoch=400, n_hypersteps=13]: prior precision: [0.12742223 0.08248952 0.06499373 2.0864353 ], sigma noise: [0.34486008 0.38893387 0.38261133 0.28477153]
[Epoch=400, n_hypersteps=14]: prior precision: [0.12743767 0.08258066 0.06487304 2.0565636 ], sigma noise: [0.3451281  0.38983637 0.3834999  0.28425068]
[Epoch=400, n_hypersteps=15]: prior precision: [0.12744139 0.08266618 0.06475464 2.0133028 ], sigma noise: [0.3452403  0.39050853 0.38417244 0.2836455 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.12744024 0.0827459  0.06463858 1.9615355 ], sigma noise: [0.34519115 0.39094168 0.38462067 0.28295437]
[Epoch=400, n_hypersteps=17]: prior precision: [0.12743083 0.08282015 0.06452556 1.906039  ], sigma noise: [0.34498873 0.39114588 0.38485172 0.2821832 ]
[Epoch=400, n_hypersteps=18]: prior precision: [0.12741639 0.08288913 0.06441483 1.8510218 ], sigma noise: [0.34465432 0.39114976 0.38489532 0.28134444]
[Epoch=400, n_hypersteps=19]: prior precision: [0.12739404 0.08295301 0.0643076  1.7999041 ], sigma noise: [0.34421736 0.39099553 0.3847914  0.2804554 ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.12736773 0.08301173 0.06420306 1.7552471 ], sigma noise: [0.34371534 0.3907349  0.38458818 0.2795364 ]
[Epoch=400, n_hypersteps=21]: prior precision: [0.127338   0.08306544 0.06410141 1.7187701 ], sigma noise: [0.34318686 0.39042434 0.3843357  0.27860862]
[Epoch=400, n_hypersteps=22]: prior precision: [0.1273049  0.08311425 0.06400237 1.6914583 ], sigma noise: [0.34266773 0.39011842 0.38409033 0.27769268]
[Epoch=400, n_hypersteps=23]: prior precision: [0.12726833 0.08315812 0.06390694 1.6737432 ], sigma noise: [0.34219193 0.38986683 0.3838969  0.2768066 ]
[Epoch=400, n_hypersteps=24]: prior precision: [0.12723146 0.08319724 0.06381582 1.6655011 ], sigma noise: [0.34178582 0.38970944 0.38379505 0.27596483]
[Epoch=400, n_hypersteps=25]: prior precision: [0.12719133 0.08323193 0.06372894 1.66618   ], sigma noise: [0.34146622 0.3896749  0.38381028 0.27517697]
[Epoch=400, n_hypersteps=26]: prior precision: [0.12714879 0.08326259 0.06364575 1.6749477 ], sigma noise: [0.34124607 0.38977814 0.38395658 0.2744477 ]
[Epoch=400, n_hypersteps=27]: prior precision: [0.12710212 0.08328936 0.06356567 1.6906737 ], sigma noise: [0.34112486 0.39002112 0.38423735 0.27377686]
[Epoch=400, n_hypersteps=28]: prior precision: [0.127055   0.08331269 0.06348848 1.7119868 ], sigma noise: [0.34109595 0.3903923  0.38463917 0.27315977]
[Epoch=400, n_hypersteps=29]: prior precision: [0.12700322 0.08333281 0.06341483 1.7373503 ], sigma noise: [0.34114236 0.39086953 0.38514182 0.27258813]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.001, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='gelu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8190831  0.81907517 0.81906414 0.8191091 ], sigma noise: [0.81886995 0.81886995 0.8188702  0.81886894]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74198663 0.7419592  0.741922   0.74207586], sigma noise: [0.74133915 0.7413391  0.7413403  0.74133533]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6728149  0.6727543  0.67267346 0.67301124], sigma noise: [0.6715887  0.6715887  0.6715923  0.67157906]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6108605  0.61075217 0.6106091  0.6112117 ], sigma noise: [0.6090698 0.6090703 0.6090786 0.6090496]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55544907 0.55527896 0.5550553  0.55600244], sigma noise: [0.55335337 0.5533551  0.5533715  0.55331534]
[Epoch=100, n_hypersteps=7]: prior precision: [0.505945   0.50570005 0.505378   0.50674474], sigma noise: [0.5041497 0.5041537 0.5041839 0.5040821]
[Epoch=100, n_hypersteps=8]: prior precision: [0.4617554  0.4614235  0.4609863  0.46284106], sigma noise: [0.46133476 0.46134302 0.4613944  0.46121934]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42233142 0.42190182 0.42133436 0.42373526], sigma noise: [0.424969   0.42498493 0.42506883 0.42477873]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38717005 0.38663238 0.3859213  0.38891682], sigma noise: [0.39527735 0.39530528 0.39543742 0.39497256]
[Epoch=100, n_hypersteps=11]: prior precision: [0.3558117  0.355158   0.3542889  0.35792136], sigma noise: [0.37252834 0.37257442 0.3727742  0.37205562]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32783997 0.3270631  0.32602373 0.33032688], sigma noise: [0.3568063  0.35687682 0.35716715 0.35610285]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30287713 0.30197325 0.30075312 0.3057542 ], sigma noise: [0.34780553 0.3479074  0.34831235 0.34680554]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28058544 0.27955025 0.27814218 0.2838558 ], sigma noise: [0.34483692 0.3449775  0.3455194  0.34347647]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26066425 0.25949267 0.2578927  0.2643383 ], sigma noise: [0.34702158 0.34720868 0.3479101  0.345238  ]
[Epoch=100, n_hypersteps=16]: prior precision: [0.24284305 0.2415326  0.23973747 0.24692617], sigma noise: [0.35347703 0.3537181  0.35460433 0.35120317]
[Epoch=100, n_hypersteps=17]: prior precision: [0.22688362 0.2254315  0.22343948 0.23137973], sigma noise: [0.363388   0.3636907  0.36478907 0.36054978]
[Epoch=100, n_hypersteps=18]: prior precision: [0.21257271 0.21097867 0.20879006 0.21748358], sigma noise: [0.37599477 0.37636694 0.37770694 0.3725134 ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.19972572 0.19798884 0.19560254 0.20504913], sigma noise: [0.390551   0.39100122 0.39261332 0.38634276]
[Epoch=100, n_hypersteps=20]: prior precision: [0.18817544 0.18629673 0.1837131  0.19391513], sigma noise: [0.40628967 0.40682673 0.40874195 0.40127566]
[Epoch=100, n_hypersteps=21]: prior precision: [0.17777857 0.17575693 0.17297633 0.18393318], sigma noise: [0.42241547 0.4230467  0.42529184 0.4165279 ]
[Epoch=100, n_hypersteps=22]: prior precision: [0.16840513 0.16624223 0.16326614 0.17497814], sigma noise: [0.43812326 0.4388537  0.4414466  0.4313185 ]
[Epoch=100, n_hypersteps=23]: prior precision: [0.15994187 0.15764043 0.15447    0.16693245], sigma noise: [0.45264184 0.45347303 0.45641786 0.44490921]
[Epoch=100, n_hypersteps=24]: prior precision: [0.15229052 0.14985172 0.1464888  0.15970317], sigma noise: [0.4652839  0.46621227 0.46949974 0.456653  ]
[Epoch=100, n_hypersteps=25]: prior precision: [0.14536414 0.14278905 0.1392354  0.15320116], sigma noise: [0.47549942 0.47651893 0.4801218  0.4660414 ]
[Epoch=100, n_hypersteps=26]: prior precision: [0.13908637 0.13637424 0.13263217 0.14735506], sigma noise: [0.48291385 0.48401368 0.48789054 0.4727356 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.13338862 0.13053994 0.12661089 0.14209498], sigma noise: [0.48734424 0.48851115 0.4926108  0.476581  ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.1282117  0.12522659 0.12111115 0.1373539 ], sigma noise: [0.4887987  0.49001604 0.49427995 0.47759932]
[Epoch=100, n_hypersteps=29]: prior precision: [0.12350286 0.1203808  0.11608049 0.13308255], sigma noise: [0.4874532  0.4887053  0.4930741  0.47596973]
[Epoch=200, n_hypersteps=0]: prior precision: [0.11921746 0.11595646 0.11147176 0.12924191], sigma noise: [0.48362407 0.4848955  0.4893123  0.47199622]
[Epoch=200, n_hypersteps=1]: prior precision: [0.11526818 0.11173853 0.10723646 0.12578392], sigma noise: [0.4755262 0.476818  0.4811405 0.4640093]
[Epoch=200, n_hypersteps=2]: prior precision: [0.11162699 0.10772923 0.10333874 0.1226771 ], sigma noise: [0.46403855 0.46535206 0.46946803 0.4528324 ]
[Epoch=200, n_hypersteps=3]: prior precision: [0.10827184 0.10392807 0.09974843 0.11989135], sigma noise: [0.4500883  0.45142502 0.45525724 0.43933374]
[Epoch=200, n_hypersteps=4]: prior precision: [0.10518098 0.10033276 0.09643742 0.11739872], sigma noise: [0.43459222 0.43595502 0.43945578 0.42437038]
[Epoch=200, n_hypersteps=5]: prior precision: [0.10233372 0.09693915 0.09338016 0.11515757], sigma noise: [0.4184158  0.4198115  0.4229589  0.40875384]
[Epoch=200, n_hypersteps=6]: prior precision: [0.09970959 0.09374338 0.09055203 0.11315893], sigma noise: [0.40235212 0.40378883 0.40658343 0.393228  ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.09729172 0.09073588 0.08793383 0.11138026], sigma noise: [0.38710612 0.38859707 0.39105815 0.3784596 ]
[Epoch=200, n_hypersteps=8]: prior precision: [0.09506681 0.08791113 0.08550698 0.10979738], sigma noise: [0.3732846  0.37484783 0.3770021  0.36502102]
[Epoch=200, n_hypersteps=9]: prior precision: [0.09301806 0.08526021 0.08325719 0.10840093], sigma noise: [0.36139113 0.36304677 0.36492813 0.35338327]
[Epoch=200, n_hypersteps=10]: prior precision: [0.09113178 0.08277673 0.08116788 0.10717215], sigma noise: [0.35180137 0.35358173 0.35522357 0.34391084]
[Epoch=200, n_hypersteps=11]: prior precision: [0.08939477 0.0804517  0.07922589 0.10609872], sigma noise: [0.34476423 0.34670776 0.34814078 0.33683476]
[Epoch=200, n_hypersteps=12]: prior precision: [0.08780191 0.07827783 0.07741923 0.10517215], sigma noise: [0.34039035 0.34254277 0.34378964 0.33225492]
[Epoch=200, n_hypersteps=13]: prior precision: [0.08634126 0.07624575 0.07573635 0.10437112], sigma noise: [0.33865562 0.34106752 0.34214625 0.3301412 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.08500034 0.07434862 0.07416496 0.10368817], sigma noise: [0.3394035  0.34212935 0.34305388 0.33033943]
[Epoch=200, n_hypersteps=15]: prior precision: [0.08377286 0.07257752 0.07269982 0.10311352], sigma noise: [0.34237355 0.34547502 0.34625375 0.33259135]
[Epoch=200, n_hypersteps=16]: prior precision: [0.08264291 0.070925   0.07132896 0.10263456], sigma noise: [0.34722003 0.35075334 0.3513919  0.33656263]
[Epoch=200, n_hypersteps=17]: prior precision: [0.081604   0.06938057 0.07004459 0.10225805], sigma noise: [0.35353035 0.35755172 0.35804483 0.34184977]
[Epoch=200, n_hypersteps=18]: prior precision: [0.08065002 0.06793704 0.06884133 0.10197519], sigma noise: [0.36084026 0.36539945 0.36573958 0.34801257]
[Epoch=200, n_hypersteps=19]: prior precision: [0.07977462 0.06658779 0.06771333 0.10177325], sigma noise: [0.36865526 0.37379545 0.37397194 0.35459375]
[Epoch=200, n_hypersteps=20]: prior precision: [0.0789687  0.06532637 0.06665506 0.10164342], sigma noise: [0.37648624 0.3822306  0.38222882 0.3611379 ]
[Epoch=200, n_hypersteps=21]: prior precision: [0.07823037 0.06414869 0.06565952 0.10158305], sigma noise: [0.3838603  0.39021692 0.39002556 0.36722857]
[Epoch=200, n_hypersteps=22]: prior precision: [0.07755239 0.06304896 0.06472287 0.10158305], sigma noise: [0.39036283 0.39731413 0.39692444 0.37249786]
[Epoch=200, n_hypersteps=23]: prior precision: [0.07692973 0.06201886 0.06383985 0.10164587], sigma noise: [0.39565492 0.40316084 0.40257698 0.37666458]
[Epoch=200, n_hypersteps=24]: prior precision: [0.07636292 0.06105676 0.0630061  0.1017603 ], sigma noise: [0.39949936 0.40749884 0.40672094 0.379536  ]
[Epoch=200, n_hypersteps=25]: prior precision: [0.0758439  0.06015601 0.06222038 0.10191372], sigma noise: [0.40177047 0.41018853 0.4092192  0.3810144 ]
[Epoch=200, n_hypersteps=26]: prior precision: [0.07536874 0.05931486 0.06147576 0.10211252], sigma noise: [0.40246078 0.41120923 0.4100628  0.38110593]
[Epoch=200, n_hypersteps=27]: prior precision: [0.07493763 0.05853008 0.06077196 0.10235135], sigma noise: [0.40165997 0.41065392 0.40934741 0.3799015 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.0745474  0.05779831 0.06010583 0.10262778], sigma noise: [0.39954373 0.4087053  0.40725744 0.37756494]
[Epoch=200, n_hypersteps=29]: prior precision: [0.07419272 0.05711532 0.05947521 0.10293696], sigma noise: [0.39636198 0.40562743 0.40405765 0.3743117 ]
[Epoch=300, n_hypersteps=0]: prior precision: [0.07387333 0.05647838 0.05887657 0.1032875 ], sigma noise: [0.3924088 0.4017282 0.4000448 0.370399 ]
[Epoch=300, n_hypersteps=1]: prior precision: [0.07358694 0.05585692 0.05830807 0.10367505], sigma noise: [0.3875227  0.3968532  0.39505604 0.3656904 ]
[Epoch=300, n_hypersteps=2]: prior precision: [0.0733308  0.05525215 0.05776755 0.1040903 ], sigma noise: [0.3820989  0.39141536 0.38950303 0.36052328]
[Epoch=300, n_hypersteps=3]: prior precision: [0.07310305 0.05466515 0.05725114 0.10452523], sigma noise: [0.37651628 0.38582784 0.38379    0.35522422]
[Epoch=300, n_hypersteps=4]: prior precision: [0.07290176 0.05409645 0.05676015 0.10496691], sigma noise: [0.37113786 0.38047454 0.37829933 0.3501016 ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.07273158 0.05354806 0.05629461 0.10542464], sigma noise: [0.36627916 0.375693   0.3733627  0.34542406]
/scratch/work/zhangx18/Reproduced-LA-NAM/LANAM/utils/plotting.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig_indiv, axs = plt.subplots(rows, cols, figsize=figsize)
[Epoch=300, n_hypersteps=6]: prior precision: [0.07258498 0.05301981 0.05585359 0.10590255], sigma noise: [0.36220148 0.3717566  0.36925778 0.34140924]
[Epoch=300, n_hypersteps=7]: prior precision: [0.07245803 0.05251158 0.05543506 0.10640141], sigma noise: [0.35908684 0.36886972 0.36617246 0.3382151 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.07235126 0.05202319 0.05503867 0.10691287], sigma noise: [0.35704395 0.36715046 0.3642243  0.33592972]
[Epoch=300, n_hypersteps=9]: prior precision: [0.07226282 0.05155686 0.05466115 0.10742731], sigma noise: [0.35610545 0.3666401  0.36344886 0.33457658]
[Epoch=300, n_hypersteps=10]: prior precision: [0.07219635 0.05111133 0.05430136 0.10794792], sigma noise: [0.356229   0.3673016  0.36380324 0.3341186 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.07214656 0.05068555 0.05396038 0.1084622 ], sigma noise: [0.35731143 0.3690263  0.36518288 0.33445898]
[Epoch=300, n_hypersteps=12]: prior precision: [0.07211752 0.05027959 0.05363479 0.10896698], sigma noise: [0.3591908  0.37163723 0.36741295 0.33545786]
[Epoch=300, n_hypersteps=13]: prior precision: [0.0721031  0.04989314 0.05332531 0.10946362], sigma noise: [0.36167008 0.37492678 0.3702842  0.3369402 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.0721002  0.04952477 0.05303107 0.10994866], sigma noise: [0.3645187  0.378647   0.37355182 0.33871788]
[Epoch=300, n_hypersteps=15]: prior precision: [0.07210781 0.04917451 0.05274986 0.11042437], sigma noise: [0.36749995 0.3825321  0.37696862 0.34058952]
[Epoch=300, n_hypersteps=16]: prior precision: [0.07212337 0.04884271 0.0524809  0.1108928 ], sigma noise: [0.37038353 0.38632533 0.3802893  0.3423737 ]
[Epoch=300, n_hypersteps=17]: prior precision: [0.07215004 0.04852689 0.05222687 0.11135828], sigma noise: [0.3729619  0.3898003  0.38329095 0.34390393]
[Epoch=300, n_hypersteps=18]: prior precision: [0.07218669 0.04822685 0.05198395 0.11181475], sigma noise: [0.3750748  0.39276105 0.38579765 0.34505728]
[Epoch=300, n_hypersteps=19]: prior precision: [0.0722286  0.04794337 0.0517519  0.11227158], sigma noise: [0.3766015  0.3950593  0.3876745  0.34573925]
[Epoch=300, n_hypersteps=20]: prior precision: [0.07227609 0.0476738  0.05153125 0.1127089 ], sigma noise: [0.37746996 0.39661437 0.3888507  0.34590483]
[Epoch=300, n_hypersteps=21]: prior precision: [0.07232903 0.04741869 0.05131992 0.11311839], sigma noise: [0.37767282 0.39740413 0.38931036 0.3455478 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.07238665 0.04717778 0.05111843 0.1135157 ], sigma noise: [0.37724632 0.3974657  0.38909104 0.34470263]
[Epoch=300, n_hypersteps=23]: prior precision: [0.07244824 0.04695014 0.05092565 0.11390723], sigma noise: [0.37627277 0.39688885 0.3882721  0.34343138]
[Epoch=300, n_hypersteps=24]: prior precision: [0.07251195 0.04673628 0.05074038 0.11430273], sigma noise: [0.37486762 0.39580637 0.38697815 0.34183127]
[Epoch=300, n_hypersteps=25]: prior precision: [0.07258171 0.04653464 0.05056373 0.1146732 ], sigma noise: [0.3731674  0.39437738 0.38536388 0.340009  ]
[Epoch=300, n_hypersteps=26]: prior precision: [0.07265268 0.04634394 0.05039488 0.11502849], sigma noise: [0.37131882 0.39277384 0.38359675 0.33808038]
[Epoch=300, n_hypersteps=27]: prior precision: [0.07272664 0.04616556 0.05023381 0.11537054], sigma noise: [0.3694658  0.39116916 0.38182488 0.33615673]
[Epoch=300, n_hypersteps=28]: prior precision: [0.07279907 0.04600027 0.05007887 0.11569312], sigma noise: [0.3677411  0.38971075 0.38019148 0.33433396]
[Epoch=300, n_hypersteps=29]: prior precision: [0.07287394 0.0458439  0.04993061 0.11601406], sigma noise: [0.3662585 0.3885329 0.378823  0.332697 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.0729468  0.04570036 0.04978593 0.11632352], sigma noise: [0.36509988 0.38773578 0.3778054  0.33131012]
[Epoch=400, n_hypersteps=1]: prior precision: [0.07302326 0.04555972 0.04964703 0.11662222], sigma noise: [0.3640635  0.38708672 0.37692502 0.33001894]
[Epoch=400, n_hypersteps=2]: prior precision: [0.07310461 0.04542261 0.04951587 0.11692862], sigma noise: [0.36320594 0.38665816 0.3762438  0.32886866]
[Epoch=400, n_hypersteps=3]: prior precision: [0.07318583 0.04528617 0.04939125 0.11724941], sigma noise: [0.36257467 0.3865012  0.37579933 0.3278893 ]
[Epoch=400, n_hypersteps=4]: prior precision: [0.07327003 0.04515364 0.04927283 0.11756905], sigma noise: [0.36218762 0.38663843 0.37561148 0.3270941 ]
[Epoch=400, n_hypersteps=5]: prior precision: [0.07335575 0.04502536 0.04915938 0.11788049], sigma noise: [0.36204267 0.38707197 0.37570047 0.32648215]
[Epoch=400, n_hypersteps=6]: prior precision: [0.07343998 0.04490214 0.04904806 0.11819924], sigma noise: [0.3621199  0.38778666 0.37604278 0.32604113]
[Epoch=400, n_hypersteps=7]: prior precision: [0.07352638 0.04478496 0.04894163 0.11851588], sigma noise: [0.36238614 0.38873488 0.3765862  0.32573885]
[Epoch=400, n_hypersteps=8]: prior precision: [0.07361563 0.04467249 0.04883849 0.11881527], sigma noise: [0.3627913  0.38985837 0.37728274 0.32554677]
[Epoch=400, n_hypersteps=9]: prior precision: [0.07370829 0.04456426 0.04873669 0.1191005 ], sigma noise: [0.3632788  0.39108998 0.3780836  0.3254197 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.07380314 0.0444616  0.0486384  0.11938053], sigma noise: [0.36379412 0.39235714 0.37891018 0.32531545]
[Epoch=400, n_hypersteps=11]: prior precision: [0.0738961  0.044364   0.04854483 0.11964533], sigma noise: [0.36428156 0.39359462 0.3797134  0.32519287]
[Epoch=400, n_hypersteps=12]: prior precision: [0.07398713 0.04427172 0.04845396 0.11991588], sigma noise: [0.36469316 0.39473745 0.38043135 0.3250179 ]
[Epoch=400, n_hypersteps=13]: prior precision: [0.07407626 0.04418364 0.04836527 0.12017682], sigma noise: [0.3649897  0.39574262 0.38102314 0.3247689 ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.07416386 0.04409997 0.04828202 0.12041973], sigma noise: [0.3651511  0.39657393 0.38145825 0.32442147]
[Epoch=400, n_hypersteps=15]: prior precision: [0.07424876 0.0440204  0.04820105 0.12064235], sigma noise: [0.36516455 0.39720798 0.38171354 0.32396844]
[Epoch=400, n_hypersteps=16]: prior precision: [0.0743277  0.0439437  0.04812308 0.12084086], sigma noise: [0.36502963 0.39764482 0.3817932  0.32341638]
[Epoch=400, n_hypersteps=17]: prior precision: [0.07440548 0.04386977 0.04804715 0.12103512], sigma noise: [0.36476547 0.3979027  0.3817247  0.32277504]
[Epoch=400, n_hypersteps=18]: prior precision: [0.07448168 0.04380055 0.04797617 0.12121636], sigma noise: [0.3643889  0.3980168  0.38152874 0.32206446]
[Epoch=400, n_hypersteps=19]: prior precision: [0.07456044 0.04373562 0.04790837 0.121392  ], sigma noise: [0.36394355 0.39802402 0.38124937 0.32130826]
[Epoch=400, n_hypersteps=20]: prior precision: [0.07464082 0.04367357 0.04784231 0.12153906], sigma noise: [0.3634605  0.397977   0.38092357 0.32052794]
[Epoch=400, n_hypersteps=21]: prior precision: [0.07471617 0.0436157  0.04777763 0.12166488], sigma noise: [0.3629763  0.39791664 0.38058913 0.3197469 ]
[Epoch=400, n_hypersteps=22]: prior precision: [0.07478726 0.04356179 0.04771396 0.12177211], sigma noise: [0.3625181  0.3978908  0.38029012 0.318993  ]
[Epoch=400, n_hypersteps=23]: prior precision: [0.07485778 0.04351132 0.04765248 0.12187455], sigma noise: [0.36211458 0.39793217 0.3800602  0.3182809 ]
[Epoch=400, n_hypersteps=24]: prior precision: [0.07492286 0.04346341 0.04759456 0.12194634], sigma noise: [0.36178872 0.39807233 0.37991884 0.31762478]
[Epoch=400, n_hypersteps=25]: prior precision: [0.07498597 0.04341827 0.0475365  0.12201146], sigma noise: [0.36154974 0.39831814 0.37987778 0.31703427]
[Epoch=400, n_hypersteps=26]: prior precision: [0.07504939 0.04337664 0.04747875 0.12206875], sigma noise: [0.3613992  0.3986834  0.3799405  0.31651166]
[Epoch=400, n_hypersteps=27]: prior precision: [0.07511021 0.04333803 0.04742083 0.12213314], sigma noise: [0.36133325 0.39915743 0.3801099  0.31605458]
[Epoch=400, n_hypersteps=28]: prior precision: [0.07516286 0.0433034  0.04736434 0.12216311], sigma noise: [0.36134416 0.39972547 0.3803554  0.3156509 ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.207 MB of 0.207 MB uploaded (0.000 MB deduped)wandb: \ 0.207 MB of 0.296 MB uploaded (0.000 MB deduped)wandb: | 0.296 MB of 0.296 MB uploaded (0.000 MB deduped)wandb: / 0.296 MB of 0.296 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.5288
wandb:                       Metrics 0.52594
wandb:  Negative_marginal_likelihood 1195.92944
wandb: Predictive_posterior_std_mean 0.73348
wandb:                   Sigma_noise 0.73159
wandb: 
wandb: üöÄ View run fearless-sweep-3 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/lyfgdu6n
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165909-lyfgdu6n/logs
wandb: Agent Starting Run: 5exp7oqf with config:
wandb: 	activation_cls: gelu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_170022-5exp7oqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/5exp7oqf
[Epoch=400, n_hypersteps=29]: prior precision: [0.07521211 0.04327039 0.04731127 0.12218009], sigma noise: [0.36141443 0.4003596  0.38066348 0.31528747]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='gelu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.81906176 0.8190623  0.81905395 0.81906384], sigma noise: [0.8188589  0.8188601  0.81885886 0.8188578 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74191314 0.7419154  0.74188673 0.7419202 ], sigma noise: [0.7412965  0.74130106 0.74129635 0.7412923 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.67265236 0.67265797 0.6725947  0.6726679 ], sigma noise: [0.6714809  0.6714921  0.6714806  0.67147076]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6105692 0.6105803 0.6104669 0.610597 ], sigma noise: [0.6088448  0.6088677  0.6088443  0.60882485]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55498856 0.55500805 0.554828   0.55503285], sigma noise: [0.552932  0.5529739 0.552931  0.5528966]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50527596 0.5053069  0.50504416 0.5053412 ], sigma noise: [0.503413   0.50348467 0.5034108  0.50335413]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46084058 0.46088615 0.46052524 0.46093094], sigma noise: [0.46010685 0.46022424 0.46010223 0.46001253]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42113653 0.42119998 0.42072657 0.42125645], sigma noise: [0.42300162 0.42318827 0.42299205 0.42285398]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38566366 0.38574782 0.38514894 0.38581815], sigma noise: [0.39224887 0.39253792 0.3922307  0.39202228]
[Epoch=100, n_hypersteps=11]: prior precision: [0.3539668  0.3540739  0.35333773 0.35416016], sigma noise: [0.36808515 0.3685221  0.36805248 0.36774483]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32563275 0.32576472 0.32488236 0.32586986], sigma noise: [0.3506517  0.3512908  0.3505972  0.35015497]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30028996 0.30044815 0.29941213 0.30057466], sigma noise: [0.33978033 0.34068057 0.33969662 0.33908153]
[Epoch=100, n_hypersteps=14]: prior precision: [0.27760512 0.27778992 0.2765947  0.27794087], sigma noise: [0.33492813 0.3361476  0.33480647 0.33398095]
[Epoch=100, n_hypersteps=15]: prior precision: [0.25727975 0.25749114 0.2561337  0.2576697 ], sigma noise: [0.3353081  0.33690515 0.33514097 0.33406705]
[Epoch=100, n_hypersteps=16]: prior precision: [0.23904851 0.23928611 0.23776467 0.23949458], sigma noise: [0.3400789  0.34211344 0.33985785 0.33849552]
[Epoch=100, n_hypersteps=17]: prior precision: [0.22267522 0.2229383  0.22125249 0.22317882], sigma noise: [0.34844533 0.3509836  0.34816235 0.34646815]
[Epoch=100, n_hypersteps=18]: prior precision: [0.20795058 0.20823807 0.20638885 0.20851205], sigma noise: [0.35967094 0.36278576 0.359317   0.3572439 ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.1946895  0.19499993 0.19298948 0.195309  ], sigma noise: [0.37304634 0.37681463 0.3726116  0.3701099 ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.1827282  0.18306087 0.18089108 0.18340565], sigma noise: [0.3878521  0.39235136 0.387327   0.38434848]
[Epoch=100, n_hypersteps=21]: prior precision: [0.1719222  0.17227635 0.16994992 0.17265704], sigma noise: [0.40334317 0.4086428  0.4027181  0.39922082]
[Epoch=100, n_hypersteps=22]: prior precision: [0.1621439  0.16251877 0.16003843 0.16293567], sigma noise: [0.4187549  0.42490777 0.41802385 0.41397616]
[Epoch=100, n_hypersteps=23]: prior precision: [0.15328093 0.15367591 0.15104443 0.15412824], sigma noise: [0.4333373  0.440369   0.43249732 0.42788687]
[Epoch=100, n_hypersteps=24]: prior precision: [0.1452342  0.14564829 0.14286873 0.14613605], sigma noise: [0.4463993  0.45430017 0.4454524  0.44028932]
[Epoch=100, n_hypersteps=25]: prior precision: [0.13791598 0.13834842 0.13542388 0.13887164], sigma noise: [0.45735952 0.46607926 0.4563119  0.45063218]
[Epoch=100, n_hypersteps=26]: prior precision: [0.13124938 0.13169916 0.1286329  0.13225771], sigma noise: [0.4657871  0.4752385  0.46465012 0.45851144]
[Epoch=100, n_hypersteps=27]: prior precision: [0.12516569 0.12563275 0.12242728 0.12622644], sigma noise: [0.4714257  0.48148978 0.47021392 0.46369478]
[Epoch=100, n_hypersteps=28]: prior precision: [0.11960531 0.12008892 0.11674669 0.12071825], sigma noise: [0.4741998 0.4847377 0.4729311 0.4661214]
[Epoch=100, n_hypersteps=29]: prior precision: [0.11451479 0.11501464 0.11153764 0.11567936], sigma noise: [0.47420222 0.48506725 0.47289482 0.46589053]
[Epoch=200, n_hypersteps=0]: prior precision: [0.10984692 0.11036249 0.10675278 0.11106243], sigma noise: [0.4716702  0.48272017 0.47034252 0.4632335 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.10556372 0.10606938 0.10232909 0.10693109], sigma noise: [0.46599805 0.47706416 0.46472964 0.45757547]
[Epoch=200, n_hypersteps=2]: prior precision: [0.10162745 0.10210367 0.09823494 0.10322578], sigma noise: [0.45777094 0.46871477 0.45662746 0.44947636]
[Epoch=200, n_hypersteps=3]: prior precision: [0.09800459 0.09843682 0.09444162 0.09989534], sigma noise: [0.44763467 0.45835492 0.44666645 0.43955106]
[Epoch=200, n_hypersteps=4]: prior precision: [0.09466525 0.09504301 0.09092309 0.09689608], sigma noise: [0.43625325 0.4466896  0.4354977  0.42843223]
[Epoch=200, n_hypersteps=5]: prior precision: [0.09158311 0.09189896 0.08765573 0.09419026], sigma noise: [0.4242761  0.43440717 0.42375907 0.41673875]
[Epoch=200, n_hypersteps=6]: prior precision: [0.08873435 0.08898351 0.08461802 0.09174499], sigma noise: [0.4123136  0.42215636 0.4120536  0.40505183]
[Epoch=200, n_hypersteps=7]: prior precision: [0.08609757 0.08627751 0.0817906  0.08953192], sigma noise: [0.40091932 0.4105237  0.40092817 0.39389867]
[Epoch=200, n_hypersteps=8]: prior precision: [0.08365352 0.0837635  0.07915594 0.08752642], sigma noise: [0.39057198 0.40001866 0.3908596  0.38373658]
[Epoch=200, n_hypersteps=9]: prior precision: [0.08138545 0.0814257  0.07669787 0.08570658], sigma noise: [0.3816648  0.39106074 0.38224354 0.37494162]
[Epoch=200, n_hypersteps=10]: prior precision: [0.07927804 0.07924969 0.07440226 0.08405357], sigma noise: [0.3744945  0.38396874 0.3753821  0.36779743]
[Epoch=200, n_hypersteps=11]: prior precision: [0.07731746 0.07722222 0.0722556  0.08255031], sigma noise: [0.36925387 0.37894893 0.37047178 0.36248547]
[Epoch=200, n_hypersteps=12]: prior precision: [0.07549114 0.0753312  0.07024588 0.08118177], sigma noise: [0.36602676 0.37609798 0.3676006  0.35908347]
[Epoch=200, n_hypersteps=13]: prior precision: [0.07378775 0.07356592 0.06836218 0.079935  ], sigma noise: [0.36479115 0.37540093 0.36675435 0.35756466]
[Epoch=200, n_hypersteps=14]: prior precision: [0.07219721 0.07191638 0.06659441 0.07879842], sigma noise: [0.3654251  0.3767386  0.367818   0.35781062]
[Epoch=200, n_hypersteps=15]: prior precision: [0.07070994 0.07037333 0.06493346 0.07776161], sigma noise: [0.36772186 0.37990353 0.37058976 0.3596189 ]
[Epoch=200, n_hypersteps=16]: prior precision: [0.0693175  0.06892858 0.06337083 0.07681492], sigma noise: [0.37140703 0.3846089  0.37479886 0.36272016]
[Epoch=200, n_hypersteps=17]: prior precision: [0.06801209 0.06757425 0.06189902 0.07595047], sigma noise: [0.37614924 0.3905086  0.38011426 0.36679712]
[Epoch=200, n_hypersteps=18]: prior precision: [0.06678651 0.06630307 0.06051107 0.0751606 ], sigma noise: [0.38158208 0.3972121  0.38616496 0.37150076]
[Epoch=200, n_hypersteps=19]: prior precision: [0.06563468 0.06510875 0.05920076 0.07443848], sigma noise: [0.38732606 0.40430382 0.39256045 0.37647274]
[Epoch=200, n_hypersteps=20]: prior precision: [0.06455069 0.06398544 0.05796224 0.07377788], sigma noise: [0.39300197 0.41136324 0.3989114  0.3813609 ]
[Epoch=200, n_hypersteps=21]: prior precision: [0.06352942 0.06292754 0.05679009 0.07317318], sigma noise: [0.3982626  0.41799363 0.4048523  0.3858454 ]
[Epoch=200, n_hypersteps=22]: prior precision: [0.06256615 0.06193044 0.0556794  0.07261986], sigma noise: [0.4028053  0.42384392 0.41006553 0.38965347]
[Epoch=200, n_hypersteps=23]: prior precision: [0.06165625 0.06098983 0.05462576 0.07211305], sigma noise: [0.40639347 0.42863092 0.4142947  0.3925756 ]
[Epoch=200, n_hypersteps=24]: prior precision: [0.06079619 0.06010145 0.05362519 0.07164896], sigma noise: [0.4088698  0.43215618 0.4173636  0.3944751 ]
[Epoch=200, n_hypersteps=25]: prior precision: [0.05998229 0.05926177 0.0526741  0.07122396], sigma noise: [0.41016144 0.43431783 0.41918576 0.39529088]
[Epoch=200, n_hypersteps=26]: prior precision: [0.05921122 0.05846715 0.05176879 0.0708347 ], sigma noise: [0.4102741  0.43511114 0.41976222 0.39503697]
[Epoch=200, n_hypersteps=27]: prior precision: [0.05847992 0.05771482 0.05090635 0.07047834], sigma noise: [0.40929237 0.43462232 0.41917244 0.39379343]
[Epoch=200, n_hypersteps=28]: prior precision: [0.05778574 0.05700191 0.05008405 0.07015185], sigma noise: [0.40736014 0.43301663 0.41756916 0.39169702]
[Epoch=200, n_hypersteps=29]: prior precision: [0.05712612 0.05632584 0.04929941 0.06985327], sigma noise: [0.40467286 0.43051648 0.41515377 0.38892242]
[Epoch=300, n_hypersteps=0]: prior precision: [0.0564991  0.05568416 0.04854991 0.06958032], sigma noise: [0.4014553  0.42738593 0.41216612 0.38567376]
[Epoch=300, n_hypersteps=1]: prior precision: [0.0558771  0.0550576  0.04784368 0.06937947], sigma noise: [0.39651093 0.42217022 0.4073053  0.3808759 ]
[Epoch=300, n_hypersteps=2]: prior precision: [0.05526166 0.0544466  0.04717726 0.06924406], sigma noise: [0.3903065  0.41542995 0.4010736  0.37494823]
[Epoch=300, n_hypersteps=3]: prior precision: [0.05465417 0.05385149 0.04654741 0.06916866], sigma noise: [0.38334328 0.40776864 0.39400938 0.36833724]
[Epoch=300, n_hypersteps=4]: prior precision: [0.05405574 0.05327261 0.0459513  0.06914818], sigma noise: [0.37612182 0.3997866  0.3866536  0.36148962]
[Epoch=300, n_hypersteps=5]: prior precision: [0.05346725 0.05271015 0.04538647 0.06917839], sigma noise: [0.36910936 0.392046   0.37951505 0.35482386]
[Epoch=300, n_hypersteps=6]: prior precision: [0.0528896  0.05216409 0.04485071 0.06925491], sigma noise: [0.3627175  0.38503876 0.3730411  0.3487107 ]
[Epoch=300, n_hypersteps=7]: prior precision: [0.05232343 0.05163451 0.04434181 0.06937428], sigma noise: [0.3572854  0.3791642  0.36760125 0.3434531 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.05176941 0.05112142 0.04385782 0.06953306], sigma noise: [0.35306254 0.37471664 0.36346686 0.33927488]
[Epoch=300, n_hypersteps=9]: prior precision: [0.05122799 0.05062464 0.04339692 0.06972852], sigma noise: [0.35020113 0.37187827 0.36080757 0.33631077]
[Epoch=300, n_hypersteps=10]: prior precision: [0.05069953 0.05014393 0.04295739 0.06995769], sigma noise: [0.34875354 0.37071347 0.35968617 0.33460537]
[Epoch=300, n_hypersteps=11]: prior precision: [0.05018397 0.04967888 0.04253801 0.07021762], sigma noise: [0.34867626 0.37117815 0.36006415 0.33411554]
[Epoch=300, n_hypersteps=12]: prior precision: [0.04968143 0.04922917 0.04213745 0.07050627], sigma noise: [0.34984004 0.37312618 0.36180606 0.33472058]
[Epoch=300, n_hypersteps=13]: prior precision: [0.04919207 0.04879425 0.04175408 0.07082131], sigma noise: [0.35204422 0.3763308  0.36470172 0.3362355 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.04871583 0.0483737  0.04138687 0.07116076], sigma noise: [0.3550324  0.3804946  0.36847296 0.3384293 ]
[Epoch=300, n_hypersteps=15]: prior precision: [0.0482525  0.04796698 0.04103475 0.07152219], sigma noise: [0.35851482 0.38527688 0.3728043  0.34104174]
[Epoch=300, n_hypersteps=16]: prior precision: [0.047802   0.04757355 0.04069658 0.07190393], sigma noise: [0.36218795 0.3903138  0.3773627  0.34380654]
[Epoch=300, n_hypersteps=17]: prior precision: [0.0473641  0.04719289 0.0403715  0.0723041 ], sigma noise: [0.36576304 0.39524427 0.38181806 0.3464695 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.04693852 0.04682467 0.0400589  0.07272078], sigma noise: [0.36897433 0.39973915 0.3858699  0.34880593]
[Epoch=300, n_hypersteps=19]: prior precision: [0.04652481 0.04646831 0.03975796 0.07315263], sigma noise: [0.37160435 0.40352023 0.3892664  0.3506367 ]
[Epoch=300, n_hypersteps=20]: prior precision: [0.04612302 0.04612342 0.03946776 0.07359833], sigma noise: [0.3734996  0.40638202 0.3918248  0.3518359 ]
[Epoch=300, n_hypersteps=21]: prior precision: [0.04573279 0.04578974 0.03918757 0.07405686], sigma noise: [0.37457314 0.40820557 0.39343938 0.35233694]
[Epoch=300, n_hypersteps=22]: prior precision: [0.04535395 0.04546684 0.03891671 0.07452701], sigma noise: [0.3748106  0.40896103 0.39408556 0.3521316 ]
[Epoch=300, n_hypersteps=23]: prior precision: [0.04498639 0.04515435 0.03865507 0.07500751], sigma noise: [0.37425846 0.40870488 0.39381438 0.35126564]
[Epoch=300, n_hypersteps=24]: prior precision: [0.04462987 0.04485197 0.038402   0.07549757], sigma noise: [0.37302336 0.40756702 0.3927446  0.34982932]
[Epoch=300, n_hypersteps=25]: prior precision: [0.04428418 0.04455946 0.03815692 0.0759964 ], sigma noise: [0.37125194 0.40573406 0.3910432  0.34794837]
[Epoch=300, n_hypersteps=26]: prior precision: [0.04394918 0.04427669 0.03791938 0.07650282], sigma noise: [0.36912113 0.40343016 0.38891688 0.34577012]
[Epoch=300, n_hypersteps=27]: prior precision: [0.04362484 0.04400355 0.03768903 0.07701583], sigma noise: [0.36681753 0.40090024 0.3865845  0.34345055]
[Epoch=300, n_hypersteps=28]: prior precision: [0.04331061 0.04373981 0.03746572 0.07753505], sigma noise: [0.3645246  0.39837986 0.3842586  0.34114158]
[Epoch=300, n_hypersteps=29]: prior precision: [0.04300651 0.04348512 0.03724912 0.07805952], sigma noise: [0.362408   0.3960838  0.38213646 0.33898073]
[Epoch=400, n_hypersteps=0]: prior precision: [0.04271222 0.04323943 0.03703886 0.0785889 ], sigma noise: [0.36060652 0.39418924 0.38037843 0.33708197]
[Epoch=400, n_hypersteps=1]: prior precision: [0.04239109 0.04299719 0.03683687 0.07918178], sigma noise: [0.35926673 0.3928668  0.37912974 0.33556902]
[Epoch=400, n_hypersteps=2]: prior precision: [0.04204735 0.04275877 0.03664272 0.07983387], sigma noise: [0.35844374 0.39218992 0.37845528 0.33448577]
[Epoch=400, n_hypersteps=3]: prior precision: [0.04168499 0.04252444 0.03645605 0.08054108], sigma noise: [0.35814932 0.3921762  0.37837356 0.3338395 ]
[Epoch=400, n_hypersteps=4]: prior precision: [0.04130757 0.04229447 0.03627623 0.08129979], sigma noise: [0.3583538  0.39278972 0.37885225 0.33360332]
[Epoch=400, n_hypersteps=5]: prior precision: [0.04091843 0.04206898 0.03610288 0.08210675], sigma noise: [0.35899118 0.39394912 0.3798187  0.33372095]
[Epoch=400, n_hypersteps=6]: prior precision: [0.04052037 0.04184814 0.03593573 0.08295892], sigma noise: [0.35996592 0.39553556 0.381163   0.33411437]
[Epoch=400, n_hypersteps=7]: prior precision: [0.04011603 0.04163211 0.03577437 0.08385351], sigma noise: [0.36116657 0.3974055  0.3827559  0.33469066]
[Epoch=400, n_hypersteps=8]: prior precision: [0.03970772 0.04142084 0.03561839 0.08478779], sigma noise: [0.36247304 0.39940128 0.3844576  0.33535206]
[Epoch=400, n_hypersteps=9]: prior precision: [0.03929752 0.04121432 0.03546751 0.08575933], sigma noise: [0.3637662  0.40136805 0.38612673 0.33600372]
[Epoch=400, n_hypersteps=10]: prior precision: [0.03888719 0.04101267 0.03532144 0.08676581], sigma noise: [0.3649412  0.4031639  0.38763583 0.33656082]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.184 MB of 0.297 MB uploaded (0.000 MB deduped)wandb: \ 0.184 MB of 0.297 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.54526
wandb:                       Metrics 0.54095
wandb:  Negative_marginal_likelihood 1227.40515
wandb: Predictive_posterior_std_mean 0.74662
wandb:                   Sigma_noise 0.74419
wandb: 
wandb: üöÄ View run northern-sweep-4 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/5exp7oqf
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_170022-5exp7oqf/logs
wandb: Agent Starting Run: 1yf5q0xh with config:
wandb: 	activation_cls: gelu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_172009-1yf5q0xh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/2qal8f2u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/1yf5q0xh
[Epoch=400, n_hypersteps=11]: prior precision: [0.03847845 0.04081588 0.03517985 0.08780511], sigma noise: [0.36590883 0.40467125 0.38887706 0.3369542 ]
[Epoch=400, n_hypersteps=12]: prior precision: [0.03807266 0.04062391 0.03504242 0.08887513], sigma noise: [0.36660776 0.40580514 0.38978133 0.337137  ]
[Epoch=400, n_hypersteps=13]: prior precision: [0.03767109 0.04043675 0.0349091  0.08997399], sigma noise: [0.36700362 0.40652013 0.39030802 0.337085  ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.03727497 0.04025445 0.03477967 0.09109998], sigma noise: [0.36709127 0.40680927 0.3904516  0.33679506]
[Epoch=400, n_hypersteps=15]: prior precision: [0.03688531 0.04007697 0.03465388 0.09225131], sigma noise: [0.36689398 0.40670204 0.39024016 0.3362862 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.03650284 0.03990417 0.03453156 0.09342632], sigma noise: [0.3664562  0.40625873 0.38972688 0.3355942 ]
[Epoch=400, n_hypersteps=17]: prior precision: [0.03612833 0.03973626 0.03441232 0.09462371], sigma noise: [0.3658408  0.40556598 0.38898814 0.33476782]
[Epoch=400, n_hypersteps=18]: prior precision: [0.03576207 0.03957309 0.034296   0.09584222], sigma noise: [0.36511812 0.40472108 0.3881131  0.3338636 ]
[Epoch=400, n_hypersteps=19]: prior precision: [0.03540483 0.0394147  0.03418266 0.09708026], sigma noise: [0.3643646  0.4038276  0.38719475 0.33294034]
[Epoch=400, n_hypersteps=20]: prior precision: [0.03505693 0.03926105 0.03407218 0.09833661], sigma noise: [0.36365283 0.40298188 0.38632128 0.3320525 ]
[Epoch=400, n_hypersteps=21]: prior precision: [0.03471851 0.03911201 0.03396454 0.09960987], sigma noise: [0.36304593 0.40226853 0.3855645  0.33124816]
[Epoch=400, n_hypersteps=22]: prior precision: [0.03438977 0.03896762 0.0338597  0.10089897], sigma noise: [0.3625923  0.40175313 0.38498443 0.33056387]
[Epoch=400, n_hypersteps=23]: prior precision: [0.03407087 0.03882775 0.03375731 0.10220236], sigma noise: [0.362322   0.401477   0.38461682 0.33002216]
[Epoch=400, n_hypersteps=24]: prior precision: [0.03376173 0.03869243 0.03365741 0.10351897], sigma noise: [0.36224702 0.40145802 0.3844759  0.32963184]
[Epoch=400, n_hypersteps=25]: prior precision: [0.03346238 0.03856155 0.03356008 0.10484756], sigma noise: [0.36236086 0.40168846 0.38455456 0.32938802]
[Epoch=400, n_hypersteps=26]: prior precision: [0.03317307 0.0384349  0.0334649  0.10618696], sigma noise: [0.3626446  0.4021403  0.3848261  0.32927307]
[Epoch=400, n_hypersteps=27]: prior precision: [0.03289335 0.03831249 0.03337176 0.10753604], sigma noise: [0.3630642  0.40276596 0.38525248 0.32925972]
[Epoch=400, n_hypersteps=28]: prior precision: [0.03262319 0.03819417 0.03328071 0.10889328], sigma noise: [0.36357394 0.40350723 0.385778   0.329315  ]
[Epoch=400, n_hypersteps=29]: prior precision: [0.03236242 0.03807977 0.03319166 0.11025774], sigma noise: [0.36412695 0.40430132 0.3863514  0.3294033 ]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='gelu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8190852  0.81909055 0.8190633  0.8194152 ], sigma noise: [0.8188354  0.81883657 0.81883526 0.8188335 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74199355 0.7420125  0.74191856 0.74314946], sigma noise: [0.74120617 0.7412105  0.74120575 0.74119914]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6728301  0.67287326 0.67266464 0.67543495], sigma noise: [0.67125446 0.6712651  0.6712538  0.67123777]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6108876  0.61096805 0.610592   0.6156577 ], sigma noise: [0.6083771 0.6083987 0.6083763 0.6083443]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55549234 0.55562466 0.5550263  0.5631944 ], sigma noise: [0.5520659  0.5521052  0.55206585 0.55200845]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50600886 0.5062083  0.50533336 0.5174337 ], sigma noise: [0.5019163 0.5019829 0.5019183 0.5018217]
[Epoch=100, n_hypersteps=8]: prior precision: [0.4618439  0.46212554 0.46092305 0.4777832 ], sigma noise: [0.45763993 0.4577476  0.4576458  0.45749024]
[Epoch=100, n_hypersteps=9]: prior precision: [0.4224483  0.4228265  0.4212495  0.44366252], sigma noise: [0.41908097 0.4192497  0.4190941  0.41885003]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38731754 0.38780537 0.3858125  0.41454297], sigma noise: [0.38622743 0.38648608 0.38625178 0.38587707]
[Epoch=100, n_hypersteps=11]: prior precision: [0.3559932  0.3566006  0.35415584 0.38993117], sigma noise: [0.35919315 0.3595821  0.35923478 0.35866943]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32805726 0.3287933  0.32586625 0.36934972], sigma noise: [0.33813694 0.33870903 0.33820406 0.337369  ]
[Epoch=100, n_hypersteps=13]: prior precision: [0.3031356  0.30400562 0.30057204 0.35239258], sigma noise: [0.323109   0.32392675 0.32321015 0.3220115 ]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28088942 0.28189778 0.27793834 0.3386803 ], sigma noise: [0.31389678 0.31502712 0.31404224 0.3123768 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26101688 0.26216564 0.2576664  0.32787782], sigma noise: [0.3099953  0.3115066  0.31019473 0.30795828]
[Epoch=100, n_hypersteps=16]: prior precision: [0.24324898 0.24453884 0.23949015 0.31967187], sigma noise: [0.31072134 0.31268263 0.3109826  0.30807158]
[Epoch=100, n_hypersteps=17]: prior precision: [0.22734453 0.228777   0.2231732  0.31379944], sigma noise: [0.31535414 0.31783825 0.31568754 0.3119911 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.2130932  0.21466756 0.20850599 0.31001616], sigma noise: [0.32321033 0.32629606 0.32362574 0.31902438]
[Epoch=100, n_hypersteps=19]: prior precision: [0.20030636 0.20202103 0.19530201 0.3081258 ], sigma noise: [0.33364886 0.3374233  0.33415824 0.32852155]
[Epoch=100, n_hypersteps=20]: prior precision: [0.18881851 0.19067271 0.1833976  0.3079297 ], sigma noise: [0.34604624 0.35060185 0.3466614  0.33985293]
[Epoch=100, n_hypersteps=21]: prior precision: [0.17848298 0.18047595 0.1726471  0.30927318], sigma noise: [0.35976854 0.3651973  0.3605012  0.35238558]
[Epoch=100, n_hypersteps=22]: prior precision: [0.16917163 0.17130256 0.16292354 0.31200248], sigma noise: [0.37415692 0.38054198 0.37501782 0.36547375]
[Epoch=100, n_hypersteps=23]: prior precision: [0.16077232 0.16303897 0.1541138  0.31597623], sigma noise: [0.3885363  0.39593962 0.38953242 0.3784688 ]
[Epoch=100, n_hypersteps=24]: prior precision: [0.15318647 0.1555859  0.14611953 0.32108015], sigma noise: [0.4022381  0.41069168 0.40337414 0.39074588]
[Epoch=100, n_hypersteps=25]: prior precision: [0.14632493 0.14885595 0.13885297 0.3271698 ], sigma noise: [0.41464302 0.42413682 0.4159174  0.4017391 ]
[Epoch=100, n_hypersteps=26]: prior precision: [0.14010985 0.1427719  0.13223706 0.33411825], sigma noise: [0.42522007 0.43569833 0.42662555 0.41097757]
[Epoch=100, n_hypersteps=27]: prior precision: [0.13447268 0.13726673 0.12620388 0.34180707], sigma noise: [0.43356356 0.44492596 0.43508813 0.418114  ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.12935473 0.13228048 0.12069275 0.35008976], sigma noise: [0.4394168  0.4515247  0.44104233 0.4229397 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.12470295 0.12776041 0.11565007 0.35882705], sigma noise: [0.44267997 0.4553684  0.4443848  0.42538744]
slurmstepd: error: *** STEP 21146168.0 ON csl48 CANCELLED AT 2023-08-15T18:00:58 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 21146168 ON csl48 CANCELLED AT 2023-08-15T18:00:58 DUE TO TIME LIMIT ***
