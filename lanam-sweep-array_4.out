wandb: Currently logged in as: xinyu-zhang. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165601-ov8496vk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-pond-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/ov8496vk
wandb: \ 1 of 3 files downloaded...wandb:   3 of 3 files downloaded.  
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: üöÄ View run solar-pond-118 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/ov8496vk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165601-ov8496vk/logs
wandb: Agent Starting Run: 27k6wax3 with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165641-27k6wax3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/27k6wax3
Create sweep with ID: i1thic1u
Sweep URL: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 1.1051708], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.81912804 0.8190907  0.8190898  1.2211087 ], sigma noise: [0.81882584 0.81882566 0.81882775 0.818823  ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74214464 0.7420135  0.7420112  1.3485405 ], sigma noise: [0.7411698  0.74116904 0.7411766  0.7411593 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6731725  0.67287606 0.67287266 1.4879966 ], sigma noise: [0.6711642  0.6711619  0.67117995 0.671139  ]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6115174 0.6109735 0.6109705 1.6396326], sigma noise: [0.60819244 0.6081872  0.6082225  0.6081427 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5565138  0.5556329  0.55563337 1.8029653 ], sigma noise: [0.5517277 0.5517174 0.5517791 0.5516398]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50752974 0.5062187  0.5062273  1.9764875 ], sigma noise: [0.5013382  0.5013196  0.50142044 0.50119305]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46397206 0.4621365  0.46215993 2.157188  ], sigma noise: [0.45669675 0.45666498 0.4568228  0.45646733]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42528877 0.42283538 0.42288223 2.340031  ], sigma noise: [0.41759413 0.4175422  0.41778252 0.41724175]
[Epoch=100, n_hypersteps=10]: prior precision: [0.39097053 0.38780877 0.38788942 2.5176725 ], sigma noise: [0.38395166 0.3838694  0.38422865 0.38342056]
[Epoch=100, n_hypersteps=11]: prior precision: [0.3605508  0.35659465 0.356721   2.6808107 ], sigma noise: [0.3558172  0.35569033 0.35622025 0.35502845]
[Epoch=100, n_hypersteps=12]: prior precision: [0.3336036  0.32877403 0.3289589  2.8195014 ], sigma noise: [0.33331802 0.33312753 0.3338977  0.33216506]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30974558 0.3039693  0.30422452 2.9252605 ], sigma noise: [0.3165473  0.3162696  0.31736624 0.31489718]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28862852 0.2818414  0.2821791  2.993028  ], sigma noise: [0.30541456 0.3050233  0.30654383 0.30311638]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26994047 0.26208737 0.26251772 3.0219872 ], sigma noise: [0.29956222 0.29902974 0.3010761  0.2964576 ]
[Epoch=100, n_hypersteps=16]: prior precision: [0.25340417 0.24443725 0.24496947 3.0151055 ], sigma noise: [0.29841688 0.2977151  0.30039126 0.2943447 ]
[Epoch=100, n_hypersteps=17]: prior precision: [0.23876892 0.22865126 0.22929107 2.977914  ], sigma noise: [0.3013168  0.30041635 0.30383024 0.29610977]
[Epoch=100, n_hypersteps=18]: prior precision: [0.2258148  0.21451683 0.21526882 2.9172218 ], sigma noise: [0.30760956 0.30647874 0.31074733 0.30108818]
[Epoch=100, n_hypersteps=19]: prior precision: [0.21434666 0.20184615 0.20271271 2.8401093 ], sigma noise: [0.31668386 0.31528732 0.32053924 0.30865237]
[Epoch=100, n_hypersteps=20]: prior precision: [0.20419404 0.19047342 0.19145447 2.7532725 ], sigma noise: [0.32795468 0.32625428 0.3326293  0.3182035 ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.19520348 0.18025258 0.18134622 2.662653  ], sigma noise: [0.3408362  0.33879203 0.34643683 0.32915094]
[Epoch=100, n_hypersteps=22]: prior precision: [0.1872438  0.17105499 0.17225863 2.5732536 ], sigma noise: [0.35472098 0.35229424 0.36135042 0.34089875]
[Epoch=100, n_hypersteps=23]: prior precision: [0.1801989  0.16276754 0.1640774  2.48909   ], sigma noise: [0.36897567 0.3661326  0.37672207 0.35284775]
[Epoch=100, n_hypersteps=24]: prior precision: [0.17396724 0.15529075 0.1567018  2.4132075 ], sigma noise: [0.38295603 0.3796729  0.3918808  0.36441293]
[Epoch=100, n_hypersteps=25]: prior precision: [0.16846089 0.14853716 0.15004443 2.3477495 ], sigma noise: [0.39603803 0.3923052  0.40616238 0.37505192]
[Epoch=100, n_hypersteps=26]: prior precision: [0.16360323 0.14242984 0.14402813 2.2940729 ], sigma noise: [0.4076558  0.4034815  0.41895244 0.38429606]
[Epoch=100, n_hypersteps=27]: prior precision: [0.15932791 0.13690113 0.13858572 2.2528646 ], sigma noise: [0.41734105 0.41275266 0.42973    0.39177784]
[Epoch=100, n_hypersteps=28]: prior precision: [0.15557621 0.1318914  0.1336579  2.2242672 ], sigma noise: [0.42475367 0.41979614 0.4381061  0.3972486 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.15229702 0.12734812 0.12919252 2.2079914 ], sigma noise: [0.42969924 0.4244314  0.44384798 0.4005847 ]
[Epoch=200, n_hypersteps=0]: prior precision: [0.14944682 0.12322488 0.12514395 2.2034137 ], sigma noise: [0.43213105 0.42662105 0.4468846  0.40178296]
[Epoch=200, n_hypersteps=1]: prior precision: [0.14677449 0.11920686 0.12130396 2.112047  ], sigma noise: [0.4321183  0.42645603 0.4472458  0.40092397]
[Epoch=200, n_hypersteps=2]: prior precision: [0.14427613 0.11531279 0.11766804 1.9803783 ], sigma noise: [0.42987308 0.42414394 0.44515547 0.39820388]
[Epoch=200, n_hypersteps=3]: prior precision: [0.14194725 0.11155689 0.11423089 1.8304155 ], sigma noise: [0.42570052 0.41998023 0.4409448  0.3938871 ]
[Epoch=200, n_hypersteps=4]: prior precision: [0.13978374 0.10794949 0.11098637 1.6754649 ], sigma noise: [0.41997144 0.4143221  0.43502077 0.38828477]
[Epoch=200, n_hypersteps=5]: prior precision: [0.13778149 0.10449755 0.1079281  1.5240185 ], sigma noise: [0.41309527 0.40756327 0.42783523 0.38173452]
[Epoch=200, n_hypersteps=6]: prior precision: [0.13593605 0.10120525 0.10504918 1.3813928 ], sigma noise: [0.4054962  0.4001114  0.41985697 0.3745828 ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.1342433  0.09807435 0.10234249 1.2506673 ], sigma noise: [0.3975928  0.39236885 0.41154835 0.36716938]
[Epoch=200, n_hypersteps=8]: prior precision: [0.13269877 0.09510466 0.09980078 1.1333311 ], sigma noise: [0.3897808  0.38471642 0.4033457  0.35981444]
[Epoch=200, n_hypersteps=9]: prior precision: [0.1312982  0.09229439 0.09741687 1.0297658 ], sigma noise: [0.38241923 0.37749988 0.39564314 0.35280737]
[Epoch=200, n_hypersteps=10]: prior precision: [0.1300365  0.08964047 0.09518329 0.93961865], sigma noise: [0.37581855 0.37101886 0.38878116 0.34639755]
[Epoch=200, n_hypersteps=11]: prior precision: [0.12890862 0.08713884 0.09309261 0.86208415], sigma noise: [0.37023205 0.36551777 0.38303742 0.34078616]
[Epoch=200, n_hypersteps=12]: prior precision: [0.12790929 0.08478466 0.0911378  0.7961138 ], sigma noise: [0.36584845 0.3611788  0.37861884 0.33612034]
[Epoch=200, n_hypersteps=13]: prior precision: [0.1270328  0.0825725  0.08931126 0.7405652 ], sigma noise: [0.3627877  0.3581176  0.37565953 0.3324892 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.12627333 0.08049653 0.08760601 0.6943009 ], sigma noise: [0.3610994  0.35638168 0.37421593 0.32992294]
[Epoch=200, n_hypersteps=15]: prior precision: [0.12562487 0.07855065 0.08601548 0.6562485 ], sigma noise: [0.36076492 0.35595214 0.37427256 0.32839477]
[Epoch=200, n_hypersteps=16]: prior precision: [0.12508023 0.07672865 0.08453264 0.62543505], sigma noise: [0.36170208 0.35674822 0.37574407 0.32782596]
[Epoch=200, n_hypersteps=17]: prior precision: [0.12463287 0.07502425 0.0831506  0.60100055], sigma noise: [0.3637718  0.35863435 0.3784846  0.32809365]
[Epoch=200, n_hypersteps=18]: prior precision: [0.12427574 0.07343122 0.0818629  0.58219916], sigma noise: [0.36678773 0.36142918 0.38229474 0.3290402 ]
[Epoch=200, n_hypersteps=19]: prior precision: [0.12400164 0.07194344 0.08066393 0.5683927 ], sigma noise: [0.37052652 0.3649162  0.38693398 0.3304843 ]
[Epoch=200, n_hypersteps=20]: prior precision: [0.12380309 0.07055497 0.07954775 0.5590395 ], sigma noise: [0.3747399  0.3688558  0.39212927 0.33223262]
[Epoch=200, n_hypersteps=21]: prior precision: [0.12367423 0.06926008 0.07850873 0.55368185], sigma noise: [0.37916833 0.37299842 0.3975928  0.3340915 ]
[Epoch=200, n_hypersteps=22]: prior precision: [0.12360752 0.06805327 0.07754143 0.55193245], sigma noise: [0.38355497 0.37709823 0.40303388 0.33587828]
[Epoch=200, n_hypersteps=23]: prior precision: [0.12359647 0.06692933 0.07664137 0.55346143], sigma noise: [0.3876605  0.3809271  0.4081767  0.33743092]
[Epoch=200, n_hypersteps=24]: prior precision: [0.12363455 0.06588328 0.07580457 0.5579837 ], sigma noise: [0.3912761  0.38428715 0.41277745 0.33861622]
[Epoch=200, n_hypersteps=25]: prior precision: [0.12371694 0.06491046 0.07502656 0.56524646], sigma noise: [0.3942355  0.3870216  0.41663802 0.33933514]
[Epoch=200, n_hypersteps=26]: prior precision: [0.12383837 0.06400648 0.07430384 0.57501906], sigma noise: [0.39642295 0.38902226 0.4196156  0.33952576]
[Epoch=200, n_hypersteps=27]: prior precision: [0.12399448 0.06316724 0.07363261 0.58708274], sigma noise: [0.39777815 0.39023355 0.4216311  0.33916354]
[Epoch=200, n_hypersteps=28]: prior precision: [0.12418081 0.06238886 0.07300965 0.60122126], sigma noise: [0.39829698 0.39065272 0.42267242 0.33825913]
[Epoch=200, n_hypersteps=29]: prior precision: [0.12439351 0.06166776 0.07243221 0.61721283], sigma noise: [0.39802703 0.39032608 0.42278916 0.33685428]
[Epoch=300, n_hypersteps=0]: prior precision: [0.12462966 0.06100057 0.07189748 0.6348229 ], sigma noise: [0.39706182 0.38934255 0.42208642 0.33501643]
[Epoch=300, n_hypersteps=1]: prior precision: [0.1247538  0.06038797 0.07135027 0.65486056], sigma noise: [0.39568043 0.38799158 0.4209096  0.33294004]
[Epoch=300, n_hypersteps=2]: prior precision: [0.12477469 0.05982664 0.07079419 0.67700577], sigma noise: [0.3940133  0.3863945  0.4194106  0.33070716]
[Epoch=300, n_hypersteps=3]: prior precision: [0.1247015  0.05931346 0.070233   0.7009038 ], sigma noise: [0.39219737 0.3846786  0.41774994 0.32840168]
[Epoch=300, n_hypersteps=4]: prior precision: [0.12454319 0.05884552 0.06966978 0.72615796], sigma noise: [0.39036673 0.38296878 0.4160863  0.3261042 ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.12430901 0.05842006 0.06910747 0.7523249 ], sigma noise: [0.3886448  0.38138023 0.41456512 0.32388744]
[Epoch=300, n_hypersteps=6]: prior precision: [0.12400778 0.05803441 0.06854914 0.77891624], sigma noise: [0.3871376  0.38001168 0.41331205 0.32181254]
[Epoch=300, n_hypersteps=7]: prior precision: [0.12364802 0.05768614 0.06799719 0.80540335], sigma noise: [0.38592824 0.3789408  0.4124272  0.3199261 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.12323819 0.05737293 0.06745329 0.83123076], sigma noise: [0.3850738  0.37822062 0.4119796  0.3182584 ]
[Epoch=300, n_hypersteps=9]: prior precision: [0.12278616 0.05709252 0.06691904 0.85583323], sigma noise: [0.38460332 0.37787816 0.41200608 0.31682295]
[Epoch=300, n_hypersteps=10]: prior precision: [0.12229944 0.05684274 0.06639577 0.8786598 ], sigma noise: [0.3845181  0.37791422 0.41250935 0.31561682]
[Epoch=300, n_hypersteps=11]: prior precision: [0.12178494 0.05662154 0.06588506 0.89919925], sigma noise: [0.3847939  0.37830514 0.4134621  0.31462228]
[Epoch=300, n_hypersteps=12]: prior precision: [0.12124943 0.05642695 0.0653879  0.91700846], sigma noise: [0.38538396 0.37900567 0.41480973 0.31380942]
[Epoch=300, n_hypersteps=13]: prior precision: [0.12069879 0.05625723 0.06490452 0.93173677], sigma noise: [0.3862236  0.37995386 0.4164742  0.31313905]
[Epoch=300, n_hypersteps=14]: prior precision: [0.12013864 0.05611056 0.06443544 0.94314635], sigma noise: [0.38723588 0.38107538 0.41836143 0.31256652]
[Epoch=300, n_hypersteps=15]: prior precision: [0.1195736 0.0559853 0.0639814 0.9511249], sigma noise: [0.3883372  0.38229012 0.4203684  0.3120451 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.11900913 0.05587982 0.06354298 0.9556885 ], sigma noise: [0.38944402 0.38351724 0.4223902  0.3115297 ]
[Epoch=300, n_hypersteps=17]: prior precision: [0.11844865 0.05579254 0.06311992 0.9569772 ], sigma noise: [0.39047864 0.38468158 0.42432758 0.31097972]
[Epoch=300, n_hypersteps=18]: prior precision: [0.11789612 0.05572205 0.06271228 0.95524096], sigma noise: [0.3913739  0.38571796 0.42609474 0.31036162]
[Epoch=300, n_hypersteps=19]: prior precision: [0.11735468 0.05566694 0.06232022 0.9508178 ], sigma noise: [0.39207754 0.38657537 0.4276219  0.30965057]
[Epoch=300, n_hypersteps=20]: prior precision: [0.11682716 0.05562602 0.06194364 0.94411224], sigma noise: [0.39255512 0.38721982 0.4288618  0.30883133]
[Epoch=300, n_hypersteps=21]: prior precision: [0.11631674 0.05559813 0.06158236 0.9355684 ], sigma noise: [0.39279124 0.38763538 0.42979196 0.30789852]
[Epoch=300, n_hypersteps=22]: prior precision: [0.11582549 0.05558218 0.06123632 0.9256464 ], sigma noise: [0.3927888  0.38782403 0.43041334 0.3068559 ]
[Epoch=300, n_hypersteps=23]: prior precision: [0.11535511 0.0555772  0.06090594 0.9148008 ], sigma noise: [0.39256826 0.3878042  0.43074888 0.30571532]
[Epoch=300, n_hypersteps=24]: prior precision: [0.11490753 0.05558217 0.06059049 0.9034626 ], sigma noise: [0.3921642  0.38760838 0.43084216 0.30449507]
[Epoch=300, n_hypersteps=25]: prior precision: [0.1144841  0.05559611 0.06028973 0.8920268 ], sigma noise: [0.39162183 0.3872793  0.43074992 0.30321795]
[Epoch=300, n_hypersteps=26]: prior precision: [0.11408553 0.05561835 0.06000369 0.88084275], sigma noise: [0.3909926  0.3868664  0.43053934 0.3019092 ]
[Epoch=300, n_hypersteps=27]: prior precision: [0.11371252 0.05564806 0.05973252 0.8702091 ], sigma noise: [0.39033026 0.38642114 0.43027994 0.3005944 ]
[Epoch=300, n_hypersteps=28]: prior precision: [0.11336562 0.05568454 0.05947572 0.8603715 ], sigma noise: [0.3896861  0.38599318 0.4300389  0.29929763]
[Epoch=300, n_hypersteps=29]: prior precision: [0.1130447  0.05572704 0.05923355 0.8515242 ], sigma noise: [0.3891059  0.38562676 0.42987645 0.2980397 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.11275077 0.05577487 0.05900532 0.8438113 ], sigma noise: [0.38862622 0.3853578  0.42984238 0.29683697]
[Epoch=400, n_hypersteps=1]: prior precision: [0.11229803 0.05582695 0.05877345 0.8481828 ], sigma noise: [0.3882745  0.38520473 0.42994088 0.2957484 ]
[Epoch=400, n_hypersteps=2]: prior precision: [0.11170769 0.05588264 0.05853959 0.86333627], sigma noise: [0.38806394 0.38518244 0.43019387 0.2947746 ]
[Epoch=400, n_hypersteps=3]: prior precision: [0.11100088 0.05594151 0.05830514 0.88800544], sigma noise: [0.3879966  0.38529253 0.4306064  0.29391095]
[Epoch=400, n_hypersteps=4]: prior precision: [0.11019529 0.05600276 0.05807096 0.9208731 ], sigma noise: [0.38806328 0.38552636 0.4311697  0.29314822]
[Epoch=400, n_hypersteps=5]: prior precision: [0.10931137 0.05606626 0.05783811 0.96045977], sigma noise: [0.3882446  0.38586563 0.4318602  0.29247344]
[Epoch=400, n_hypersteps=6]: prior precision: [0.10836654 0.05613149 0.05760769 1.0050123 ], sigma noise: [0.38851422 0.38628507 0.43264434 0.2918709 ]
[Epoch=400, n_hypersteps=7]: prior precision: [0.10737731 0.05619812 0.05738047 1.0524315 ], sigma noise: [0.38884026 0.38675427 0.4334818  0.2913234 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.10635989 0.05626536 0.05715698 1.1002595 ], sigma noise: [0.3891902  0.3872416  0.4343281  0.29081368]
[Epoch=400, n_hypersteps=9]: prior precision: [0.10532851 0.05633301 0.05693781 1.1457781 ], sigma noise: [0.38953215 0.387715   0.4351404  0.2903255 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.10429642 0.05640066 0.05672366 1.1862112 ], sigma noise: [0.3898384  0.3881468  0.43588153 0.2898446 ]
[Epoch=400, n_hypersteps=11]: prior precision: [0.10327509 0.05646814 0.05651483 1.2190374 ], sigma noise: [0.3900854  0.38851482 0.43652093 0.28935972]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.203 MB of 0.292 MB uploaded (0.000 MB deduped)wandb: \ 0.214 MB of 0.292 MB uploaded (0.000 MB deduped)wandb: | 0.214 MB of 0.292 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.56688
wandb:                       Metrics 0.56349
wandb:  Negative_marginal_likelihood 1222.00366
wandb: Predictive_posterior_std_mean 0.76074
wandb:                   Sigma_noise 0.75844
wandb: 
wandb: üöÄ View run exalted-sweep-1 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/27k6wax3
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165641-27k6wax3/logs
wandb: Agent Starting Run: ampa7rnn with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165804-ampa7rnn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ampa7rnn
[Epoch=400, n_hypersteps=12]: prior precision: [0.10227507 0.05653505 0.05631171 1.242322  ], sigma noise: [0.3902584  0.38880327 0.43703777 0.28886282]
[Epoch=400, n_hypersteps=13]: prior precision: [0.10130075 0.05660105 0.0561145  1.2549952 ], sigma noise: [0.39034927 0.38900462 0.4374213  0.2883494 ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.10036087 0.05666593 0.05592373 1.2569816 ], sigma noise: [0.39035767 0.38911936 0.43767282 0.28781846]
[Epoch=400, n_hypersteps=15]: prior precision: [0.09946376 0.05672951 0.05573968 1.249154  ], sigma noise: [0.3902919  0.38915414 0.43780366 0.2872721 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.09861215 0.05679161 0.05556246 1.2331355 ], sigma noise: [0.39016563 0.3891226  0.43783313 0.28671494]
[Epoch=400, n_hypersteps=17]: prior precision: [0.09780895 0.05685198 0.05539181 1.2110221 ], sigma noise: [0.38999674 0.3890424  0.4377865  0.2861534 ]
[Epoch=400, n_hypersteps=18]: prior precision: [0.09705883 0.05691048 0.05522831 1.1850916 ], sigma noise: [0.38980493 0.3889336  0.43769294 0.28559485]
[Epoch=400, n_hypersteps=19]: prior precision: [0.09636447 0.05696706 0.05507187 1.1575574 ], sigma noise: [0.38961014 0.38881704 0.43758237 0.2850469 ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.09572646 0.05702149 0.05492277 1.1303893 ], sigma noise: [0.38943198 0.38871214 0.43748215 0.28451666]
[Epoch=400, n_hypersteps=21]: prior precision: [0.09514494 0.05707393 0.05478072 1.1052145 ], sigma noise: [0.38928688 0.3886352  0.4374164  0.28401005]
[Epoch=400, n_hypersteps=22]: prior precision: [0.09461949 0.05712416 0.05464597 1.0832733 ], sigma noise: [0.38918763 0.38859865 0.43740296 0.28353134]
[Epoch=400, n_hypersteps=23]: prior precision: [0.09414969 0.05717202 0.05451823 1.0654244 ], sigma noise: [0.38914144 0.38861036 0.43745384 0.28308287]
[Epoch=400, n_hypersteps=24]: prior precision: [0.09373482 0.05721756 0.05439766 1.052179  ], sigma noise: [0.38915083 0.3886727  0.43757167 0.28266495]
[Epoch=400, n_hypersteps=25]: prior precision: [0.09337117 0.05726057 0.05428404 1.0437453 ], sigma noise: [0.38921282 0.38878363 0.43775457 0.28227597]
[Epoch=400, n_hypersteps=26]: prior precision: [0.09305888 0.05730122 0.05417704 1.0400747 ], sigma noise: [0.38932127 0.38893625 0.43799356 0.28191265]
[Epoch=400, n_hypersteps=27]: prior precision: [0.09279615 0.0573396  0.05407686 1.0409043 ], sigma noise: [0.38946557 0.38912055 0.43827456 0.2815705 ]
[Epoch=400, n_hypersteps=28]: prior precision: [0.09258021 0.05737552 0.05398295 1.0457891 ], sigma noise: [0.3896327  0.38932356 0.4385796  0.28124407]
[Epoch=400, n_hypersteps=29]: prior precision: [0.09240809 0.05740907 0.05389513 1.0541348 ], sigma noise: [0.38980892 0.3895325  0.43889078 0.2809279 ]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8191084  0.8190924  0.8190834  0.81965643], sigma noise: [0.8188425 0.8188426 0.8188442 0.8188387]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74207747 0.7420205  0.7419892  0.7440836 ], sigma noise: [0.7412332  0.7412334  0.7412395  0.74121916]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6730248  0.67289394 0.67282444 0.6777523 ], sigma noise: [0.6713218  0.67132145 0.6713364  0.67128795]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6112548  0.6110097  0.61088496 0.6203149 ], sigma noise: [0.6085148  0.6085127  0.6085432  0.60844785]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5561004  0.5556962  0.5555     0.57142663], sigma noise: [0.5523179  0.552312   0.5523679  0.55219936]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50693053 0.5063187  0.50603724 0.5307441 ], sigma noise: [0.5023456  0.50233257 0.50242835 0.5021497 ]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46315414 0.46228418 0.4619054  0.49787557], sigma noise: [0.45833677 0.4583113  0.45846874 0.45802653]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42421937 0.42304182 0.4225575  0.4723424 ], sigma noise: [0.42017242 0.42012706 0.42037755 0.41969463]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38961917 0.38808578 0.38749084 0.45364094], sigma noise: [0.38788447 0.3878083  0.38819817 0.38716277]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35888842 0.35695276 0.3562457  0.4411892 ], sigma noise: [0.36162645 0.36150455 0.36209813 0.36055493]
[Epoch=100, n_hypersteps=12]: prior precision: [0.33160475 0.3292222  0.32840428 0.43437937], sigma noise: [0.34156856 0.3413821  0.34226292 0.3400104 ]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30738658 0.3045172  0.30359066 0.43260857], sigma noise: [0.32772148 0.32744798 0.3287146  0.3255164 ]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28588632 0.28249547 0.281465   0.43531722], sigma noise: [0.31979144 0.31940797 0.32116386 0.31676936]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26679102 0.26285192 0.26172176 0.44202173], sigma noise: [0.31719443 0.31667778 0.31902575 0.31318304]
[Epoch=100, n_hypersteps=16]: prior precision: [0.24982065 0.24531488 0.24409056 0.45224917], sigma noise: [0.31919816 0.31852382 0.3215685  0.31402132]
[Epoch=100, n_hypersteps=17]: prior precision: [0.23473272 0.22964315 0.22832805 0.46556118], sigma noise: [0.3250601  0.32420307 0.3280563  0.3185312 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.22130448 0.21562469 0.21421817 0.4815157 ], sigma noise: [0.33408713 0.33301952 0.33780375 0.32600248]
[Epoch=100, n_hypersteps=19]: prior precision: [0.2093418  0.20306724 0.20157145 0.49964294], sigma noise: [0.34562626 0.34431836 0.350168   0.3357658 ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.19867745 0.19180273 0.19021879 0.51940703], sigma noise: [0.3590354  0.35745463 0.36451313 0.347169  ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.18915945 0.18168771 0.18001384 0.5401516 ], sigma noise: [0.3736533  0.3717668  0.38017583 0.35955703]
[Epoch=100, n_hypersteps=22]: prior precision: [0.18066058 0.17259231 0.17082682 0.5611579 ], sigma noise: [0.38878942 0.3865678  0.39645326 0.3722695 ]
[Epoch=100, n_hypersteps=23]: prior precision: [0.1730656  0.16440232 0.16254365 0.5816084 ], sigma noise: [0.4037361  0.40115786 0.41261283 0.3846569 ]
[Epoch=100, n_hypersteps=24]: prior precision: [0.16627382 0.15701994 0.15506439 0.60062945], sigma noise: [0.4178016  0.41485688 0.42792    0.39611116]
[Epoch=100, n_hypersteps=25]: prior precision: [0.1601983  0.15035634 0.14830153 0.6173706 ], sigma noise: [0.43035346 0.4270456  0.4416932  0.40610206]
[Epoch=100, n_hypersteps=26]: prior precision: [0.15476458 0.1443358  0.14217852 0.63110167], sigma noise: [0.44086283 0.43721065 0.4533463  0.4142096 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.14990519 0.13889241 0.13662718 0.6412508 ], sigma noise: [0.4489383  0.44497773 0.4624376  0.42014572]
[Epoch=100, n_hypersteps=28]: prior precision: [0.14556289 0.13396612 0.13159078 0.64748377], sigma noise: [0.45435137 0.4501314  0.46869737 0.4237637 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.14168802 0.12950529 0.12701675 0.649717  ], sigma noise: [0.4570411  0.45261726 0.47203663 0.42505297]
[Epoch=200, n_hypersteps=0]: prior precision: [0.13823445 0.12546363 0.12285963 0.64816177], sigma noise: [0.45709914 0.4525317  0.47253722 0.42412457]
[Epoch=200, n_hypersteps=1]: prior precision: [0.13515842 0.12157937 0.11904801 0.647486  ], sigma noise: [0.45335886 0.4487318  0.4688459  0.42004603]
[Epoch=200, n_hypersteps=2]: prior precision: [0.13242984 0.1178611  0.1155533  0.6476833 ], sigma noise: [0.44638795 0.44177407 0.46158984 0.41329786]
[Epoch=200, n_hypersteps=3]: prior precision: [0.13002288 0.11431491 0.11234901 0.6487504 ], sigma noise: [0.43684936 0.43230647 0.45150557 0.40442783]
[Epoch=200, n_hypersteps=4]: prior precision: [0.12791274 0.11094352 0.10941043 0.65069115], sigma noise: [0.42544883 0.4210187  0.43937826 0.3940119 ]
[Epoch=200, n_hypersteps=5]: prior precision: [0.12608114 0.10774903 0.10671682 0.65347344], sigma noise: [0.41289368 0.40859914 0.42598972 0.38262504]
[Epoch=200, n_hypersteps=6]: prior precision: [0.12450753 0.10473038 0.10424903 0.65707546], sigma noise: [0.3998601  0.3957069  0.4120851  0.37081856]
[Epoch=200, n_hypersteps=7]: prior precision: [0.12317979 0.10188571 0.10198973 0.6614603 ], sigma noise: [0.38697362 0.38295138 0.39834753 0.35910448]
[Epoch=200, n_hypersteps=8]: prior precision: [0.12208258 0.09921278 0.09992416 0.6665784 ], sigma noise: [0.37479421 0.37087744 0.38538447 0.34794357]
[Epoch=200, n_hypersteps=9]: prior precision: [0.12120102 0.09670664 0.09803842 0.6723533 ], sigma noise: [0.3638081  0.35995737 0.37371218 0.33773497]
[Epoch=200, n_hypersteps=10]: prior precision: [0.12052482 0.09436303 0.0963191  0.6786696 ], sigma noise: [0.35441005 0.35057753 0.36375526 0.3288063 ]
[Epoch=200, n_hypersteps=11]: prior precision: [0.12004361 0.09217643 0.09475271 0.6854055 ], sigma noise: [0.3469039  0.34303132 0.35583186 0.32140422]
[Epoch=200, n_hypersteps=12]: prior precision: [0.11974526 0.09013928 0.09332713 0.6923928 ], sigma noise: [0.34148815 0.33750975 0.35014588 0.31568614]
[Epoch=200, n_hypersteps=13]: prior precision: [0.11961597 0.08824525 0.09203286 0.69940424], sigma noise: [0.3382526  0.33409914 0.34679064 0.31171608]
[Epoch=200, n_hypersteps=14]: prior precision: [0.11964521 0.08648919 0.09085918 0.7062083 ], sigma noise: [0.33718458 0.33278042 0.34574968 0.30946577]
[Epoch=200, n_hypersteps=15]: prior precision: [0.11982017 0.08486321 0.08979779 0.71257097], sigma noise: [0.33817193 0.33344138 0.3469029  0.30882177]
[Epoch=200, n_hypersteps=16]: prior precision: [0.12012993 0.08335795 0.08884039 0.718233  ], sigma noise: [0.34101498 0.3358827  0.35003936 0.30959764]
[Epoch=200, n_hypersteps=17]: prior precision: [0.12055833 0.0819675  0.08797829 0.72296447], sigma noise: [0.3454445  0.33983663 0.3548761  0.31154945]
[Epoch=200, n_hypersteps=18]: prior precision: [0.12109897 0.08068413 0.08720379 0.72659224], sigma noise: [0.35113215 0.34498003 0.3610656  0.31439245]
[Epoch=200, n_hypersteps=19]: prior precision: [0.12173249 0.07950139 0.08650677 0.72894055], sigma noise: [0.35770008 0.35095066 0.3682172  0.31781834]
[Epoch=200, n_hypersteps=20]: prior precision: [0.12244473 0.07841249 0.0858821  0.7299303 ], sigma noise: [0.36474764 0.3573618  0.37590492 0.32151344]
[Epoch=200, n_hypersteps=21]: prior precision: [0.12322585 0.07740943 0.08532453 0.7295819 ], sigma noise: [0.37186396 0.3638227  0.38368887 0.32517606]
[Epoch=200, n_hypersteps=22]: prior precision: [0.12406557 0.07648712 0.08482847 0.7279369 ], sigma noise: [0.37865147 0.3699618  0.39114228 0.32853338]
[Epoch=200, n_hypersteps=23]: prior precision: [0.12495179 0.07564013 0.08438618 0.7251128 ], sigma noise: [0.3847525  0.3754487  0.397873   0.33135584]
[Epoch=200, n_hypersteps=24]: prior precision: [0.12587573 0.07486329 0.08399153 0.7213073 ], sigma noise: [0.38987172 0.38000867 0.40355375 0.33346763]
[Epoch=200, n_hypersteps=25]: prior precision: [0.12682757 0.07415161 0.083642   0.7167928 ], sigma noise: [0.39378807 0.38344446 0.40794104 0.33475235]
[Epoch=200, n_hypersteps=26]: prior precision: [0.1277944  0.07350139 0.08333281 0.7118122 ], sigma noise: [0.39637083 0.3856421  0.41088733 0.3351549 ]
[Epoch=200, n_hypersteps=27]: prior precision: [0.12876745 0.07290869 0.08306154 0.7066413 ], sigma noise: [0.3975873  0.38657317 0.4123463  0.33467826]
[Epoch=200, n_hypersteps=28]: prior precision: [0.12974079 0.07237022 0.0828241  0.70159143], sigma noise: [0.3974882  0.38629246 0.41237533 0.33337715]
[Epoch=200, n_hypersteps=29]: prior precision: [0.13070989 0.07188269 0.08261875 0.6968939 ], sigma noise: [0.39620715 0.38492677 0.41111386 0.33134946]
[Epoch=300, n_hypersteps=0]: prior precision: [0.13166915 0.07144229 0.08244331 0.69281447], sigma noise: [0.39394102 0.38265708 0.40877625 0.32872587]
[Epoch=300, n_hypersteps=1]: prior precision: [0.13260098 0.07097223 0.08228731 0.6955538 ], sigma noise: [0.3906524  0.37947085 0.40530974 0.32549307]
[Epoch=300, n_hypersteps=2]: prior precision: [0.13350484 0.07047794 0.0821508  0.7044684 ], sigma noise: [0.38665038 0.37565032 0.4010555  0.32184112]
[Epoch=300, n_hypersteps=3]: prior precision: [0.13438214 0.06996594 0.08203235 0.71886367], sigma noise: [0.38225707 0.37149093 0.3963705  0.31796622]
[Epoch=300, n_hypersteps=4]: prior precision: [0.13523413 0.0694417  0.08193188 0.7380134 ], sigma noise: [0.3777957  0.3672888  0.39161015 0.3140598 ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.13605632 0.06891    0.08184982 0.7610741 ], sigma noise: [0.37356094 0.3633144  0.38709876 0.31029734]
[Epoch=300, n_hypersteps=6]: prior precision: [0.13685168 0.06837555 0.08178518 0.787086  ], sigma noise: [0.36980924 0.35980374 0.3831203  0.30683023]
[Epoch=300, n_hypersteps=7]: prior precision: [0.1376152  0.06784286 0.08173641 0.8149154 ], sigma noise: [0.3667475  0.3569448  0.37989566 0.30377802]
[Epoch=300, n_hypersteps=8]: prior precision: [0.13834706 0.06731733 0.08170112 0.84325415], sigma noise: [0.36452025 0.35487354 0.3775884  0.3012239 ]
[Epoch=300, n_hypersteps=9]: prior precision: [0.13904631 0.06680136 0.08167892 0.8706854 ], sigma noise: [0.363214   0.35366678 0.3762867  0.29921132]
[Epoch=300, n_hypersteps=10]: prior precision: [0.13971236 0.06629746 0.0816699  0.895815  ], sigma noise: [0.36284566 0.35334283 0.37601534 0.29774493]
[Epoch=300, n_hypersteps=11]: prior precision: [0.14034076 0.06580694 0.08167362 0.9172445 ], sigma noise: [0.36337504 0.3538623  0.37672946 0.29679278]
[Epoch=300, n_hypersteps=12]: prior precision: [0.14093608 0.06533158 0.08168805 0.93383026], sigma noise: [0.36470693 0.35513988 0.37832883 0.29629165]
[Epoch=300, n_hypersteps=13]: prior precision: [0.14149047 0.06487317 0.08171252 0.9447827 ], sigma noise: [0.36670366 0.35704106 0.3806623  0.29615393]
[Epoch=300, n_hypersteps=14]: prior precision: [0.14200369 0.06443239 0.08174443 0.94982725], sigma noise: [0.3691922  0.35940704 0.3835392  0.29627606]
[Epoch=300, n_hypersteps=15]: prior precision: [0.14247403 0.0640092  0.08178402 0.9490937 ], sigma noise: [0.37197587 0.3620573  0.38674897 0.29654747]
[Epoch=300, n_hypersteps=16]: prior precision: [0.14290275 0.06360476 0.08183064 0.9431376 ], sigma noise: [0.3748531  0.36480433 0.39006683 0.29685885]
[Epoch=300, n_hypersteps=17]: prior precision: [0.14328317 0.06321801 0.08188226 0.93288314], sigma noise: [0.3776299  0.36746675 0.39327377 0.2971102 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.14361542 0.06284861 0.08193808 0.9194637 ], sigma noise: [0.38012782 0.3698825  0.3961775  0.29721686]
[Epoch=300, n_hypersteps=19]: prior precision: [0.14389926 0.06249735 0.0819959  0.9040914 ], sigma noise: [0.38220614 0.37191933 0.3986166  0.29711413]
[Epoch=300, n_hypersteps=20]: prior precision: [0.14413626 0.06216364 0.08205592 0.8879378 ], sigma noise: [0.38376486 0.37348294 0.40047592 0.2967596 ]
[Epoch=300, n_hypersteps=21]: prior precision: [0.14432687 0.06184713 0.08211601 0.8720219 ], sigma noise: [0.38474584 0.37451923 0.40168676 0.2961338 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.14447317 0.06154777 0.08217682 0.85732555], sigma noise: [0.38513997 0.37501732 0.40223914 0.29523903]
[Epoch=300, n_hypersteps=23]: prior precision: [0.1445842  0.06126588 0.08223677 0.8445593 ], sigma noise: [0.38498154 0.3750083  0.40216962 0.2940975 ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.178 MB of 0.291 MB uploaded (0.000 MB deduped)wandb: \ 0.178 MB of 0.291 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.49984
wandb:                       Metrics 0.496
wandb:  Negative_marginal_likelihood 1172.24719
wandb: Predictive_posterior_std_mean 0.71561
wandb:                   Sigma_noise 0.71276
wandb: 
wandb: üöÄ View run deep-sweep-2 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ampa7rnn
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165804-ampa7rnn/logs
wandb: Agent Starting Run: 71iznyqs with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.001
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165922-71iznyqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/71iznyqs
[Epoch=300, n_hypersteps=24]: prior precision: [0.14465746 0.06100122 0.08229546 0.83425283], sigma noise: [0.38434047 0.3745557  0.40155756 0.29274687]
[Epoch=300, n_hypersteps=25]: prior precision: [0.14469163 0.06075416 0.08235363 0.826757  ], sigma noise: [0.38331965 0.37375444 0.40051565 0.2912369 ]
[Epoch=300, n_hypersteps=26]: prior precision: [0.14468879 0.06052378 0.08241246 0.822241  ], sigma noise: [0.3820407  0.37271598 0.3991821  0.2896244 ]
[Epoch=300, n_hypersteps=27]: prior precision: [0.14466015 0.06031026 0.08247086 0.8206757 ], sigma noise: [0.38063124 0.37155715 0.39770204 0.28796855]
[Epoch=300, n_hypersteps=28]: prior precision: [0.14460295 0.06011455 0.0825302  0.82193184], sigma noise: [0.37921956 0.37039867 0.39622018 0.2863268 ]
[Epoch=300, n_hypersteps=29]: prior precision: [0.14452732 0.05993626 0.08258866 0.8257602 ], sigma noise: [0.3779221  0.36934963 0.39486608 0.2847507 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.14443326 0.05977511 0.0826489  0.83177984], sigma noise: [0.37683848 0.3685018  0.393751   0.28328252]
[Epoch=400, n_hypersteps=1]: prior precision: [0.14432506 0.0596048  0.08270434 0.8452623 ], sigma noise: [0.37579146 0.36769596 0.392663   0.2818382 ]
[Epoch=400, n_hypersteps=2]: prior precision: [0.14420116 0.05942847 0.08275454 0.8651825 ], sigma noise: [0.3748674  0.36701083 0.39170069 0.28045577]
[Epoch=400, n_hypersteps=3]: prior precision: [0.1440726  0.05924841 0.08279958 0.89037275], sigma noise: [0.37413776 0.3665126  0.3909488  0.27916515]
[Epoch=400, n_hypersteps=4]: prior precision: [0.14393532 0.05906553 0.08284114 0.9194887 ], sigma noise: [0.37365323 0.36624783 0.39046553 0.27798665]
[Epoch=400, n_hypersteps=5]: prior precision: [0.1437875  0.05888246 0.08287929 0.95094866], sigma noise: [0.37343806 0.3662429  0.3902761  0.27693012]
[Epoch=400, n_hypersteps=6]: prior precision: [0.14363755 0.05870022 0.08291319 0.9830155 ], sigma noise: [0.3734986  0.36650103 0.39038524 0.27599555]
[Epoch=400, n_hypersteps=7]: prior precision: [0.14348766 0.05851935 0.08294366 1.0138524 ], sigma noise: [0.3738152  0.36700436 0.3907755  0.2751734 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.1433389  0.05834169 0.08297163 1.0415841 ], sigma noise: [0.37434876 0.367718   0.39140317 0.27444673]
[Epoch=400, n_hypersteps=9]: prior precision: [0.14318968 0.05816706 0.08299465 1.0645831 ], sigma noise: [0.3750532  0.3685939  0.39221278 0.27379334]
[Epoch=400, n_hypersteps=10]: prior precision: [0.14304179 0.05799638 0.08301446 1.0814615 ], sigma noise: [0.37586233 0.36957273 0.39313325 0.27318785]
[Epoch=400, n_hypersteps=11]: prior precision: [0.14289513 0.05782974 0.08303277 1.091477  ], sigma noise: [0.37671307 0.3705927  0.39409432 0.27260444]
[Epoch=400, n_hypersteps=12]: prior precision: [0.14274874 0.05766767 0.0830474  1.0944557 ], sigma noise: [0.3775394  0.3715929  0.39502293 0.2720187 ]
[Epoch=400, n_hypersteps=13]: prior precision: [0.14260206 0.05751047 0.08305922 1.090858  ], sigma noise: [0.37828878 0.37251797 0.39585957 0.2714098 ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.14245571 0.05735891 0.08306938 1.0815871 ], sigma noise: [0.37891436 0.3733253  0.39655554 0.27076182]
[Epoch=400, n_hypersteps=15]: prior precision: [0.14231202 0.05721419 0.08307624 1.0679544 ], sigma noise: [0.37938505 0.37398365 0.39707562 0.27006468]
[Epoch=400, n_hypersteps=16]: prior precision: [0.14217246 0.05707607 0.08307897 1.0514474 ], sigma noise: [0.37968662 0.3744796  0.3973991  0.26931384]
[Epoch=400, n_hypersteps=17]: prior precision: [0.14204283 0.05694464 0.0830782  1.0335816 ], sigma noise: [0.37982082 0.37481055 0.39752728 0.26851088]
[Epoch=400, n_hypersteps=18]: prior precision: [0.14191759 0.05681976 0.08307438 1.015727  ], sigma noise: [0.37980175 0.37499166 0.3974747  0.2676623 ]
[Epoch=400, n_hypersteps=19]: prior precision: [0.14179786 0.05670229 0.08306959 0.99905545], sigma noise: [0.37965333 0.37504637 0.39727306 0.26677853]
[Epoch=400, n_hypersteps=20]: prior precision: [0.14168243 0.05659262 0.08306237 0.9845591 ], sigma noise: [0.37941256 0.37500873 0.39696324 0.26587296]
[Epoch=400, n_hypersteps=21]: prior precision: [0.14157252 0.05648979 0.08305251 0.97290295], sigma noise: [0.37911716 0.374915   0.396592   0.26496017]
[Epoch=400, n_hypersteps=22]: prior precision: [0.14147152 0.05639504 0.08304144 0.96450466], sigma noise: [0.37881142 0.37480465 0.39620003 0.26405463]
[Epoch=400, n_hypersteps=23]: prior precision: [0.14137825 0.05630846 0.08303142 0.9595789 ], sigma noise: [0.37853047 0.37471756 0.39583334 0.26316988]
[Epoch=400, n_hypersteps=24]: prior precision: [0.1412943  0.05622931 0.08302042 0.9580735 ], sigma noise: [0.3783088  0.3746846  0.39553297 0.26231706]
[Epoch=400, n_hypersteps=25]: prior precision: [0.14122072 0.05615721 0.0830086  0.95983046], sigma noise: [0.37816897 0.37473014 0.39532918 0.26150435]
[Epoch=400, n_hypersteps=26]: prior precision: [0.14115492 0.0560917  0.0829965  0.96449256], sigma noise: [0.3781287  0.37486872 0.3952364  0.26073635]
[Epoch=400, n_hypersteps=27]: prior precision: [0.14109814 0.05603273 0.08298624 0.9715624 ], sigma noise: [0.37818968 0.3751055  0.3952607  0.26001397]
[Epoch=400, n_hypersteps=28]: prior precision: [0.14104827 0.05598082 0.08297519 0.9804376 ], sigma noise: [0.3783483 0.3754348 0.3953971 0.2593349]
[Epoch=400, n_hypersteps=29]: prior precision: [0.1410097  0.05593522 0.08296205 0.9904322 ], sigma noise: [0.37859252 0.3758431  0.39562482 0.2586941 ]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.001, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8191016  0.8190946  0.8190887  0.81909746], sigma noise: [0.8211787 0.821173  0.8212329 0.8211339]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7420531  0.74202824 0.74200594 0.7420371 ], sigma noise: [0.752604   0.7525724  0.75290287 0.7523553 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6729674  0.6729107  0.67285717 0.6729285 ], sigma noise: [0.7062722  0.70616883 0.7072454  0.70545   ]
[Epoch=100, n_hypersteps=5]: prior precision: [0.61113983 0.6110366  0.610934   0.61106503], sigma noise: [0.6864022  0.6861781  0.68849707 0.6846066 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5558938  0.5557294  0.5555594  0.55576843], sigma noise: [0.6879017  0.6875317  0.69133395 0.6849227 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50658566 0.50634694 0.5060936  0.50639653], sigma noise: [0.7036036  0.7030718  0.70850503 0.69930625]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46261302 0.46228847 0.46193874 0.46235007], sigma noise: [0.7281697 0.7274559 0.7346997 0.7223944]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42341843 0.4229987  0.42254227 0.4230746 ], sigma noise: [0.7573317  0.75641024 0.7656859  0.7498841 ]
[Epoch=100, n_hypersteps=10]: prior precision: [0.3884905  0.38796857 0.38739744 0.38806105], sigma noise: [0.7869661  0.78581184 0.7973224  0.7776597 ]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35736465 0.35673496 0.35604322 0.3568467 ], sigma noise: [0.8129865  0.81158406 0.82541984 0.8017217 ]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32962194 0.3288798  0.32806298 0.32901305], sigma noise: [0.83197576 0.8303267  0.8463824  0.8188087 ]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30488658 0.30402842 0.3030822  0.30418465], sigma noise: [0.84194934 0.8400775  0.8580416  0.8271032 ]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28282365 0.28184593 0.28076628 0.28202537], sigma noise: [0.842623   0.840567   0.86000293 0.8264282 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26313472 0.2620341  0.260816   0.26223603], sigma noise: [0.83510196 0.83290493 0.85335904 0.81790876]
[Epoch=100, n_hypersteps=16]: prior precision: [0.24555515 0.24432793 0.24296634 0.24455094], sigma noise: [0.82135886 0.8190578  0.8401424  0.8034658 ]
[Epoch=100, n_hypersteps=17]: prior precision: [0.2298503  0.2284929  0.22698168 0.22873496], sigma noise: [0.80378765 0.8014086  0.82286    0.7853962 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.21581228 0.21432075 0.21265267 0.21457839], sigma noise: [0.78491014 0.78246015 0.80416864 0.76609147]
[Epoch=100, n_hypersteps=19]: prior precision: [0.20325781 0.20162746 0.19979532 0.20189613], sigma noise: [0.76716244 0.764631   0.78665346 0.7478376 ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.19202368 0.19024959 0.18824565 0.19052443], sigma noise: [0.7526778  0.75003374 0.77259856 0.7326207 ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.18196496 0.1800428  0.17785975 0.18031934], sigma noise: [0.7430353  0.7402303  0.76370883 0.72189134]
[Epoch=100, n_hypersteps=22]: prior precision: [0.17295463 0.17087942 0.1685094  0.17115125], sigma noise: [0.7390545  0.7360259  0.76087934 0.71638125]
[Epoch=100, n_hypersteps=23]: prior precision: [0.16487817 0.16264576 0.1600816  0.16290803], sigma noise: [0.7407268  0.737409   0.76413107 0.71604687]
[Epoch=100, n_hypersteps=24]: prior precision: [0.15763399 0.15524036 0.15247652 0.15548947], sigma noise: [0.7473379 0.7436644 0.7727311 0.7201819]
[Epoch=100, n_hypersteps=25]: prior precision: [0.15113316 0.1485745  0.14560637 0.14880781], sigma noise: [0.75763226 0.75354356 0.7853643  0.7275905 ]
[Epoch=100, n_hypersteps=26]: prior precision: [0.14529486 0.14256787 0.13939187 0.1427843 ], sigma noise: [0.7699952  0.76544565 0.8003094  0.7367623 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.14004819 0.13715045 0.13376221 0.13734911], sigma noise: [0.78263676 0.7776053  0.8156146  0.7460749 ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.1353329  0.13226172 0.12865734 0.13244104], sigma noise: [0.79380727 0.78830254 0.82933766 0.75398636]
[Epoch=100, n_hypersteps=29]: prior precision: [0.13109367 0.12784706 0.12402372 0.12800628], sigma noise: [0.8020485  0.7961112  0.83981353 0.75925916]
[Epoch=200, n_hypersteps=0]: prior precision: [0.12728392 0.12385877 0.11981383 0.12399782], sigma noise: [0.8064201  0.80011857 0.8459355  0.7611387 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.12372687 0.12005758 0.1157049  0.12039934], sigma noise: [0.7802571  0.77410984 0.81806403 0.73637813]
[Epoch=200, n_hypersteps=2]: prior precision: [0.12041697 0.11644849 0.11172439 0.11717018], sigma noise: [0.73765546 0.73187155 0.77260125 0.69668317]
[Epoch=200, n_hypersteps=3]: prior precision: [0.11735028 0.11303745 0.10789458 0.11427783], sigma noise: [0.6864995 0.6811687 0.7181854 0.6490434]
[Epoch=200, n_hypersteps=4]: prior precision: [0.11452454 0.10982972 0.10423571 0.11169251], sigma noise: [0.6319362  0.62708616 0.66032237 0.59814614]
[Epoch=200, n_hypersteps=5]: prior precision: [0.11193734 0.10682802 0.10076307 0.10938966], sigma noise: [0.5775465  0.57316613 0.6027982  0.54729927]
[Epoch=200, n_hypersteps=6]: prior precision: [0.10958411 0.10403533 0.09748778 0.10734823], sigma noise: [0.52595097 0.5220039  0.5483642  0.49894363]
[Epoch=200, n_hypersteps=7]: prior precision: [0.10746185 0.101454   0.094418   0.10555496], sigma noise: [0.47921795 0.47564423 0.49918407 0.45500937]
[Epoch=200, n_hypersteps=8]: prior precision: [0.10557034 0.09908614 0.09155565 0.10399197], sigma noise: [0.43916166 0.43587554 0.45714355 0.4171796 ]
[Epoch=200, n_hypersteps=9]: prior precision: [0.10390595 0.09692674 0.08890544 0.10264503], sigma noise: [0.40743247 0.40432447 0.42396364 0.3869821 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.10245804 0.09497585 0.08646256 0.10149755], sigma noise: [0.38527662 0.38222006 0.4009251  0.3655813 ]
[Epoch=200, n_hypersteps=11]: prior precision: [0.10121797 0.09322489 0.08422147 0.10054001], sigma noise: [0.37303722 0.36990252 0.3883709  0.3533088 ]
[Epoch=200, n_hypersteps=12]: prior precision: [0.10017902 0.09166653 0.08217064 0.09975002], sigma noise: [0.36998928 0.3666503  0.38550577 0.34950945]
[Epoch=200, n_hypersteps=13]: prior precision: [0.09933008 0.09028608 0.08030196 0.09912258], sigma noise: [0.37479746 0.37114397 0.39092582 0.3529274 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.09865731 0.0890688  0.07860403 0.09865105], sigma noise: [0.38600636 0.38193047 0.40311038 0.36216974]
[Epoch=200, n_hypersteps=15]: prior precision: [0.09813346 0.08799226 0.077061   0.09830806], sigma noise: [0.40221983 0.3976196  0.42062095 0.3758869 ]
[Epoch=200, n_hypersteps=16]: prior precision: [0.09774123 0.08705055 0.07566098 0.0980886 ], sigma noise: [0.4220392  0.41682115 0.44201922 0.3927397 ]
[Epoch=200, n_hypersteps=17]: prior precision: [0.09746605 0.08622526 0.07438549 0.09797715], sigma noise: [0.4439783  0.43806094 0.46575484 0.41132364]
[Epoch=200, n_hypersteps=18]: prior precision: [0.09728879 0.08550291 0.07322361 0.09795746], sigma noise: [0.4664278  0.4597585  0.49013874 0.43017155]
[Epoch=200, n_hypersteps=19]: prior precision: [0.09719604 0.08486928 0.07216254 0.09802014], sigma noise: [0.48772743 0.4802983  0.51340437 0.44783667]
[Epoch=200, n_hypersteps=20]: prior precision: [0.09717175 0.08431385 0.07119265 0.09815031], sigma noise: [0.50632316 0.49817815 0.53386706 0.46300566]
[Epoch=200, n_hypersteps=21]: prior precision: [0.09720375 0.08382557 0.07030442 0.09834126], sigma noise: [0.5209424  0.5121864  0.5501257  0.47465727]
[Epoch=200, n_hypersteps=22]: prior precision: [0.09728796 0.08339582 0.06949115 0.09858783], sigma noise: [0.5307344  0.52151364 0.561215   0.48215264]
[Epoch=200, n_hypersteps=23]: prior precision: [0.09741604 0.08302341 0.06874782 0.09888234], sigma noise: [0.53534186 0.5258313  0.56671166 0.48525405]
[Epoch=200, n_hypersteps=24]: prior precision: [0.09758199 0.08270095 0.06806888 0.09922136], sigma noise: [0.5348868  0.52526677 0.56671727 0.48411068]
[Epoch=200, n_hypersteps=25]: prior precision: [0.09778222 0.08242507 0.06745314 0.09959869], sigma noise: [0.5298925  0.5203291  0.56177855 0.4791864 ]
[Epoch=200, n_hypersteps=26]: prior precision: [0.09801599 0.08219465 0.06689549 0.10001139], sigma noise: [0.5211758  0.5118058  0.5527792  0.47117132]
[Epoch=200, n_hypersteps=27]: prior precision: [0.09827758 0.08200683 0.06639647 0.10045823], sigma noise: [0.5097318  0.5006544  0.54080194 0.46088654]
[Epoch=200, n_hypersteps=28]: prior precision: [0.0985667  0.08186352 0.06595449 0.10093674], sigma noise: [0.49663478 0.48790056 0.5270155  0.449217  ]
[Epoch=200, n_hypersteps=29]: prior precision: [0.09888613 0.08176379 0.06556603 0.1014434 ], sigma noise: [0.48295152 0.4745726  0.5125911  0.43703493]
[Epoch=300, n_hypersteps=0]: prior precision: [0.09924159 0.08170737 0.06523158 0.10198059], sigma noise: [0.46967405 0.46163163 0.49862796 0.42516285]
[Epoch=300, n_hypersteps=1]: prior precision: [0.09956186 0.08157581 0.06495082 0.10255276], sigma noise: [0.4530558  0.4455086  0.4809736  0.41048074]
[Epoch=300, n_hypersteps=2]: prior precision: [0.09984469 0.08138328 0.06472426 0.10314912], sigma noise: [0.43461412 0.42765212 0.4613042  0.39424476]
[Epoch=300, n_hypersteps=3]: prior precision: [0.10010949 0.08114516 0.06455449 0.10377441], sigma noise: [0.41577974 0.40943414 0.44119242 0.3776336 ]
[Epoch=300, n_hypersteps=4]: prior precision: [0.10036331 0.08087727 0.06444135 0.10442442], sigma noise: [0.39782923 0.39208493 0.42204717 0.36171532]
[Epoch=300, n_hypersteps=5]: prior precision: [0.10061814 0.08059252 0.06438618 0.10510415], sigma noise: [0.38184327 0.37665543 0.4050653  0.34739646]
/scratch/work/zhangx18/Reproduced-LA-NAM/LANAM/utils/plotting.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig_indiv, axs = plt.subplots(rows, cols, figsize=figsize)
[Epoch=300, n_hypersteps=6]: prior precision: [0.1008751  0.08030152 0.06438722 0.10582176], sigma noise: [0.36868232 0.36398855 0.39119354 0.33540905]
[Epoch=300, n_hypersteps=7]: prior precision: [0.10113504 0.08001401 0.0644413  0.10656399], sigma noise: [0.35895595 0.35467398 0.38109916 0.32626432]
[Epoch=300, n_hypersteps=8]: prior precision: [0.10140399 0.0797413  0.06454013 0.10734213], sigma noise: [0.35298336 0.3490348  0.37512764 0.3202263 ]
[Epoch=300, n_hypersteps=9]: prior precision: [0.10168545 0.07947761 0.06468552 0.10814545], sigma noise: [0.35079557 0.34710947 0.37334302 0.31731611]
[Epoch=300, n_hypersteps=10]: prior precision: [0.10197303 0.07922055 0.06487692 0.10896605], sigma noise: [0.35216713 0.34868515 0.37551257 0.31731972]
[Epoch=300, n_hypersteps=11]: prior precision: [0.10226592 0.07897787 0.06510352 0.1098134 ], sigma noise: [0.35665655 0.3533495  0.3811656  0.31983566]
[Epoch=300, n_hypersteps=12]: prior precision: [0.10256553 0.07875241 0.06536496 0.11068358], sigma noise: [0.36365464 0.3605051  0.3896648  0.32432058]
[Epoch=300, n_hypersteps=13]: prior precision: [0.10285801 0.07854365 0.06565586 0.11156577], sigma noise: [0.37243778 0.36944625 0.40022302 0.3301484 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.1031429  0.07833961 0.06596616 0.11244658], sigma noise: [0.38219896 0.3793748  0.41194063 0.3366494 ]
[Epoch=300, n_hypersteps=15]: prior precision: [0.10340506 0.07812727 0.06629351 0.11332473], sigma noise: [0.39209965 0.38946077 0.42387378 0.34316304]
[Epoch=300, n_hypersteps=16]: prior precision: [0.10364458 0.07792474 0.06663113 0.11420592], sigma noise: [0.40133932 0.39890763 0.43509072 0.34908506]
[Epoch=300, n_hypersteps=17]: prior precision: [0.10384423 0.07771487 0.06696878 0.11507654], sigma noise: [0.40921646 0.40700585 0.4447608  0.3539161 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.10400987 0.07750463 0.06730648 0.1159287 ], sigma noise: [0.4151867  0.41321307 0.4522245  0.35729444]
[Epoch=300, n_hypersteps=19]: prior precision: [0.10413901 0.07728891 0.06763899 0.11675766], sigma noise: [0.4189119  0.41718557 0.45705175 0.3590144 ]
[Epoch=300, n_hypersteps=20]: prior precision: [0.10422574 0.07706783 0.06796273 0.11756729], sigma noise: [0.42027238 0.4188001  0.4590852  0.35903078]
[Epoch=300, n_hypersteps=21]: prior precision: [0.10427195 0.07684296 0.06827383 0.11834963], sigma noise: [0.4193764  0.41814762 0.45842585 0.3574461 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.1042846  0.07661898 0.06857233 0.11910229], sigma noise: [0.4165036  0.4155067  0.4553975  0.35447845]
[Epoch=300, n_hypersteps=23]: prior precision: [0.10426459 0.07639544 0.06886372 0.1198324 ], sigma noise: [0.4120784  0.4112982  0.45050615 0.35043204]
[Epoch=300, n_hypersteps=24]: prior precision: [0.10422246 0.07617619 0.0691415  0.12053097], sigma noise: [0.4066044  0.40602544 0.4443616  0.34566215]
[Epoch=300, n_hypersteps=25]: prior precision: [0.10417057 0.07596666 0.06941271 0.12120165], sigma noise: [0.40062815 0.40023687 0.43760717 0.34054637]
[Epoch=300, n_hypersteps=26]: prior precision: [0.1041118  0.07577842 0.06967236 0.12183402], sigma noise: [0.3946792  0.3944678  0.4308897  0.33545166]
[Epoch=300, n_hypersteps=27]: prior precision: [0.10404296 0.0756071  0.06992489 0.12243857], sigma noise: [0.3892404  0.38920313 0.42477497 0.33070403]
[Epoch=300, n_hypersteps=28]: prior precision: [0.10396701 0.07545745 0.07016918 0.12301808], sigma noise: [0.384699   0.38484535 0.4197351  0.32657483]
[Epoch=300, n_hypersteps=29]: prior precision: [0.10389532 0.07533042 0.07040492 0.12356821], sigma noise: [0.3813456  0.3816918  0.41611105 0.32326487]
[Epoch=400, n_hypersteps=0]: prior precision: [0.10382267 0.07522378 0.07063475 0.12408965], sigma noise: [0.3793443  0.3799182  0.41410363 0.32087746]
[Epoch=400, n_hypersteps=1]: prior precision: [0.10376402 0.07501702 0.07085501 0.12460013], sigma noise: [0.37792554 0.3786829  0.41277602 0.31888238]
[Epoch=400, n_hypersteps=2]: prior precision: [0.10371356 0.0747169  0.07106009 0.1251073 ], sigma noise: [0.3771631  0.37807068 0.41222382 0.31732616]
[Epoch=400, n_hypersteps=3]: prior precision: [0.1036723  0.07433121 0.0712601  0.12560019], sigma noise: [0.3770655  0.37810054 0.41245162 0.31621212]
[Epoch=400, n_hypersteps=4]: prior precision: [0.10364744 0.07387915 0.07144524 0.12608787], sigma noise: [0.37758985 0.37873164 0.41341677 0.3155088 ]
[Epoch=400, n_hypersteps=5]: prior precision: [0.10364082 0.0733758  0.07161884 0.12656245], sigma noise: [0.37865105 0.3798709  0.41501617 0.31515142]
[Epoch=400, n_hypersteps=6]: prior precision: [0.10363163 0.0728343  0.07178024 0.12703277], sigma noise: [0.38011664 0.38139647 0.41709766 0.31505036]
[Epoch=400, n_hypersteps=7]: prior precision: [0.10362968 0.07225831 0.07192875 0.12748457], sigma noise: [0.38183329 0.38315615 0.41947305 0.31510413]
[Epoch=400, n_hypersteps=8]: prior precision: [0.1036382  0.0716612  0.07206488 0.12792854], sigma noise: [0.3836361  0.38497055 0.42195016 0.3152046 ]
[Epoch=400, n_hypersteps=9]: prior precision: [0.10364784 0.07106162 0.07218401 0.12836991], sigma noise: [0.38537344 0.3866969  0.42432955 0.3152635 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.10365666 0.07045969 0.07229284 0.12879358], sigma noise: [0.38690525 0.38819695 0.42645565 0.3151919 ]
[Epoch=400, n_hypersteps=11]: prior precision: [0.10366872 0.06985474 0.07238355 0.12919693], sigma noise: [0.38812473 0.38936353 0.42819118 0.31493726]
[Epoch=400, n_hypersteps=12]: prior precision: [0.10367876 0.06926426 0.07245974 0.12958269], sigma noise: [0.38896686 0.39013237 0.42944247 0.31445947]
[Epoch=400, n_hypersteps=13]: prior precision: [0.10369025 0.06869052 0.07252321 0.12994963], sigma noise: [0.38940248 0.39046878 0.43018022 0.3137464 ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.10368929 0.06813137 0.07257112 0.1302916 ], sigma noise: [0.38944012 0.39038298 0.43041697 0.31281105]
[Epoch=400, n_hypersteps=15]: prior precision: [0.1036839  0.06760037 0.0726049  0.13061923], sigma noise: [0.3891275  0.38993767 0.4302119  0.3116881 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.10367411 0.06709843 0.07262775 0.13092881], sigma noise: [0.38854063 0.38920727 0.42965186 0.31041965]
[Epoch=400, n_hypersteps=17]: prior precision: [0.10366111 0.06662495 0.07263909 0.13122924], sigma noise: [0.38777637 0.38829052 0.4288635  0.3090712 ]
[Epoch=400, n_hypersteps=18]: prior precision: [0.10364796 0.06617326 0.07264317 0.13152038], sigma noise: [0.3869411  0.38729772 0.4279762  0.3076964 ]
[Epoch=400, n_hypersteps=19]: prior precision: [0.10362582 0.06575316 0.07263981 0.13179462], sigma noise: [0.38612953 0.38633245 0.4271109  0.3063511 ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.10360339 0.065359   0.07262769 0.13206536], sigma noise: [0.38543528 0.38547608 0.42638615 0.30508935]
[Epoch=400, n_hypersteps=21]: prior precision: [0.10358294 0.06499334 0.07260713 0.13231918], sigma noise: [0.3849299  0.38480884 0.42587736 0.3039527 ]
[Epoch=400, n_hypersteps=22]: prior precision: [0.10356455 0.06465481 0.07257809 0.13255073], sigma noise: [0.38466257 0.38438737 0.42565513 0.30295548]
[Epoch=400, n_hypersteps=23]: prior precision: [0.10354543 0.06435567 0.07254557 0.13276719], sigma noise: [0.38465026 0.38422787 0.4257487  0.30211622]
[Epoch=400, n_hypersteps=24]: prior precision: [0.10353171 0.06409572 0.07250956 0.1329726 ], sigma noise: [0.3848909  0.38432533 0.42615002 0.30143008]
[Epoch=400, n_hypersteps=25]: prior precision: [0.10351826 0.0638665  0.07246883 0.13315146], sigma noise: [0.38535845 0.3846477  0.42682368 0.30088055]
[Epoch=400, n_hypersteps=26]: prior precision: [0.10351431 0.06367274 0.07242257 0.1332935 ], sigma noise: [0.3860046  0.38515    0.4277075  0.30043444]
[Epoch=400, n_hypersteps=27]: prior precision: [0.10351534 0.06351344 0.07237417 0.13342288], sigma noise: [0.3867653  0.38577005 0.4287352  0.30006528]
[Epoch=400, n_hypersteps=28]: prior precision: [0.10352359 0.06338325 0.07232045 0.13355248], sigma noise: [0.38757387 0.38643497 0.4298095  0.29973754]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.56301
wandb:                       Metrics 0.55864
wandb:  Negative_marginal_likelihood 1238.63647
wandb: Predictive_posterior_std_mean 0.76217
wandb:                   Sigma_noise 0.75891
wandb: 
wandb: üöÄ View run efficient-sweep-3 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/71iznyqs
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165922-71iznyqs/logs
wandb: Agent Starting Run: 6cje0p1f with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_170044-6cje0p1f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/6cje0p1f
[Epoch=400, n_hypersteps=29]: prior precision: [0.10353295 0.06328143 0.07226424 0.13366275], sigma noise: [0.3883603  0.38707528 0.4308612  0.29941693]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8190577  0.81905663 0.8190541  0.81905574], sigma noise: [0.8188786  0.8188792  0.81887865 0.8188764 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74190015 0.7418966  0.7418875  0.7418934 ], sigma noise: [0.74137276 0.7413749  0.74137306 0.74136454]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6726256  0.6726182  0.67259717 0.6726105 ], sigma noise: [0.6716738  0.67167896 0.6716749  0.67165405]
[Epoch=100, n_hypersteps=5]: prior precision: [0.61052465 0.61051154 0.6104725  0.6104973 ], sigma noise: [0.60924786 0.609258   0.6092505  0.60920835]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5549239  0.5549031  0.5548395  0.55487967], sigma noise: [0.5536877  0.55370516 0.55369276 0.5536162 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50519043 0.50516003 0.5050648  0.505125  ], sigma noise: [0.5047353  0.5047628  0.50474495 0.50461376]
[Epoch=100, n_hypersteps=8]: prior precision: [0.4607348  0.4606925  0.46055943 0.4606438 ], sigma noise: [0.4623111  0.46235263 0.46232885 0.46211252]
[Epoch=100, n_hypersteps=9]: prior precision: [0.4210128  0.4209561  0.4207789  0.42089164], sigma noise: [0.42653105 0.42659175 0.4265637  0.42621487]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38552493 0.38545159 0.38522416 0.3853697 ], sigma noise: [0.3976682  0.39775407 0.39772484 0.3971778 ]
[Epoch=100, n_hypersteps=11]: prior precision: [0.3538164  0.35372353 0.3534417  0.35362327], sigma noise: [0.3760001  0.37611848 0.3760914  0.37526232]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32547465 0.32536    0.32502037 0.32524002], sigma noise: [0.36154944 0.36170924 0.3616891  0.36048058]
[Epoch=100, n_hypersteps=13]: prior precision: [0.3001278  0.29998922 0.2995883  0.29984865], sigma noise: [0.35390082 0.35411105 0.35410437 0.35241556]
[Epoch=100, n_hypersteps=14]: prior precision: [0.27744174 0.27727774 0.27681273 0.2771152 ], sigma noise: [0.35227075 0.35254118 0.35254952 0.3502843 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.25711694 0.25692692 0.25639597 0.2567424 ], sigma noise: [0.35573092 0.35606843 0.35609442 0.3531574 ]
[Epoch=100, n_hypersteps=16]: prior precision: [0.23888595 0.23867008 0.23807275 0.2384637 ], sigma noise: [0.36337706 0.3637919  0.36383843 0.3601265 ]
[Epoch=100, n_hypersteps=17]: prior precision: [0.22251211 0.22227032 0.22160676 0.22204244], sigma noise: [0.37438324 0.3748843  0.37495688 0.3703568 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.2077854  0.207518   0.2067888  0.20726924], sigma noise: [0.3879729  0.3885738  0.38867456 0.38306302]
[Epoch=100, n_hypersteps=19]: prior precision: [0.19452047 0.19422752 0.19343376 0.19395864], sigma noise: [0.40337387 0.40408823 0.40422025 0.39747012]
[Epoch=100, n_hypersteps=20]: prior precision: [0.1825529  0.18223487 0.18137826 0.18194683], sigma noise: [0.41978776 0.42063016 0.42079085 0.41278687]
[Epoch=100, n_hypersteps=21]: prior precision: [0.17173839 0.17139542 0.17047742 0.17108956], sigma noise: [0.4363874  0.43737024 0.43755856 0.4282039 ]
[Epoch=100, n_hypersteps=22]: prior precision: [0.16194963 0.16158205 0.16060413 0.1612593 ], sigma noise: [0.45234483 0.45347407 0.45368677 0.44292635]
[Epoch=100, n_hypersteps=23]: prior precision: [0.15307435 0.15268254 0.15164651 0.15234362], sigma noise: [0.466877   0.46815223 0.46838513 0.45621923]
[Epoch=100, n_hypersteps=24]: prior precision: [0.1450134  0.14459787 0.14350541 0.14424367], sigma noise: [0.47930402 0.48071954 0.4809648  0.46745732]
[Epoch=100, n_hypersteps=25]: prior precision: [0.13767968 0.13724074 0.13609366 0.13687216], sigma noise: [0.4890972  0.49064383 0.49089253 0.47616798]
[Epoch=100, n_hypersteps=26]: prior precision: [0.13099632 0.13053417 0.1293341  0.13015243], sigma noise: [0.49592304 0.4975864  0.4978242  0.48206252]
[Epoch=100, n_hypersteps=27]: prior precision: [0.12489496 0.12441053 0.1231588  0.12401648], sigma noise: [0.49964824 0.50140524 0.50162417 0.4850417 ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.11931588 0.11880989 0.11750752 0.1184037 ], sigma noise: [0.5003329  0.50216085 0.50235224 0.48517895]
[Epoch=100, n_hypersteps=29]: prior precision: [0.11420679 0.11367936 0.11232726 0.11326139], sigma noise: [0.4982063  0.5000803  0.5002355  0.48270044]
[Epoch=200, n_hypersteps=0]: prior precision: [0.10952053 0.10897208 0.10757086 0.10854266], sigma noise: [0.49363178 0.49553198 0.49564144 0.4779547 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.10519449 0.10459416 0.10314534 0.1042325 ], sigma noise: [0.4860233  0.48792014 0.48797742 0.47039416]
[Epoch=200, n_hypersteps=2]: prior precision: [0.10119623 0.10052041 0.09902594 0.10028733], sigma noise: [0.4760706  0.47794074 0.4779409  0.46065736]
[Epoch=200, n_hypersteps=3]: prior precision: [0.09749725 0.09672795 0.09518889 0.09666877], sigma noise: [0.46450236 0.46632588 0.46626717 0.44941616]
[Epoch=200, n_hypersteps=4]: prior precision: [0.09407157 0.09319524 0.09161261 0.09334328], sigma noise: [0.45204145 0.45381013 0.4537002  0.43733847]
[Epoch=200, n_hypersteps=5]: prior precision: [0.09089562 0.08990403 0.0882773  0.09028151], sigma noise: [0.43938276 0.44109514 0.44093406 0.42506242]
[Epoch=200, n_hypersteps=6]: prior precision: [0.08794829 0.08683559 0.08516429 0.08745754], sigma noise: [0.42716435 0.42882782 0.4286151  0.41317394]
[Epoch=200, n_hypersteps=7]: prior precision: [0.08521046 0.08397204 0.08225687 0.08484818], sigma noise: [0.41595262 0.41757867 0.4173166  0.40218967]
[Epoch=200, n_hypersteps=8]: prior precision: [0.08266458 0.08129737 0.0795391  0.08243305], sigma noise: [0.40621698 0.40781987 0.40750873 0.39254266]
[Epoch=200, n_hypersteps=9]: prior precision: [0.0802949  0.07879878 0.0769958  0.08019469], sigma noise: [0.398327   0.39992547 0.39956436 0.38456666]
[Epoch=200, n_hypersteps=10]: prior precision: [0.07808701 0.07646269 0.07461441 0.0781168 ], sigma noise: [0.3925331  0.3941505  0.3937381  0.37848628]
[Epoch=200, n_hypersteps=11]: prior precision: [0.07602743 0.07427612 0.07238252 0.07618418], sigma noise: [0.38896585 0.3906197  0.3901519  0.3744114 ]
[Epoch=200, n_hypersteps=12]: prior precision: [0.07410463 0.07222728 0.07028904 0.07438415], sigma noise: [0.38763162 0.38934588 0.3888173  0.372335  ]
[Epoch=200, n_hypersteps=13]: prior precision: [0.07230741 0.07030588 0.06832321 0.0727048 ], sigma noise: [0.3884228  0.39022055 0.38962817 0.37214717]
[Epoch=200, n_hypersteps=14]: prior precision: [0.07062495 0.06850282 0.06647541 0.07113544], sigma noise: [0.3911333  0.39303443 0.3923743  0.37364247]
[Epoch=200, n_hypersteps=15]: prior precision: [0.06904846 0.06680851 0.06473641 0.06966651], sigma noise: [0.3954714  0.39749625 0.39675707 0.37653956]
[Epoch=200, n_hypersteps=16]: prior precision: [0.0675694  0.06521506 0.06309836 0.06828938], sigma noise: [0.40107664 0.4032436  0.40240762 0.38050398]
[Epoch=200, n_hypersteps=17]: prior precision: [0.06617961 0.06371423 0.06155412 0.0669961 ], sigma noise: [0.4075352  0.40985912 0.40893057 0.3851658 ]
[Epoch=200, n_hypersteps=18]: prior precision: [0.06487264 0.06230018 0.06009658 0.0657796 ], sigma noise: [0.4144162  0.4169107  0.41588223 0.39014015]
[Epoch=200, n_hypersteps=19]: prior precision: [0.06364185 0.06096609 0.05871889 0.06463362], sigma noise: [0.42128178 0.4239484  0.42282015 0.3950496 ]
[Epoch=200, n_hypersteps=20]: prior precision: [0.06248139 0.05970616 0.05741562 0.06355277], sigma noise: [0.4277225  0.43055153 0.42932093 0.39955193]
[Epoch=200, n_hypersteps=21]: prior precision: [0.06138596 0.05851397 0.05618143 0.06253152], sigma noise: [0.4333687  0.43634745 0.4350332  0.4033542 ]
[Epoch=200, n_hypersteps=22]: prior precision: [0.06035045 0.057385   0.05501107 0.06156523], sigma noise: [0.43792987 0.44105127 0.43966284 0.40623248]
[Epoch=200, n_hypersteps=23]: prior precision: [0.05936999 0.05631469 0.05390008 0.06064944], sigma noise: [0.4412121  0.44445193 0.4429991  0.40804294]
[Epoch=200, n_hypersteps=24]: prior precision: [0.05844088 0.05530004 0.05284468 0.05978029], sigma noise: [0.4431125  0.44644833 0.44493708 0.4087193 ]
[Epoch=200, n_hypersteps=25]: prior precision: [0.05755954 0.05433704 0.05184132 0.05895465], sigma noise: [0.44362903 0.4470375  0.44546962 0.4082801 ]
[Epoch=200, n_hypersteps=26]: prior precision: [0.05672272 0.05342207 0.05088649 0.05816976], sigma noise: [0.44285423 0.4463053  0.4446917  0.40681294]
[Epoch=200, n_hypersteps=27]: prior precision: [0.05592776 0.05255162 0.04997732 0.05742214], sigma noise: [0.44096103 0.44443476 0.44279253 0.40446597]
[Epoch=200, n_hypersteps=28]: prior precision: [0.05517207 0.05172298 0.04911075 0.05670921], sigma noise: [0.43818557 0.44165337 0.44000664 0.40142572]
[Epoch=200, n_hypersteps=29]: prior precision: [0.05445347 0.05093292 0.04828409 0.0560284 ], sigma noise: [0.43479478 0.4382584  0.43660957 0.39790955]
[Epoch=300, n_hypersteps=0]: prior precision: [0.0537698  0.05018008 0.04749525 0.0553783 ], sigma noise: [0.43107668 0.4345416  0.43287614 0.39414605]
[Epoch=300, n_hypersteps=1]: prior precision: [0.05312643 0.04945235 0.04673925 0.05478134], sigma noise: [0.42756325 0.4310107  0.429441   0.39050922]
[Epoch=300, n_hypersteps=2]: prior precision: [0.05252041 0.04874979 0.0460145  0.0542323 ], sigma noise: [0.42447597 0.42790017 0.42652267 0.38717505]
[Epoch=300, n_hypersteps=3]: prior precision: [0.05194875 0.04807068 0.0453185  0.05372659], sigma noise: [0.42199525 0.4253942  0.42429516 0.38428184]
[Epoch=300, n_hypersteps=4]: prior precision: [0.05140872 0.04741456 0.0446506  0.05325996], sigma noise: [0.42024553 0.4236222  0.42287737 0.38192734]
[Epoch=300, n_hypersteps=5]: prior precision: [0.05089783 0.04678066 0.04400903 0.05282901], sigma noise: [0.41929606 0.4226516  0.4223261  0.38016275]
[Epoch=300, n_hypersteps=6]: prior precision: [0.05041436 0.04616806 0.04339288 0.05243037], sigma noise: [0.4191529  0.42249653 0.42265144 0.37898672]
[Epoch=300, n_hypersteps=7]: prior precision: [0.04995642 0.04557597 0.04280008 0.05206131], sigma noise: [0.41976228 0.42310363 0.42380562 0.37835747]
[Epoch=300, n_hypersteps=8]: prior precision: [0.04952236 0.04500339 0.04222992 0.05171963], sigma noise: [0.4210291  0.42437676 0.42567888 0.37819785]
[Epoch=300, n_hypersteps=9]: prior precision: [0.04911057 0.04444981 0.04168118 0.05140232], sigma noise: [0.42281386 0.4261758  0.42813927 0.3784033 ]
[Epoch=300, n_hypersteps=10]: prior precision: [0.04871897 0.04391503 0.04115256 0.05110734], sigma noise: [0.4249531  0.42833257 0.4310209  0.3788465 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.04834642 0.04339803 0.0406427  0.05083293], sigma noise: [0.4272713  0.43066302 0.4341376  0.37940022]
[Epoch=300, n_hypersteps=12]: prior precision: [0.04799076 0.04289803 0.04015125 0.05057728], sigma noise: [0.42959028 0.4329938  0.43729714 0.37993857]
[Epoch=300, n_hypersteps=13]: prior precision: [0.04765134 0.04241452 0.0396778  0.0503385 ], sigma noise: [0.4317496  0.4351458  0.44032052 0.3803459 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.04732746 0.04194699 0.03922139 0.05011551], sigma noise: [0.43359506 0.43698332 0.44305748 0.3805325 ]
[Epoch=300, n_hypersteps=15]: prior precision: [0.04701745 0.04149466 0.03878084 0.04990632], sigma noise: [0.43502653 0.43839395 0.44537783 0.38042697]
[Epoch=300, n_hypersteps=16]: prior precision: [0.04672069 0.04105677 0.03835575 0.04970997], sigma noise: [0.43598232 0.43930808 0.44719905 0.37998778]
[Epoch=300, n_hypersteps=17]: prior precision: [0.04643632 0.04063274 0.03794554 0.04952552], sigma noise: [0.43642938 0.43970028 0.44849256 0.37920445]
[Epoch=300, n_hypersteps=18]: prior precision: [0.04616345 0.04022231 0.03754929 0.04935155], sigma noise: [0.43637174 0.4395812  0.44925836 0.378094  ]
[Epoch=300, n_hypersteps=19]: prior precision: [0.04590134 0.0398248  0.03716597 0.04918754], sigma noise: [0.4358653  0.43899834 0.449545   0.37669644]
[Epoch=300, n_hypersteps=20]: prior precision: [0.04565027 0.03944016 0.03679543 0.04903283], sigma noise: [0.43498707 0.43804    0.4494284  0.37506413]
[Epoch=300, n_hypersteps=21]: prior precision: [0.04540894 0.03906761 0.03643688 0.04888621], sigma noise: [0.4338498  0.43681982 0.4490254  0.37327105]
[Epoch=300, n_hypersteps=22]: prior precision: [0.04517709 0.03870615 0.03608962 0.04874757], sigma noise: [0.43257165 0.4354514  0.44845873 0.37139344]
[Epoch=300, n_hypersteps=23]: prior precision: [0.04495424 0.03835603 0.03575299 0.04861605], sigma noise: [0.4312706  0.43405584 0.4478552  0.36950797]
[Epoch=300, n_hypersteps=24]: prior precision: [0.04473966 0.03801647 0.03542724 0.04849077], sigma noise: [0.43004647 0.43274018 0.44734854 0.36768833]
[Epoch=300, n_hypersteps=25]: prior precision: [0.04453295 0.03768733 0.03511206 0.04837185], sigma noise: [0.4289969  0.43159795 0.44703507 0.36598945]
[Epoch=300, n_hypersteps=26]: prior precision: [0.04433394 0.03736841 0.03480662 0.04825813], sigma noise: [0.4281864  0.4307     0.44697377 0.36445522]
[Epoch=300, n_hypersteps=27]: prior precision: [0.04414177 0.03705941 0.03451094 0.04814956], sigma noise: [0.42765447 0.43008664 0.44721466 0.36311367]
[Epoch=300, n_hypersteps=28]: prior precision: [0.0439566  0.03676009 0.0342241  0.04804628], sigma noise: [0.42743218 0.42978022 0.44778365 0.36197382]
[Epoch=300, n_hypersteps=29]: prior precision: [0.04377782 0.03647019 0.03394602 0.04794806], sigma noise: [0.42750895 0.42977843 0.44869033 0.3610307 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.04360526 0.03618923 0.03367642 0.04785383], sigma noise: [0.42783764 0.4300595  0.44989684 0.3602598 ]
[Epoch=400, n_hypersteps=1]: prior precision: [0.04347228 0.03591586 0.03343626 0.0477971 ], sigma noise: [0.4288596  0.43094537 0.4518531  0.35985494]
[Epoch=400, n_hypersteps=2]: prior precision: [0.04337501 0.03564984 0.03322269 0.04777442], sigma noise: [0.43042946 0.43230048 0.45441386 0.35973135]
[Epoch=400, n_hypersteps=3]: prior precision: [0.04331026 0.03539094 0.03303301 0.04778261], sigma noise: [0.4323756  0.4339559  0.45737362 0.35978723]
[Epoch=400, n_hypersteps=4]: prior precision: [0.04327498 0.03513878 0.03286484 0.04781901], sigma noise: [0.43451098 0.43573463 0.46053085 0.3599149 ]
[Epoch=400, n_hypersteps=5]: prior precision: [0.04326585 0.0348934  0.03271607 0.04788107], sigma noise: [0.43664995 0.4374489  0.46366683 0.36000922]
[Epoch=400, n_hypersteps=6]: prior precision: [0.04328129 0.03465436 0.03258504 0.04796665], sigma noise: [0.4386235  0.43893933 0.46657652 0.35997814]
[Epoch=400, n_hypersteps=7]: prior precision: [0.0433187  0.03442148 0.03247026 0.04807369], sigma noise: [0.440293   0.44006884 0.46910208 0.35975164]
[Epoch=400, n_hypersteps=8]: prior precision: [0.04337602 0.0341944  0.0323698  0.04820042], sigma noise: [0.44155407 0.44075963 0.4711174  0.35928085]
[Epoch=400, n_hypersteps=9]: prior precision: [0.04345136 0.03397296 0.03228265 0.04834532], sigma noise: [0.44235685 0.44095364 0.4725436  0.3585469 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.04354349 0.03375691 0.03220746 0.04850693], sigma noise: [0.4426972  0.44065055 0.47336912 0.35755405]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.217 MB of 0.217 MB uploaded (0.000 MB deduped)wandb: \ 0.229 MB of 0.306 MB uploaded (0.000 MB deduped)wandb: | 0.229 MB of 0.306 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.7105
wandb:                       Metrics 0.7058
wandb:  Negative_marginal_likelihood 1356.05371
wandb: Predictive_posterior_std_mean 0.85846
wandb:                   Sigma_noise 0.85523
wandb: 
wandb: üöÄ View run fine-sweep-4 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/6cje0p1f
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_170044-6cje0p1f/logs
wandb: Agent Starting Run: ii96xgii with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_171110-ii96xgii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ii96xgii
[Epoch=400, n_hypersteps=11]: prior precision: [0.04365062 0.03354615 0.03214322 0.0486841 ], sigma noise: [0.44260946 0.43989253 0.4736505  0.35632864]
[Epoch=400, n_hypersteps=12]: prior precision: [0.0437713  0.03334044 0.03208878 0.04887564], sigma noise: [0.4421677  0.4387644  0.47346276 0.35491604]
[Epoch=400, n_hypersteps=13]: prior precision: [0.0439048  0.03313958 0.03204339 0.04908043], sigma noise: [0.44146842 0.43737152 0.47294614 0.35337248]
[Epoch=400, n_hypersteps=14]: prior precision: [0.04404971 0.03294369 0.03200622 0.04929766], sigma noise: [0.4406319  0.4358337  0.47223645 0.3517624 ]
[Epoch=400, n_hypersteps=15]: prior precision: [0.04420541 0.03275254 0.03197667 0.04952656], sigma noise: [0.43977866 0.43427226 0.47149074 0.35014987]
[Epoch=400, n_hypersteps=16]: prior precision: [0.04437068 0.03256606 0.03195379 0.04976637], sigma noise: [0.43902206 0.43279767 0.47084385 0.34859413]
[Epoch=400, n_hypersteps=17]: prior precision: [0.04454481 0.03238404 0.03193701 0.05001641], sigma noise: [0.43845427 0.43150008 0.47040322 0.34714466]
[Epoch=400, n_hypersteps=18]: prior precision: [0.04472682 0.03220636 0.03192583 0.05027617], sigma noise: [0.4381475  0.43045533 0.4702709  0.34583503]
[Epoch=400, n_hypersteps=19]: prior precision: [0.04491581 0.03203308 0.03191981 0.05054492], sigma noise: [0.4381383  0.42969328 0.47049332 0.34468347]
[Epoch=400, n_hypersteps=20]: prior precision: [0.04511143 0.0318642  0.03191841 0.05082226], sigma noise: [0.43843636 0.4292258  0.47108284 0.34369397]
[Epoch=400, n_hypersteps=21]: prior precision: [0.04531277 0.03169942 0.03192136 0.05110768], sigma noise: [0.43901497 0.42903084 0.4720096  0.34285474]
[Epoch=400, n_hypersteps=22]: prior precision: [0.0455192  0.03153852 0.03192821 0.05140077], sigma noise: [0.43983486 0.4290661  0.47322586 0.34214273]
[Epoch=400, n_hypersteps=23]: prior precision: [0.04573018 0.03138133 0.03193834 0.05170116], sigma noise: [0.44082847 0.4292693  0.47465014 0.3415259 ]
[Epoch=400, n_hypersteps=24]: prior precision: [0.04594539 0.03122788 0.03195171 0.05200846], sigma noise: [0.44192645 0.42956626 0.476179   0.34096897]
[Epoch=400, n_hypersteps=25]: prior precision: [0.04616452 0.03107817 0.03196792 0.05232235], sigma noise: [0.44304478 0.42988944 0.47773725 0.34043267]
[Epoch=400, n_hypersteps=26]: prior precision: [0.04638743 0.03093192 0.03198674 0.0526427 ], sigma noise: [0.4441061  0.4301787  0.47922182 0.33988398]
[Epoch=400, n_hypersteps=27]: prior precision: [0.04661326 0.03078892 0.03200788 0.05296922], sigma noise: [0.44504577 0.4303725  0.48054048 0.33929333]
[Epoch=400, n_hypersteps=28]: prior precision: [0.04684106 0.03064917 0.03203109 0.05330151], sigma noise: [0.44581625 0.43042925 0.4816312  0.3386399 ]
[Epoch=400, n_hypersteps=29]: prior precision: [0.04707068 0.03051252 0.03205612 0.05363949], sigma noise: [0.4463883  0.43033242 0.48246926 0.33791333]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.81907237 0.81906724 0.8190613  0.8190866 ], sigma noise: [0.8188671  0.81886727 0.81886804 0.8188632 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7419503 0.7419334 0.7419124 0.7419998], sigma noise: [0.74132776 0.7413287  0.7413318  0.7413136 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6727361  0.6726998  0.6726528  0.67284685], sigma noise: [0.6715594  0.67156184 0.67157    0.67152524]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6107216  0.6106587  0.61057353 0.6109241 ], sigma noise: [0.6090074  0.60901225 0.6090302  0.6089396 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55523324 0.55513674 0.5550013  0.55556023], sigma noise: [0.5532342  0.55324215 0.5532781  0.5531128 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50563747 0.50550014 0.50530356 0.5061238 ], sigma noise: [0.50393754 0.50394917 0.5040155  0.50373375]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46134385 0.46115774 0.4608901  0.46202728], sigma noise: [0.46097583 0.4609904  0.46110713 0.46064597]
[Epoch=100, n_hypersteps=9]: prior precision: [0.4218037  0.4215623  0.42121664 0.42272425], sigma noise: [0.42438692 0.42440298 0.42460066 0.4238672 ]
[Epoch=100, n_hypersteps=10]: prior precision: [0.3865157  0.38621223 0.38578317 0.38771337], sigma noise: [0.39437473 0.39438888 0.39471033 0.39357165]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35502356 0.35465044 0.35413542 0.35652858], sigma noise: [0.37120217 0.37120765 0.37171277 0.36999252]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32691306 0.3264625  0.32585746 0.3287517 ], sigma noise: [0.3549771  0.35496992 0.35572597 0.35321382]
[Epoch=100, n_hypersteps=13]: prior precision: [0.30180874 0.30127332 0.30057704 0.30400857], sigma noise: [0.34544417 0.3454185  0.34649706 0.34296945]
[Epoch=100, n_hypersteps=14]: prior precision: [0.27937636 0.27874714 0.27796102 0.2819614 ], sigma noise: [0.3419629  0.3419068  0.3433876  0.33862028]
[Epoch=100, n_hypersteps=15]: prior precision: [0.25931376 0.25858358 0.25770992 0.26230273], sigma noise: [0.34368283 0.34359023 0.34554544 0.33931744]
[Epoch=100, n_hypersteps=16]: prior precision: [0.2413517  0.2405142  0.23955582 0.24475764], sigma noise: [0.34973443 0.34959844 0.3521058  0.34418547]
[Epoch=100, n_hypersteps=17]: prior precision: [0.2252524  0.22430079 0.22326078 0.22908446], sigma noise: [0.35931262 0.35912585 0.36227053 0.3524027 ]
[Epoch=100, n_hypersteps=18]: prior precision: [0.21080461 0.20973366 0.20861273 0.21506788], sigma noise: [0.37166777 0.3714241  0.3752995  0.36320597]
[Epoch=100, n_hypersteps=19]: prior precision: [0.19782023 0.19662806 0.19542456 0.20251599], sigma noise: [0.3860696  0.38576233 0.3904637  0.37585565]
[Epoch=100, n_hypersteps=20]: prior precision: [0.18613124 0.18481994 0.18353327 0.19126192], sigma noise: [0.40176734 0.40139169 0.40701565 0.38960984]
[Epoch=100, n_hypersteps=21]: prior precision: [0.17559223 0.17416404 0.17279428 0.18115777], sigma noise: [0.4179802  0.41752926 0.42416465 0.4037139 ]
[Epoch=100, n_hypersteps=22]: prior precision: [0.16607475 0.16453332 0.16308066 0.17207243], sigma noise: [0.4339121  0.43338308 0.4410908  0.4174241 ]
[Epoch=100, n_hypersteps=23]: prior precision: [0.1574653  0.15581417 0.15427949 0.16389368], sigma noise: [0.44878745 0.44817978 0.45698872 0.43004295]
[Epoch=100, n_hypersteps=24]: prior precision: [0.14966668 0.14790712 0.14629163 0.15652646], sigma noise: [0.46190184 0.4612227  0.47111475 0.44096255]
[Epoch=100, n_hypersteps=25]: prior precision: [0.14259093 0.14072469 0.13902968 0.14988235], sigma noise: [0.47267967 0.47193804 0.48284402 0.44970596]
[Epoch=100, n_hypersteps=26]: prior precision: [0.13616097 0.1341898  0.13241604 0.14388578], sigma noise: [0.48071387 0.47991884 0.49172485 0.45595607]
[Epoch=100, n_hypersteps=27]: prior precision: [0.13030979 0.12823363 0.12638272 0.13846709], sigma noise: [0.4857849  0.4849516  0.49750653 0.45956093]
[Epoch=100, n_hypersteps=28]: prior precision: [0.12497881 0.12279734 0.12087028 0.1335675 ], sigma noise: [0.4878636  0.4870078  0.50013924 0.4605323 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.12011489 0.11782848 0.11582562 0.12913442], sigma noise: [0.48709562 0.4862316  0.49975732 0.45902345]
[Epoch=200, n_hypersteps=0]: prior precision: [0.11567142 0.11328059 0.11120336 0.12512338], sigma noise: [0.48377037 0.48291147 0.49665716 0.45530504]
[Epoch=200, n_hypersteps=1]: prior precision: [0.11162167 0.10908567 0.10696276 0.12166248], sigma noise: [0.47696334 0.47611853 0.489804   0.44859922]
[Epoch=200, n_hypersteps=2]: prior precision: [0.1079262  0.10521336 0.10306697 0.11869038], sigma noise: [0.4673702  0.4665428  0.47994488 0.43950462]
[Epoch=200, n_hypersteps=3]: prior precision: [0.10455195 0.10163608 0.09948261 0.11614998], sigma noise: [0.4557454  0.45493641 0.4678968  0.42866313]
[Epoch=200, n_hypersteps=4]: prior precision: [0.10146885 0.09832902 0.09618199 0.11399262], sigma noise: [0.4428524  0.4420597  0.4544839  0.41671875]
[Epoch=200, n_hypersteps=5]: prior precision: [0.09865166 0.09527088 0.09313823 0.11218028], sigma noise: [0.42942408 0.42864385 0.44050318 0.40429595]
[Epoch=200, n_hypersteps=6]: prior precision: [0.09607732 0.09244052 0.09032815 0.11068255], sigma noise: [0.4161487  0.415372   0.42668253 0.39197534]
[Epoch=200, n_hypersteps=7]: prior precision: [0.09372524 0.0898198  0.08773131 0.10946613], sigma noise: [0.4036348  0.40285093 0.4136795  0.38027984]
[Epoch=200, n_hypersteps=8]: prior precision: [0.09157643 0.0873923  0.08532923 0.10850545], sigma noise: [0.39241126 0.39160538 0.4020597  0.36966395]
[Epoch=200, n_hypersteps=9]: prior precision: [0.08961307 0.08514304 0.08310673 0.10777929], sigma noise: [0.38290885 0.3820637  0.3922765  0.36049655]
[Epoch=200, n_hypersteps=10]: prior precision: [0.08781962 0.08305863 0.08104742 0.10726924], sigma noise: [0.3754503  0.37454855 0.3846782  0.35304666]
[Epoch=200, n_hypersteps=11]: prior precision: [0.08618332 0.08112442 0.07913913 0.10695843], sigma noise: [0.3702357  0.36926255 0.3794703  0.34747863]
[Epoch=200, n_hypersteps=12]: prior precision: [0.08469126 0.07933007 0.07736661 0.10683334], sigma noise: [0.36734617 0.3662738  0.37675095 0.34385005]
[Epoch=200, n_hypersteps=13]: prior precision: [0.08333234 0.0776642  0.07572077 0.10687767], sigma noise: [0.36673832 0.36554202 0.37647325 0.34210846]
[Epoch=200, n_hypersteps=14]: prior precision: [0.08209553 0.07611572 0.0741898  0.10707827], sigma noise: [0.36826274 0.36691612 0.37848833 0.34210756]
[Epoch=200, n_hypersteps=15]: prior precision: [0.08096962 0.07467576 0.07276523 0.10742286], sigma noise: [0.37167773 0.37015307 0.38254514 0.34361577]
[Epoch=200, n_hypersteps=16]: prior precision: [0.0799447  0.07333608 0.07143518 0.10790148], sigma noise: [0.37665814 0.37492633 0.38830587 0.34633976]
[Epoch=200, n_hypersteps=17]: prior precision: [0.07901198 0.07208825 0.07019279 0.10850561], sigma noise: [0.382821   0.3808594  0.39537355 0.3499432 ]
[Epoch=200, n_hypersteps=18]: prior precision: [0.07816325 0.07092424 0.0690307  0.10922342], sigma noise: [0.3897401  0.38751757 0.40329233 0.35406765]
[Epoch=200, n_hypersteps=19]: prior precision: [0.07739035 0.06983737 0.0679424  0.11004349], sigma noise: [0.3969696  0.39447546 0.4115872  0.35835713]
[Epoch=200, n_hypersteps=20]: prior precision: [0.07668584 0.06882188 0.06692296 0.11095326], sigma noise: [0.4040641  0.40129948 0.41975552 0.3624718 ]
[Epoch=200, n_hypersteps=21]: prior precision: [0.0760434  0.06787242 0.06596426 0.11194532], sigma noise: [0.4106137  0.40757698 0.42735344 0.36611408]
[Epoch=200, n_hypersteps=22]: prior precision: [0.075459   0.06698298 0.06506231 0.11301158], sigma noise: [0.41626224 0.41296908 0.43397555 0.3690361 ]
[Epoch=200, n_hypersteps=23]: prior precision: [0.07492626 0.06614882 0.06421272 0.11415128], sigma noise: [0.42073682 0.41721132 0.43930125 0.37106055]
[Epoch=200, n_hypersteps=24]: prior precision: [0.07444092 0.06536622 0.06341171 0.11535671], sigma noise: [0.4238602  0.42012212 0.44311848 0.37208453]
[Epoch=200, n_hypersteps=25]: prior precision: [0.0739994  0.06463142 0.06265555 0.11662376], sigma noise: [0.4255442  0.42162514 0.44532388 0.37207788]
[Epoch=200, n_hypersteps=26]: prior precision: [0.07359852 0.06394152 0.06194105 0.1179435 ], sigma noise: [0.4258134  0.42173928 0.4459448  0.37108138]
[Epoch=200, n_hypersteps=27]: prior precision: [0.07323589 0.06329328 0.06126524 0.11930928], sigma noise: [0.424786   0.42059052 0.44510397 0.36919194]
[Epoch=200, n_hypersteps=28]: prior precision: [0.07290919 0.06268337 0.06062569 0.12072141], sigma noise: [0.42265218 0.41836128 0.44301364 0.36654836]
[Epoch=200, n_hypersteps=29]: prior precision: [0.07261477 0.06210995 0.06001973 0.12217517], sigma noise: [0.4196522  0.4152974  0.43994582 0.3633259 ]
[Epoch=300, n_hypersteps=0]: prior precision: [0.07235038 0.06157088 0.05944606 0.12366465], sigma noise: [0.41606754 0.41167167 0.4362232  0.35971844]
[Epoch=300, n_hypersteps=1]: prior precision: [0.0721499  0.06106101 0.05890601 0.1253576 ], sigma noise: [0.41162676 0.4072478  0.43148783 0.3555235 ]
[Epoch=300, n_hypersteps=2]: prior precision: [0.07200726 0.06058034 0.05839796 0.12724048], sigma noise: [0.40671012 0.4023882  0.42617232 0.35099587]
[Epoch=300, n_hypersteps=3]: prior precision: [0.07191862 0.06012726 0.05791992 0.12930429], sigma noise: [0.4016919  0.39745867 0.42070642 0.34638706]
[Epoch=300, n_hypersteps=4]: prior precision: [0.07188079 0.05970068 0.05746906 0.13154148], sigma noise: [0.39692032 0.3927913  0.41548482 0.34193042]
[Epoch=300, n_hypersteps=5]: prior precision: [0.07189046 0.05929936 0.05704442 0.13395083], sigma noise: [0.3927015  0.3886706  0.41087273 0.3378277 ]
[Epoch=300, n_hypersteps=6]: prior precision: [0.07194457 0.05892339 0.05664332 0.13652757], sigma noise: [0.38927928 0.3853474  0.40714237 0.33423883]
[Epoch=300, n_hypersteps=7]: prior precision: [0.07203927 0.05857122 0.05626496 0.13926467], sigma noise: [0.38682568 0.38298482 0.40449354 0.33127508]
[Epoch=300, n_hypersteps=8]: prior precision: [0.07217162 0.05824096 0.05590799 0.14215493], sigma noise: [0.38544005 0.38167623 0.40304095 0.3289949 ]
[Epoch=300, n_hypersteps=9]: prior precision: [0.07233829 0.05793177 0.05557074 0.1451885 ], sigma noise: [0.38514426 0.38143113 0.40281335 0.32740128]
[Epoch=300, n_hypersteps=10]: prior precision: [0.0725364  0.05764231 0.05525273 0.14836583], sigma noise: [0.38588312 0.3822009  0.40375608 0.32644933]
[Epoch=300, n_hypersteps=11]: prior precision: [0.07276232 0.05737149 0.0549534  0.15167734], sigma noise: [0.38753644 0.38387695 0.40572497 0.32605603]
[Epoch=300, n_hypersteps=12]: prior precision: [0.0730132  0.05711761 0.05467125 0.15511918], sigma noise: [0.38993287 0.38628882 0.40852907 0.32610136]
[Epoch=300, n_hypersteps=13]: prior precision: [0.07328586 0.05688058 0.05440288 0.15868832], sigma noise: [0.39286232 0.38923365 0.41193035 0.32644844]
[Epoch=300, n_hypersteps=14]: prior precision: [0.07357657 0.05665895 0.05414772 0.1623719 ], sigma noise: [0.3960866  0.39248174 0.41566607 0.3269507 ]
[Epoch=300, n_hypersteps=15]: prior precision: [0.07388391 0.05645017 0.05390477 0.16616666], sigma noise: [0.39936888 0.3957972  0.41944936 0.3274655 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.07420532 0.05625449 0.05367356 0.17007019], sigma noise: [0.40247974 0.39895424 0.4230447  0.3278656 ]
[Epoch=300, n_hypersteps=17]: prior precision: [0.07453869 0.05607301 0.05345379 0.17407456], sigma noise: [0.40522197 0.40175927 0.42619523 0.32804486]
[Epoch=300, n_hypersteps=18]: prior precision: [0.07488136 0.05590266 0.05324437 0.17816256], sigma noise: [0.40742674 0.4040586  0.4287356  0.32792643]
[Epoch=300, n_hypersteps=19]: prior precision: [0.07523143 0.05574309 0.05304454 0.18233149], sigma noise: [0.40899304 0.40574837 0.4305354  0.32746378]
[Epoch=300, n_hypersteps=20]: prior precision: [0.07558571 0.05559361 0.05285431 0.18657216], sigma noise: [0.40987137 0.40678418 0.4315339  0.32664132]
[Epoch=300, n_hypersteps=21]: prior precision: [0.07594391 0.05545379 0.05267306 0.19087546], sigma noise: [0.41007212 0.40716177 0.43174827 0.3254717 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.07630505 0.05532283 0.05249938 0.19523448], sigma noise: [0.40965405 0.40693024 0.4312508  0.32399458]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.214 MB of 0.303 MB uploaded (0.000 MB deduped)wandb: \ 0.215 MB of 0.303 MB uploaded (0.000 MB deduped)wandb: | 0.215 MB of 0.303 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.57301
wandb:                       Metrics 0.56857
wandb:  Negative_marginal_likelihood 1243.33789
wandb: Predictive_posterior_std_mean 0.76704
wandb:                   Sigma_noise 0.76384
wandb: 
wandb: üöÄ View run treasured-sweep-5 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ii96xgii
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_171110-ii96xgii/logs
wandb: Agent Starting Run: fee9mr7z with config:
wandb: 	activation_cls: elu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.001
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_172145-fee9mr7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/i1thic1u
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/fee9mr7z
[Epoch=300, n_hypersteps=23]: prior precision: [0.07666754 0.05520018 0.0523335  0.19964388], sigma noise: [0.4087271  0.40620378 0.4301589  0.32226968]
[Epoch=300, n_hypersteps=24]: prior precision: [0.07703055 0.05508463 0.05217542 0.20409784], sigma noise: [0.4074183  0.40511414 0.4286414  0.3203674 ]
[Epoch=300, n_hypersteps=25]: prior precision: [0.07739304 0.0549769  0.05202298 0.20858768], sigma noise: [0.40588507 0.40380868 0.42686656 0.31836763]
[Epoch=300, n_hypersteps=26]: prior precision: [0.07775518 0.05487593 0.05187753 0.21310751], sigma noise: [0.40428025 0.40244025 0.42502254 0.3163486 ]
[Epoch=300, n_hypersteps=27]: prior precision: [0.07811671 0.05478328 0.05173844 0.21764968], sigma noise: [0.40275183 0.40114373 0.4232685  0.31438538]
[Epoch=300, n_hypersteps=28]: prior precision: [0.07847767 0.05469795 0.05160537 0.2222018 ], sigma noise: [0.40143815 0.4000583  0.42174932 0.3125403 ]
[Epoch=300, n_hypersteps=29]: prior precision: [0.07883659 0.0546189  0.05147742 0.22675264], sigma noise: [0.40043217 0.39928567 0.42059204 0.31086022]
[Epoch=400, n_hypersteps=0]: prior precision: [0.07919211 0.05454606 0.0513539  0.2312937 ], sigma noise: [0.39980125 0.39889234 0.41987726 0.30937546]
[Epoch=400, n_hypersteps=1]: prior precision: [0.07957091 0.05445042 0.05123346 0.23616162], sigma noise: [0.39909643 0.39846134 0.419021   0.30784446]
[Epoch=400, n_hypersteps=2]: prior precision: [0.07997108 0.05433395 0.05111565 0.24134551], sigma noise: [0.39839774 0.39807224 0.41813132 0.3063081 ]
[Epoch=400, n_hypersteps=3]: prior precision: [0.08038925 0.0541988  0.0510009  0.24683572], sigma noise: [0.3977807  0.39779484 0.41728294 0.30480254]
[Epoch=400, n_hypersteps=4]: prior precision: [0.0808228  0.05404856 0.050889   0.25262257], sigma noise: [0.39730343 0.39767757 0.41656744 0.30335724]
[Epoch=400, n_hypersteps=5]: prior precision: [0.08127039 0.05388488 0.05078098 0.2586973 ], sigma noise: [0.39701164 0.39776808 0.41602778 0.301994  ]
[Epoch=400, n_hypersteps=6]: prior precision: [0.08172993 0.05371008 0.05067588 0.26505178], sigma noise: [0.3969253  0.3980916  0.41571477 0.30072492]
[Epoch=400, n_hypersteps=7]: prior precision: [0.08219841 0.05352626 0.0505735  0.27167755], sigma noise: [0.39705354 0.39865318 0.415614   0.2995523 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.08267351 0.05333516 0.05047397 0.27856633], sigma noise: [0.39738303 0.39943874 0.41573182 0.29847023]
[Epoch=400, n_hypersteps=9]: prior precision: [0.08315372 0.05313789 0.0503769  0.2857092 ], sigma noise: [0.39788613 0.40042052 0.416024   0.2974661 ]
[Epoch=400, n_hypersteps=10]: prior precision: [0.08363611 0.05293548 0.05028312 0.29309934], sigma noise: [0.39851785 0.4015537  0.4164547  0.29652193]
[Epoch=400, n_hypersteps=11]: prior precision: [0.08411961 0.0527299  0.0501917  0.30072746], sigma noise: [0.39923245 0.40278614 0.41696665 0.29561684]
[Epoch=400, n_hypersteps=12]: prior precision: [0.08460202 0.0525209  0.05010254 0.30858558], sigma noise: [0.39997268 0.40406153 0.41750187 0.29472902]
[Epoch=400, n_hypersteps=13]: prior precision: [0.08508209 0.0523094  0.05001592 0.31666368], sigma noise: [0.40069228 0.40533125 0.4179836  0.29383802]
[Epoch=400, n_hypersteps=14]: prior precision: [0.08555831 0.05209701 0.0499302  0.3249502 ], sigma noise: [0.40134072 0.40653542 0.41836634 0.29292685]
[Epoch=400, n_hypersteps=15]: prior precision: [0.0860292  0.05188514 0.0498466  0.33343658], sigma noise: [0.40188223 0.40764365 0.41862726 0.29198298]
[Epoch=400, n_hypersteps=16]: prior precision: [0.08649431 0.05167403 0.04976521 0.3421102 ], sigma noise: [0.40229672 0.4086271  0.41875905 0.29099867]
[Epoch=400, n_hypersteps=17]: prior precision: [0.08695202 0.05146446 0.04968612 0.35096204], sigma noise: [0.4025706  0.40945858 0.41873342 0.28997102]
[Epoch=400, n_hypersteps=18]: prior precision: [0.08740049 0.05125653 0.04960815 0.3599794 ], sigma noise: [0.40270704 0.41014367 0.4185568  0.28890297]
[Epoch=400, n_hypersteps=19]: prior precision: [0.08784018 0.05105239 0.04953217 0.36915043], sigma noise: [0.40271798 0.41070074 0.41824913 0.28780118]
[Epoch=400, n_hypersteps=20]: prior precision: [0.08826964 0.05085118 0.04945803 0.37846085], sigma noise: [0.402629   0.41115507 0.4178409  0.2866762 ]
[Epoch=400, n_hypersteps=21]: prior precision: [0.08868795 0.05065311 0.04938614 0.38789716], sigma noise: [0.40247536 0.41153935 0.4173629  0.2855401 ]
[Epoch=400, n_hypersteps=22]: prior precision: [0.08909507 0.05046039 0.04931658 0.3974469 ], sigma noise: [0.40228543 0.41189516 0.4168762  0.28440553]
[Epoch=400, n_hypersteps=23]: prior precision: [0.08949094 0.05027241 0.04924865 0.40709502], sigma noise: [0.4020939  0.41224062 0.41642    0.2832845 ]
[Epoch=400, n_hypersteps=24]: prior precision: [0.08987378 0.05008943 0.04918334 0.41682556], sigma noise: [0.40192798 0.4126159  0.41602057 0.28218746]
[Epoch=400, n_hypersteps=25]: prior precision: [0.09024327 0.04991131 0.04912011 0.42662415], sigma noise: [0.40181512 0.41304192 0.41567892 0.28112277]
[Epoch=400, n_hypersteps=26]: prior precision: [0.09059943 0.04973725 0.04905896 0.43647355], sigma noise: [0.40176803 0.41353583 0.41540045 0.28009534]
[Epoch=400, n_hypersteps=27]: prior precision: [0.09094193 0.04956857 0.04899997 0.44635648], sigma noise: [0.40179545 0.41410995 0.4152222  0.27910727]
[Epoch=400, n_hypersteps=28]: prior precision: [0.09127036 0.04940537 0.04894362 0.45625588], sigma noise: [0.40189767 0.41476145 0.4151295  0.2781582 ]
[Epoch=400, n_hypersteps=29]: prior precision: [0.09158492 0.04924777 0.04888942 0.46615493], sigma noise: [0.4020636  0.41547927 0.4151092  0.27724487]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.001, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='elu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ELU(alpha=1.0)
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8190534  0.81905323 0.8190521  0.81905234], sigma noise: [0.8189273  0.8189275  0.81892866 0.8189243 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7418851 0.7418845 0.7418807 0.7418814], sigma noise: [0.74156445 0.7415651  0.7415694  0.74155325]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6725922 0.6725908 0.672582  0.6725837], sigma noise: [0.6721673  0.67216974 0.67218053 0.67214006]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6104643  0.61046135 0.6104449  0.61044854], sigma noise: [0.6102997  0.61030394 0.61032826 0.6102438 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55482686 0.5548223  0.5547954  0.5548013 ], sigma noise: [0.5557021  0.5557099  0.55575734 0.55559695]
[Epoch=100, n_hypersteps=7]: prior precision: [0.5050469  0.50504035 0.5049999  0.50500834], sigma noise: [0.50833744 0.50834984 0.50843483 0.50814915]
[Epoch=100, n_hypersteps=8]: prior precision: [0.460535   0.46052605 0.4604686  0.46048048], sigma noise: [0.46842113 0.46844205 0.46859524 0.46810013]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42074665 0.42073438 0.42065647 0.42067322], sigma noise: [0.43638504 0.43642437 0.4366832  0.4358644 ]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38518465 0.3851668  0.3850666  0.38508832], sigma noise: [0.4126731  0.41273466 0.4131471  0.41185534]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35339272 0.3533682  0.35324547 0.35327142], sigma noise: [0.39734492 0.39743802 0.39806443 0.39613175]
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.056 MB of 0.137 MB uploaded (0.000 MB deduped)wandb: \ 0.137 MB of 0.137 MB uploaded (0.000 MB deduped)wandb: | 0.137 MB of 0.137 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.71317
wandb:                       Metrics 0.67288
wandb:  Negative_marginal_likelihood 1361.61475
wandb: Predictive_posterior_std_mean 1.06176
wandb:                   Sigma_noise 0.85006
wandb: 
wandb: üöÄ View run good-sweep-6 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/fee9mr7z
wandb: Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_172145-fee9mr7z/logs
[Epoch=100, n_hypersteps=12]: prior precision: [0.32495928 0.32492685 0.32478222 0.3248097 ], sigma noise: [0.38985    0.3899707  0.39087224 0.38813758]
[Epoch=100, n_hypersteps=13]: prior precision: [0.29951474 0.2994695  0.29930454 0.29933402], sigma noise: [0.38916853 0.38931352 0.39054576 0.38685536]
[Epoch=100, n_hypersteps=14]: prior precision: [0.27672422 0.2766649  0.27648082 0.27651063], sigma noise: [0.3941253  0.39429677 0.3959182  0.39111814]
[Epoch=100, n_hypersteps=15]: prior precision: [0.2562899  0.25621548 0.256014   0.25604302], sigma noise: [0.4036357  0.4038372  0.40590134 0.39982602]
[Epoch=100, n_hypersteps=16]: prior precision: [0.23794745 0.23785818 0.23763861 0.23766805], sigma noise: [0.4167019  0.41694415 0.4195207  0.41198057]
[Epoch=100, n_hypersteps=17]: prior precision: [0.22146061 0.22135898 0.22111984 0.22114843], sigma noise: [0.4324095  0.4327041  0.4358447  0.42664915]
[Epoch=100, n_hypersteps=18]: prior precision: [0.20662095 0.20650566 0.20624813 0.2062772 ], sigma noise: [0.44982275 0.4501754  0.45395657 0.44289955]
[Epoch=100, n_hypersteps=19]: prior precision: [0.19324392 0.19311492 0.19284013 0.19286935], sigma noise: [0.46798056 0.46839586 0.47288203 0.45978126]
[Epoch=100, n_hypersteps=20]: prior precision: [0.18116608 0.18102053 0.18073153 0.18076213], sigma noise: [0.48589757 0.48637986 0.49161318 0.4763303 ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.17024237 0.17007944 0.16977908 0.1698114 ], sigma noise: [0.5026104  0.5031575  0.5091581  0.49163747]
[Epoch=100, n_hypersteps=22]: prior precision: [0.1603477  0.16016714 0.15985659 0.15989037], sigma noise: [0.5172461  0.5178454  0.5245965  0.50488645]
[Epoch=100, n_hypersteps=23]: prior precision: [0.15136983 0.15117212 0.15085101 0.1508869 ], sigma noise: [0.52908736 0.5297389  0.53718436 0.5154335 ]
[Epoch=100, n_hypersteps=24]: prior precision: [0.14320947 0.14299446 0.14266366 0.14270161], sigma noise: [0.53764355 0.53834736 0.54640204 0.5228466 ]
[Epoch=100, n_hypersteps=25]: prior precision: [0.13577947 0.13554747 0.13520601 0.13524754], sigma noise: [0.5426903  0.54343015 0.5519755  0.5269296 ]
[Epoch=100, n_hypersteps=26]: prior precision: [0.1290028  0.12875375 0.12840177 0.12844734], sigma noise: [0.54422724 0.5449768  0.553897   0.5277065 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.12281083 0.12254596 0.12218344 0.12223195], sigma noise: [0.5424703 0.5432145 0.5523797 0.525406 ]
[Epoch=100, n_hypersteps=28]: prior precision: [0.11714398 0.11686365 0.11649081 0.11654262], sigma noise: [0.53781533 0.5385384  0.5478307  0.5204122 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.11194967 0.11165601 0.11127107 0.11132491], sigma noise: [0.53078985 0.5314787  0.54080844 0.51321906]
[Epoch=200, n_hypersteps=0]: prior precision: [0.10718048 0.10687446 0.10647665 0.10653196], sigma noise: [0.52200645 0.5226483  0.5319378  0.5043935 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.10278545 0.10245772 0.10206256 0.10213673], sigma noise: [0.5091188  0.50970256 0.5187214  0.49179924]
[Epoch=200, n_hypersteps=2]: prior precision: [0.09873068 0.09837156 0.09799141 0.09809751], sigma noise: [0.4932853  0.49378994 0.5024018  0.47649562]
[Epoch=200, n_hypersteps=3]: prior precision: [0.0949852  0.09458601 0.09423054 0.09437884], sigma noise: [0.47564337 0.47605821 0.4841742  0.45950183]
[Epoch=200, n_hypersteps=4]: prior precision: [0.09152016 0.09107383 0.09075081 0.090949  ], sigma noise: [0.45728174 0.45759752 0.46519095 0.44182363]
[Epoch=200, n_hypersteps=5]: prior precision: [0.0883107  0.08781298 0.08752637 0.08777869], sigma noise: [0.4391845  0.43937397 0.44648328 0.4243649 ]
[Epoch=200, n_hypersteps=6]: prior precision: [0.08533414 0.08478207 0.08453409 0.08484401], sigma noise: [0.4222095  0.42226452 0.42897663 0.4079117 ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.08256993 0.08196084 0.08175188 0.08212272], sigma noise: [0.40712726 0.40700164 0.41342428 0.3931519 ]
Run fee9mr7z errored: _LinAlgError('linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 975 is not positive-definite).')
wandb: ERROR Run fee9mr7z errored: _LinAlgError('linalg.cholesky: The factorization could not be completed because the input is not positive-definite (the leading minor of order 975 is not positive-definite).')
[Epoch=200, n_hypersteps=8]: prior precision: [0.07999954 0.07932913 0.07916239 0.07959216], sigma noise: [0.39453763 0.39422157 0.40046707 0.38065454]
[Epoch=200, n_hypersteps=9]: prior precision: [0.07760575 0.07686869 0.07674415 0.07723516], sigma noise: [0.38489813 0.3843576  0.39055106 0.37079316]
[Epoch=200, n_hypersteps=10]: prior precision: [0.07537311 0.07456566 0.07447744 0.07503434], sigma noise: [0.3784296  0.37770024 0.3839816  0.36378455]
[Epoch=200, n_hypersteps=11]: prior precision: [0.07328577 0.07240848 0.07235783 0.07297495], sigma noise: [0.37520093 0.37428546 0.38081357 0.359695  ]
[Epoch=200, n_hypersteps=12]: prior precision: [0.07133163 0.07038254 0.0703715  0.07104542], sigma noise: [0.37510994 0.3740081  0.3809182  0.3584157 ]
[Epoch=200, n_hypersteps=13]: prior precision: [0.06950025 0.06847655 0.06850508 0.06923334], sigma noise: [0.37791643 0.37659088 0.38405243 0.35969222]
[Epoch=200, n_hypersteps=14]: prior precision: [0.06778177 0.06668063 0.06674456 0.06753177], sigma noise: [0.38325363 0.3816558  0.3897888  0.36317095]
[Epoch=200, n_hypersteps=15]: prior precision: [0.06616878 0.06498713 0.0650816  0.06592849], sigma noise: [0.39060587 0.38869864 0.3976508  0.3683198 ]
[Epoch=200, n_hypersteps=16]: prior precision: [0.06465059 0.06338822 0.06351355 0.0644168 ], sigma noise: [0.39938927 0.39713848 0.40703505 0.3746287 ]
[Epoch=200, n_hypersteps=17]: prior precision: [0.06321936 0.06187913 0.0620323  0.0629898 ], sigma noise: [0.408996   0.4063543  0.4172981  0.38151333]
[Epoch=200, n_hypersteps=18]: prior precision: [0.06186903 0.0604535  0.06063388 0.06163962], sigma noise: [0.41876426 0.41573608 0.42778572 0.3884266 ]
[Epoch=200, n_hypersteps=19]: prior precision: [0.06059309 0.05910588 0.05931119 0.06035983], sigma noise: [0.42808735 0.42468065 0.4378131  0.39487964]
[Epoch=200, n_hypersteps=20]: prior precision: [0.05938699 0.05782792 0.05805695 0.05914475], sigma noise: [0.43641475 0.43257552 0.44678912 0.4003982 ]
[Epoch=200, n_hypersteps=21]: prior precision: [0.05824471 0.05661545 0.05686558 0.05798995], sigma noise: [0.4432662  0.43899247 0.45421436 0.40463087]
[Epoch=200, n_hypersteps=22]: prior precision: [0.05716149 0.05546589 0.05573221 0.05689191], sigma noise: [0.4482879  0.44362652 0.45971167 0.40740854]
[Epoch=200, n_hypersteps=23]: prior precision: [0.05613316 0.05437307 0.05465006 0.05584663], sigma noise: [0.4512933  0.44627666 0.46308005 0.40860716]
[Epoch=200, n_hypersteps=24]: prior precision: [0.05515633 0.05333324 0.05361694 0.05484647], sigma noise: [0.45224935 0.44697815 0.46426606 0.40819335]
[Epoch=200, n_hypersteps=25]: prior precision: [0.05422686 0.05234146 0.05263143 0.05389115], sigma noise: [0.45127663 0.44581243 0.463429   0.40630987]
[Epoch=200, n_hypersteps=26]: prior precision: [0.05334083 0.05139557 0.05169331 0.05297551], sigma noise: [0.4486352  0.44302633 0.4608118  0.40313265]
[Epoch=200, n_hypersteps=27]: prior precision: [0.05249536 0.05049326 0.05079802 0.0520985 ], sigma noise: [0.44464508 0.43896025 0.45678577 0.3989919 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.05168885 0.04963052 0.04994166 0.05125766], sigma noise: [0.4397116  0.4340235  0.4516988  0.39415395]
[Epoch=200, n_hypersteps=29]: prior precision: [0.05091716 0.048804   0.04911801 0.05044961], sigma noise: [0.4342998  0.42862192 0.44605333 0.38897255]
