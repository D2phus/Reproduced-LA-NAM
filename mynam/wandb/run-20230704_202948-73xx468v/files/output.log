Configuration: Config(regression=True, use_dnn=False, num_epochs=50, batch_size=64, shuffle=True, early_stopping_patience=50, decay_rate=0, logdir='output', wandb=False, log_loss_frequency=10, lr=0.0037543568766410782, l2_regularization=1.1103039239393044e-06, output_regularization=0.043672303225749505, dropout=0.1, feature_dropout=0.1, num_basis_functions=1024, hidden_sizes=[], activation='relu')
Model summary: NAM(
  (feature_dropout): Dropout(p=0.1, inplace=False)
  (feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): LinearReLU(in_features=1, out_features=1024)
        (1): Dropout(p=0.1, inplace=False)
        (2): Linear(in_features=1024, out_features=1, bias=True)
        (3): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
Finished Training.