Configuration: Config(experiment_name='nam-sparse-features-test', regression=True, use_dnn=False, num_epochs=50, batch_size=128, shuffle=True, early_stopping_patience=50, decay_rate=0.005, logdir='./output', wandb=False, log_loss_frequency=10, lr=0.006615977146888905, l2_regularization=6.434664612653172e-05, output_regularization=0.00408385075972748, dropout=0.2, feature_dropout=0.2, num_basis_functions=64, hidden_sizes=[64, 32], activation='exu')
Model summary: NAM(
  (feature_dropout): Dropout(p=0.2, inplace=False)
  (feature_nns): ModuleList(
    (0-6): 7 x FeatureNN(
      (model): Sequential(
        (0): ExU(in_features=1, out_features=64)
        (1): Dropout(p=0.2, inplace=False)
        (2): LinearReLU(in_features=64, out_features=64)
        (3): Dropout(p=0.2, inplace=False)
        (4): LinearReLU(in_features=64, out_features=32)
        (5): Dropout(p=0.2, inplace=False)
        (6): Linear(in_features=32, out_features=1, bias=True)
        (7): Dropout(p=0.2, inplace=False)
      )
    )
  )
)
Finished Training.