{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.activation.exu import ExU\n",
    "from models.activation.relu import LinearReLU\n",
    "from models.featureNN import FeatureNN\n",
    "from config.default import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([-1.9905, -0.5372,  0.2972, -0.6434, -0.6197]), \n",
      "outputs: tensor([0.0000, 0.6301, 0.0000], grad_fn=<ReluBackward0>)\n",
      "inputs: tensor([-0.7293,  0.0296,  0.0287, -0.6199,  0.7819]), \n",
      "outputs: tensor([0., 0., 0.], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def test_LinearReLU():\n",
    "    # TODO\n",
    "    n_inputs = 5 \n",
    "    n_outputs = 3\n",
    "    relu = LinearReLU(in_features=n_inputs, out_features=n_outputs)\n",
    "    inputs = torch.randn(n_inputs)\n",
    "    y = relu(inputs)\n",
    "    print(f\"inputs: {inputs}, \\noutputs: {y}\")\n",
    "    \n",
    "def test_ExU():\n",
    "    # TODO\n",
    "    n_inputs = 5 \n",
    "    n_outputs = 3\n",
    "    exu = ExU(in_features=n_inputs, out_features=n_outputs)\n",
    "    inputs = torch.randn(n_inputs)\n",
    "    y = exu(inputs, 1)\n",
    "    print(f\"inputs: {inputs}, \\noutputs: {y}\")\n",
    "    \n",
    "test_LinearReLU()\n",
    "test_ExU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(device='cpu', seed=2021, data_path='data/GALLUP.csv', experiment_name='NAM', regression=False, num_epochs=10, lr=0.01, batch_size=128, logdir='output', wandb=False, hidden_sizes=[64, 64, 32], activation='exu', dropout=0.1, feature_dropout=0.1, decay_rate=0.995, l2_regularization=0.1, output_regularization=0.1, num_basis_functions=1000, units_multiplier=2, shuffle=True, cross_val=False, num_folds=5, num_splits=3, fold_num=1, num_models=1, num_workers=16, save_model_frequency=2, save_top_k=3, use_dnn=False, early_stopping_patience=50)\n",
      "FeatureNN(\n",
      "  (model): Sequential(\n",
      "    (0): ExU()\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "    (2): LinearReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): LinearReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): LinearReLU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (9): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "tensor([0.9210, 0.2030, 0.8054])\n",
      "tensor([[ 0.1572],\n",
      "        [ 0.2277],\n",
      "        [-0.2458]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def test_featureNN():\n",
    "    cfg = defaults()\n",
    "    cfg.hidden_sizes = [64, 64, 32]\n",
    "    print(cfg)\n",
    "    name = \"featureNN test\"\n",
    "    in_features = 1\n",
    "    batch_size = 5 \n",
    "    num_units = 32\n",
    "    feature_index = 1\n",
    "    fnn = FeatureNN(cfg, name, in_features, num_units, feature_index)\n",
    "    print(fnn)\n",
    "    \n",
    "    inputs = torch.rand(batch_size)\n",
    "    print(inputs)\n",
    "    outputs = fnn(inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "    \n",
    "test_featureNN()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3043e-05, 3.0687e-41, 1.5391e-05],\n",
      "        [3.0687e-41, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 4.3158e+00],\n",
      "        [3.5988e+00,        nan,        nan],\n",
      "        [3.0156e+00, 0.0000e+00, 6.8664e-44]])\n",
      "tensor([[[1.3043e-05, 3.0687e-41, 1.5391e-05],\n",
      "         [3.0687e-41, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 4.3158e+00],\n",
      "         [3.5988e+00,        nan,        nan],\n",
      "         [3.0156e+00, 0.0000e+00, 6.8664e-44]]])\n",
      "tensor([[[1.3043e-05, 3.0687e-41, 1.5391e-05]],\n",
      "\n",
      "        [[3.0687e-41, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 4.3158e+00]],\n",
      "\n",
      "        [[3.5988e+00,        nan,        nan]],\n",
      "\n",
      "        [[3.0156e+00, 0.0000e+00, 6.8664e-44]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "in_features = 3 \n",
    "x = torch.Tensor(batch_size, in_features)\n",
    "print(x)\n",
    "\n",
    "test1 = torch.unsqueeze(x, 0)\n",
    "test2 = torch.unsqueeze(x, 1)\n",
    "print(test1)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
