{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from LANAM.models import LaNAM, NAM, BayesianLinearRegression\n",
    "from LANAM.config import *\n",
    "from LANAM.trainer import *\n",
    "from LANAM.trainer.nam_trainer import train\n",
    "from LANAM.data import *\n",
    "\n",
    "from LANAM.utils.plotting import * \n",
    "from LANAM.utils.output_filter import OutputFilter\n",
    "from LANAM.utils.wandb import *\n",
    "\n",
    "from laplace import Laplace\n",
    "from laplace import marglik_training as lamt\n",
    "from laplace.curvature.backpack import BackPackGGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Linear Regression\n",
    "$$\n",
    "\\begin{align*}\n",
    "y &= \\beta_0 X_0 + \\beta_1 X_1 + \\epsilon, \\\\\n",
    "\\epsilon &\\sim \\mathcal{N}(0, \\sigma^2) \\\\\n",
    "\\beta_0, \\beta_1 &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then the posterior $p(\\beta|X, y) = \\mathcal{N}(\\mu_\\beta, \\Sigma_\\beta)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\begin{cases}\n",
    "\\mu_\\beta &= \\sigma^{-2}A^{-1}X^Ty\\\\\n",
    "\\Sigma_\\beta &= A^{-1}\\\\\n",
    "A &= \\sigma^{-2}X^TX + \\Sigma^{-1}_\\beta\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "reg.coef_\n",
    "reg.intercept_\n",
    "reg.predict(np.array([[3, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos=[0, 0.7, 0.9, 0.95, 0.99]\n",
    "\n",
    "for rho in rhos: \n",
    "    data = linear_regression_example(rho=rho, sigma=1)\n",
    "    input_0, input_1 = data.features.T\n",
    "    target = data.targets\n",
    "    data_plot = plot_3d(input_0, input_1, target)\n",
    "    \n",
    "    blr = BayesianLinearRegression(data.features, data.targets, bf='identity', sigma_noise=1.0, prior_var=1.0)\n",
    "    \n",
    "    #reg = LinearRegression().fit(data.features, y)\n",
    "    \n",
    "    mean = blr.mean\n",
    "    cov = blr.posterior_cov\n",
    "    \n",
    "    x, y = np.random.multivariate_normal(mean.flatten(), cov, 1000).T\n",
    "    fig, axs = plt.subplots(figsize=(4, 3))\n",
    "    axs.plot(x, y, 'x')\n",
    "    axs.axis('equal')\n",
    "    axs.set_xlabel('beta_0')\n",
    "    axs.set_ylabel('beta_1')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
