wandb: Currently logged in as: xinyu-zhang. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165600-mzdpl9uq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-breeze-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/mzdpl9uq
wandb: \ 1 of 3 files downloaded...wandb:   3 of 3 files downloaded.  
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: üöÄ View run earthy-breeze-116 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic/runs/mzdpl9uq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165600-mzdpl9uq/logs
wandb: Agent Starting Run: sjvjeuuh with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165643-sjvjeuuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/sjvjeuuh
Create sweep with ID: 1vu0rcp3
Sweep URL: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ReLU()
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8193627  0.81922865 0.81914705 0.8197872 ], sigma noise: [0.8188244  0.81882745 0.8188237  0.81881815]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74297696 0.7425004  0.74221045 0.74465084], sigma noise: [0.7411635  0.74117446 0.74116105 0.741141  ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6750717  0.67398155 0.67331946 0.67931145], sigma noise: [0.6711467  0.67117226 0.67114145 0.67109394]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6150358 0.6130105 0.6117854 0.6237109], sigma noise: [0.60815334 0.6082022  0.6081441  0.60805106]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5622628 0.5589433 0.556947  0.5777848], sigma noise: [0.55165076 0.55173427 0.5516366  0.55147284]
[Epoch=100, n_hypersteps=7]: prior precision: [0.5161574 0.5111593 0.5081765 0.5413663], sigma noise: [0.5011989 0.5013317 0.5011788 0.5009092]
[Epoch=100, n_hypersteps=8]: prior precision: [0.47614276 0.46906736 0.46488374 0.51409674], sigma noise: [0.45645866 0.45666036 0.45643184 0.45600617]
[Epoch=100, n_hypersteps=9]: prior precision: [0.44166616 0.43211022 0.4265196  0.4953991 ], sigma noise: [0.41720465 0.41750214 0.41717038 0.41651618]
[Epoch=100, n_hypersteps=10]: prior precision: [0.4122046  0.39976785 0.39257586 0.48453155], sigma noise: [0.38333738 0.38376808 0.38329458 0.38230723]
[Epoch=100, n_hypersteps=11]: prior precision: [0.38726878 0.37155944 0.36258623 0.48068982], sigma noise: [0.35488263 0.3554985  0.35482967 0.3533607 ]
[Epoch=100, n_hypersteps=12]: prior precision: [0.36640456 0.34704375 0.336125   0.48310244], sigma noise: [0.33195353 0.33282417 0.33188787 0.32973528]
[Epoch=100, n_hypersteps=13]: prior precision: [0.34919313 0.32581854 0.3128052  0.491086  ], sigma noise: [0.31465074 0.31586325 0.3145688  0.31147727]
[Epoch=100, n_hypersteps=14]: prior precision: [0.33525398 0.307519   0.29227474 0.50405353], sigma noise: [0.3029197  0.30457345 0.30281702 0.2984921 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.3242405  0.29181552 0.27421793 0.52149063], sigma noise: [0.2964536  0.29865372 0.29632533 0.29045457]
[Epoch=100, n_hypersteps=16]: prior precision: [0.31584108 0.2784124  0.2583504  0.54291284], sigma noise: [0.2947233 0.297577  0.2945649 0.286829 ]
[Epoch=100, n_hypersteps=17]: prior precision: [0.30977678 0.2670454  0.24441709 0.56781155], sigma noise: [0.29709366 0.30071262 0.29690146 0.28697094]
[Epoch=100, n_hypersteps=18]: prior precision: [0.30579817 0.25748044 0.23219341 0.59559476], sigma noise: [0.30292702 0.30743194 0.30269748 0.2902226 ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.3036845  0.249511   0.22147867 0.62552655], sigma noise: [0.3116232  0.31714714 0.3113538  0.29595637]
[Epoch=100, n_hypersteps=20]: prior precision: [0.30323973 0.24295592 0.2120963  0.6566749 ], sigma noise: [0.32261026 0.32929894 0.32230002 0.30357686]
[Epoch=100, n_hypersteps=21]: prior precision: [0.3042888  0.23765634 0.20389274 0.6878839 ], sigma noise: [0.335318   0.34332463 0.33496842 0.31250757]
[Epoch=100, n_hypersteps=22]: prior precision: [0.30667195 0.23347338 0.1967312  0.7177894 ], sigma noise: [0.34915435 0.35862952 0.34876963 0.32218176]
[Epoch=100, n_hypersteps=23]: prior precision: [0.3102414  0.23028564 0.190495   0.74489856], sigma noise: [0.36349732 0.37457368 0.36308593 0.33204576]
[Epoch=100, n_hypersteps=24]: prior precision: [0.31485736 0.227987   0.18508206 0.7677397 ], sigma noise: [0.37770593 0.39047933 0.37728122 0.3415746 ]
[Epoch=100, n_hypersteps=25]: prior precision: [0.32038638 0.22648463 0.1804026  0.7850571 ], sigma noise: [0.3911479  0.40565825 0.39072812 0.35029492]
[Epoch=100, n_hypersteps=26]: prior precision: [0.32669446 0.22569688 0.17637801 0.7959978 ], sigma noise: [0.40323824 0.4194544  0.40284577 0.35780895]
[Epoch=100, n_hypersteps=27]: prior precision: [0.33364978 0.22555204 0.17294148 0.80022913], sigma noise: [0.41347948 0.431292   0.4131397  0.36381307]
[Epoch=100, n_hypersteps=28]: prior precision: [0.34111848 0.22598682 0.17003492 0.7979601 ], sigma noise: [0.4214959  0.44072017 0.42123556 0.36810791]
[Epoch=100, n_hypersteps=29]: prior precision: [0.34896377 0.226945   0.1676082  0.78986907], sigma noise: [0.42705527 0.44744477 0.42689967 0.37059906]
[Epoch=200, n_hypersteps=0]: prior precision: [0.357047   0.22837658 0.16561821 0.7769728 ], sigma noise: [0.43007538 0.45134273 0.43004733 0.37129006]
[Epoch=200, n_hypersteps=1]: prior precision: [0.36038232 0.22782506 0.1636694  0.7767062 ], sigma noise: [0.4302912  0.4519511  0.43036744 0.37009108]
[Epoch=200, n_hypersteps=2]: prior precision: [0.35929137 0.22550084 0.16177046 0.78741574], sigma noise: [0.42793974 0.4495419  0.42809647 0.3671893 ]
[Epoch=200, n_hypersteps=3]: prior precision: [0.3543337  0.22165823 0.15993057 0.80788743], sigma noise: [0.42336765 0.44452423 0.42358196 0.36282825]
[Epoch=200, n_hypersteps=4]: prior precision: [0.34620792 0.21657306 0.15815789 0.8372168 ], sigma noise: [0.4169973  0.43739966 0.41724804 0.35728958]
[Epoch=200, n_hypersteps=5]: prior precision: [0.33566135 0.21052349 0.15646034 0.8746859 ], sigma noise: [0.40929487 0.4287203  0.40956387 0.3508765 ]
[Epoch=200, n_hypersteps=6]: prior precision: [0.323421   0.20377503 0.15484464 0.9196474 ], sigma noise: [0.4007423  0.41905287 0.40101436 0.34389976]
[Epoch=200, n_hypersteps=7]: prior precision: [0.3101483  0.19657005 0.15331744 0.9714135 ], sigma noise: [0.39181417 0.40894917 0.39207724 0.33666563]
[Epoch=200, n_hypersteps=8]: prior precision: [0.2964126  0.18912128 0.15188386 1.0291452 ], sigma noise: [0.3829591  0.39892387 0.38320398 0.32946566]
[Epoch=200, n_hypersteps=9]: prior precision: [0.28268185 0.18160914 0.15054885 1.0917443 ], sigma noise: [0.3745848  0.38943774 0.37480497 0.3225671 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.26932335 0.17418131 0.14931491 1.1577569 ], sigma noise: [0.367046   0.38088506 0.36723682 0.31620446]
[Epoch=200, n_hypersteps=11]: prior precision: [0.25661057 0.16695443 0.14818361 1.2253053 ], sigma noise: [0.3606349  0.3735844  0.36079317 0.31057143]
[Epoch=200, n_hypersteps=12]: prior precision: [0.2447366  0.16001692 0.1471565  1.2920766 ], sigma noise: [0.35557288 0.367772   0.35569614 0.30581406]
[Epoch=200, n_hypersteps=13]: prior precision: [0.23382641 0.15343252 0.14623246 1.355397  ], sigma noise: [0.3520059  0.3635987  0.3520917  0.30202532]
[Epoch=200, n_hypersteps=14]: prior precision: [0.22395113 0.14724392 0.14541045 1.4124175 ], sigma noise: [0.35000214 0.36112967 0.3500482  0.29924256]
[Epoch=200, n_hypersteps=15]: prior precision: [0.21513835 0.14147677 0.14468654 1.4603999 ], sigma noise: [0.34955335 0.36034766 0.3495569  0.29744822]
[Epoch=200, n_hypersteps=16]: prior precision: [0.20738582 0.13614273 0.14405745 1.497057  ], sigma noise: [0.35057956 0.36115944 0.35053745 0.29657364]
[Epoch=200, n_hypersteps=17]: prior precision: [0.20066887 0.13124296 0.1435179  1.520865  ], sigma noise: [0.35293645 0.36340445 0.35284445 0.29650643]
[Epoch=200, n_hypersteps=18]: prior precision: [0.19494726 0.12677053 0.14306161 1.5312626 ], sigma noise: [0.35642418 0.36686465 0.35627753 0.29709986]
[Epoch=200, n_hypersteps=19]: prior precision: [0.19017228 0.12271266 0.14268155 1.528686  ], sigma noise: [0.3607986  0.37127605 0.36059204 0.29818386]
[Epoch=200, n_hypersteps=20]: prior precision: [0.18628938 0.11905266 0.1423726  1.5144489 ], sigma noise: [0.36578336 0.37634152 0.36551118 0.29957688]
[Epoch=200, n_hypersteps=21]: prior precision: [0.1832415  0.11577123 0.14212725 1.4905157 ], sigma noise: [0.37108383 0.3817452  0.37074056 0.30109727]
[Epoch=200, n_hypersteps=22]: prior precision: [0.18097226 0.11284783 0.14193854 1.4592332 ], sigma noise: [0.3764028 0.3871688 0.3759831 0.3025744]
[Epoch=200, n_hypersteps=23]: prior precision: [0.17942488 0.11026137 0.14180042 1.4230769 ], sigma noise: [0.38145673 0.3923092  0.38095626 0.3038575 ]
[Epoch=200, n_hypersteps=24]: prior precision: [0.17854473 0.10799076 0.14170638 1.384443  ], sigma noise: [0.3859924  0.39689583 0.38540792 0.30482307]
[Epoch=200, n_hypersteps=25]: prior precision: [0.17827824 0.10601556 0.14165132 1.3455024 ], sigma noise: [0.3898017  0.4007069  0.3891314  0.30537924]
[Epoch=200, n_hypersteps=26]: prior precision: [0.1785732  0.10431606 0.14163022 1.3081129 ], sigma noise: [0.39273322 0.4035818  0.3919767  0.3054681 ]
[Epoch=200, n_hypersteps=27]: prior precision: [0.17937924 0.10287359 0.14163856 1.2737797 ], sigma noise: [0.39469948 0.40542907 0.39385778 0.3050654 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.18064553 0.10167054 0.14167312 1.243655  ], sigma noise: [0.39567927 0.40622842 0.3947548  0.30417812]
[Epoch=200, n_hypersteps=29]: prior precision: [0.182322   0.10069028 0.141731   1.21856   ], sigma noise: [0.3957146  0.40602764 0.39471063 0.302841  ]
[Epoch=300, n_hypersteps=0]: prior precision: [0.18435802 0.0999172  0.14181045 1.1990206 ], sigma noise: [0.39490375 0.4049341  0.39382455 0.30111146]
[Epoch=300, n_hypersteps=1]: prior precision: [0.18584718 0.09874482 0.14130296 1.1690301 ], sigma noise: [0.394181   0.40384212 0.39284906 0.299398  ]
[Epoch=300, n_hypersteps=2]: prior precision: [0.1867933  0.09723588 0.1402703  1.1313194 ], sigma noise: [0.39361215 0.40282992 0.3918652  0.2977337 ]
[Epoch=300, n_hypersteps=3]: prior precision: [0.18721555 0.0954535  0.1387779  1.0885421 ], sigma noise: [0.39325362 0.40196452 0.39094317 0.2961461 ]
[Epoch=300, n_hypersteps=4]: prior precision: [0.18714722 0.09345888 0.13689099 1.0430874 ], sigma noise: [0.39314947 0.40129852 0.39013925 0.29465595]
[Epoch=300, n_hypersteps=5]: prior precision: [0.18663238 0.0913094  0.13467695 0.996976  ], sigma noise: [0.39332902 0.4008678  0.3894929  0.29327652]
[Epoch=300, n_hypersteps=6]: prior precision: [0.1857243  0.08905733 0.13219953 0.9518237 ], sigma noise: [0.39380574 0.40069056 0.3890264  0.29201326]
[Epoch=300, n_hypersteps=7]: prior precision: [0.18448234 0.08674918 0.1295182  0.9088513 ], sigma noise: [0.39457694 0.40076727 0.3887447  0.29086423]
[Epoch=300, n_hypersteps=8]: prior precision: [0.1829692  0.08442507 0.12668873 0.868925  ], sigma noise: [0.39562464 0.401082   0.388637   0.28982076]
[Epoch=300, n_hypersteps=9]: prior precision: [0.18124868 0.0821192  0.12375971 0.8326102 ], sigma noise: [0.39691705 0.40160438 0.38867855 0.28886864]
[Epoch=300, n_hypersteps=10]: prior precision: [0.17938237 0.07985957 0.12077646 0.80023164], sigma noise: [0.39841112 0.40229237 0.3888336  0.28798947]
[Epoch=300, n_hypersteps=11]: prior precision: [0.17742902 0.07766878 0.11777725 0.7719289 ], sigma noise: [0.40005553 0.40309593 0.38905853 0.28716242]
[Epoch=300, n_hypersteps=12]: prior precision: [0.17544231 0.07556434 0.11479353 0.7477057 ], sigma noise: [0.40179422 0.40396076 0.38930684 0.28636572]
[Epoch=300, n_hypersteps=13]: prior precision: [0.1734704  0.07355943 0.11185235 0.72747076], sigma noise: [0.40357018 0.4048322  0.38953155 0.2855783 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.17155565 0.07166351 0.10897624 0.71106887], sigma noise: [0.40532884 0.405659   0.38968933 0.28478113]
[Epoch=300, n_hypersteps=15]: prior precision: [0.16973378 0.06988264 0.10618309 0.69830585], sigma noise: [0.40702173 0.40639645 0.38974273 0.28395838]
[Epoch=300, n_hypersteps=16]: prior precision: [0.16803399 0.06822041 0.10348637 0.6889637 ], sigma noise: [0.40860918 0.40700927 0.38966313 0.28309813]
[Epoch=300, n_hypersteps=17]: prior precision: [0.16648002 0.06667811 0.10089675 0.68281335], sigma noise: [0.41006246 0.40747336 0.38943318 0.28219283]
[Epoch=300, n_hypersteps=18]: prior precision: [0.16508925 0.06525533 0.09842042 0.6796196 ], sigma noise: [0.41136506 0.40777677 0.38904524 0.28123942]
[Epoch=300, n_hypersteps=19]: prior precision: [0.16387363 0.06395036 0.09606296 0.6791447 ], sigma noise: [0.41251296 0.4079198  0.38850284 0.28023908]
[Epoch=300, n_hypersteps=20]: prior precision: [0.16284043 0.06276028 0.09382719 0.6811484 ], sigma noise: [0.41351405 0.40791392 0.38781917 0.2791967 ]
[Epoch=300, n_hypersteps=21]: prior precision: [0.16199307 0.06168155 0.09171423 0.685388  ], sigma noise: [0.414387   0.40778032 0.3870157  0.2781203 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.16133021 0.06071007 0.08972334 0.69161636], sigma noise: [0.41515863 0.4075476  0.38612038 0.27702007]
[Epoch=300, n_hypersteps=23]: prior precision: [0.16084783 0.05984126 0.08785333 0.6995787 ], sigma noise: [0.41586167 0.40724894 0.38516456 0.27590743]
[Epoch=300, n_hypersteps=24]: prior precision: [0.16053876 0.05907035 0.08610082 0.7090121 ], sigma noise: [0.41653174 0.40691966 0.38417956 0.27479404]
[Epoch=300, n_hypersteps=25]: prior precision: [0.1603932  0.05839242 0.08446304 0.7196438 ], sigma noise: [0.4172043  0.40659404 0.3831961  0.27369112]
[Epoch=300, n_hypersteps=26]: prior precision: [0.16039947 0.05780233 0.08293646 0.73119086], sigma noise: [0.41791198 0.40630308 0.38224274 0.2726084 ]
[Epoch=300, n_hypersteps=27]: prior precision: [0.16054358 0.05729517 0.08151698 0.7433621 ], sigma noise: [0.41868213 0.40607247 0.38134065 0.27155373]
[Epoch=300, n_hypersteps=28]: prior precision: [0.16081026 0.05686594 0.08019964 0.7558607 ], sigma noise: [0.41953516 0.40592083 0.38050726 0.2705326 ]
[Epoch=300, n_hypersteps=29]: prior precision: [0.1611833  0.05650979 0.07898077 0.76838857], sigma noise: [0.42048323 0.4058591  0.37975135 0.2695479 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.1616453  0.05622198 0.07785589 0.7806533 ], sigma noise: [0.42152962 0.40589014 0.3790756  0.26859996]
[Epoch=400, n_hypersteps=1]: prior precision: [0.16132827 0.05589462 0.07676449 0.7518746 ], sigma noise: [0.42419758 0.40735185 0.37958762 0.26809508]
[Epoch=400, n_hypersteps=2]: prior precision: [0.16031545 0.05553521 0.07571066 0.69921637], sigma noise: [0.42823878 0.41001025 0.38108322 0.267952  ]
[Epoch=400, n_hypersteps=3]: prior precision: [0.15870939 0.05515094 0.07469764 0.6350312 ], sigma noise: [0.4333159  0.41355774 0.38329968 0.2680686 ]
[Epoch=400, n_hypersteps=4]: prior precision: [0.15662417 0.05474848 0.07372616 0.5677086 ], sigma noise: [0.4390293  0.41763982 0.3859402  0.2683332 ]
[Epoch=400, n_hypersteps=5]: prior precision: [0.15417731 0.05433399 0.07279803 0.5025788 ], sigma noise: [0.44494802 0.4218839  0.3886999  0.26863554]
[Epoch=400, n_hypersteps=6]: prior precision: [0.15148419 0.0539131  0.07191427 0.4427061 ], sigma noise: [0.4506446  0.4259301  0.39129126 0.2688762 ]
[Epoch=400, n_hypersteps=7]: prior precision: [0.14865296 0.05349085 0.07107565 0.38955736], sigma noise: [0.4557311  0.42946026 0.39346606 0.26897377]
[Epoch=400, n_hypersteps=8]: prior precision: [0.14578113 0.05307173 0.07028294 0.3435413 ], sigma noise: [0.45989192 0.43222347 0.39503407 0.26886913]
[Epoch=400, n_hypersteps=9]: prior precision: [0.1429526  0.05265972 0.06953561 0.30442202], sigma noise: [0.46291092 0.43405432 0.39587447 0.26852745]
[Epoch=400, n_hypersteps=10]: prior precision: [0.14023803 0.05225822 0.06883281 0.27161616], sigma noise: [0.46468678 0.4348819  0.39594096 0.26793775]
[Epoch=400, n_hypersteps=11]: prior precision: [0.13769437 0.05187017 0.06817409 0.24439281], sigma noise: [0.46523604 0.43472958 0.3952592  0.267111  ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.211 MB of 0.288 MB uploaded (0.000 MB deduped)wandb: \ 0.211 MB of 0.288 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                       Metrics ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÇ‚ñÅ‚ñÑ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.59464
wandb:                       Metrics 0.59039
wandb:  Negative_marginal_likelihood 1261.86084
wandb: Predictive_posterior_std_mean 0.78546
wandb:                   Sigma_noise 0.78271
wandb: 
wandb: üöÄ View run usual-sweep-1 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/sjvjeuuh
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165643-sjvjeuuh/logs
wandb: Agent Starting Run: ug0kzw9d with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165805-ug0kzw9d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ug0kzw9d
[Epoch=400, n_hypersteps=12]: prior precision: [0.13536538 0.0514982  0.06755814 0.22199734], sigma noise: [0.46468362 0.43370485 0.39391655 0.26607668]
[Epoch=400, n_hypersteps=13]: prior precision: [0.13328342 0.05114429 0.06698401 0.20372094], sigma noise: [0.46324217 0.43198252 0.39204928 0.26487875]
[Epoch=400, n_hypersteps=14]: prior precision: [0.13146989 0.05080999 0.06645105 0.18893369], sigma noise: [0.461185   0.4297828  0.3898274  0.26357073]
[Epoch=400, n_hypersteps=15]: prior precision: [0.12993711 0.05049651 0.06595781 0.17709544], sigma noise: [0.45881534 0.42734772 0.38743588 0.26221088]
[Epoch=400, n_hypersteps=16]: prior precision: [0.12868986 0.05020481 0.06550287 0.16775404], sigma noise: [0.45643616 0.4249177  0.38505659 0.260857  ]
[Epoch=400, n_hypersteps=17]: prior precision: [0.12772608 0.04993544 0.06508429 0.16053687], sigma noise: [0.45432353 0.42271072 0.38285443 0.25956166]
[Epoch=400, n_hypersteps=18]: prior precision: [0.12703872 0.04968876 0.06470024 0.15514039], sigma noise: [0.4527051  0.4209059  0.38096437 0.2583683 ]
[Epoch=400, n_hypersteps=19]: prior precision: [0.1266152  0.04946483 0.0643493  0.15131904], sigma noise: [0.451745   0.41963103 0.37948138 0.2573077 ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.1264394  0.04926353 0.06403133 0.14887492], sigma noise: [0.45153552 0.41895655 0.3784567  0.2563963 ]
[Epoch=400, n_hypersteps=21]: prior precision: [0.12649225 0.04908451 0.06374521 0.14764866], sigma noise: [0.45209515 0.4188938  0.37789613 0.25563556]
[Epoch=400, n_hypersteps=22]: prior precision: [0.12675136 0.04892726 0.06348812 0.14751138], sigma noise: [0.4533727  0.41939914 0.37776497 0.25501338]
[Epoch=400, n_hypersteps=23]: prior precision: [0.12719248 0.04879117 0.06325851 0.14835785], sigma noise: [0.45525625 0.4203817  0.3779934  0.25450626]
[Epoch=400, n_hypersteps=24]: prior precision: [0.12778947 0.04867543 0.06305549 0.15010078], sigma noise: [0.45758677 0.421715   0.37848544 0.25408268]
[Epoch=400, n_hypersteps=25]: prior precision: [0.12851481 0.04857918 0.06287743 0.1526659 ], sigma noise: [0.4601749  0.42325103 0.37912938 0.25370702]
[Epoch=400, n_hypersteps=26]: prior precision: [0.12934048 0.04850148 0.06272209 0.15598767], sigma noise: [0.46281964 0.424835   0.3798108  0.2533435 ]
[Epoch=400, n_hypersteps=27]: prior precision: [0.13023743 0.04844129 0.06258753 0.16000547], sigma noise: [0.46532747 0.42632017 0.38042358 0.25295943]
[Epoch=400, n_hypersteps=28]: prior precision: [0.13117734 0.04839752 0.06247414 0.16466038], sigma noise: [0.46753043 0.42758137 0.38087803 0.25252822]
[Epoch=400, n_hypersteps=29]: prior precision: [0.13213237 0.04836902 0.06237948 0.16989225], sigma noise: [0.46930063 0.42852503 0.3811091  0.252031  ]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ReLU()
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 1.1051708], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8203348 0.8194572 0.8193063 1.2133839], sigma noise: [0.81883734 0.81883377 0.81882995 0.81881726]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7467752  0.74333143 0.74277735 1.3049814 ], sigma noise: [0.7412093  0.7411965  0.74118364 0.7411375 ]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6845847  0.67592436 0.67461544 1.3579564 ], sigma noise: [0.6712518  0.6712225  0.6711938  0.67108536]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6342017  0.6166951  0.61418825 1.3772277 ], sigma noise: [0.60835075 0.6082961  0.608244   0.60803443]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5958305  0.56510055 0.560873   1.3825678 ], sigma noise: [0.5519811  0.5518908  0.5518067  0.55144435]
[Epoch=100, n_hypersteps=7]: prior precision: [0.5691938 0.5205982 0.5140632 1.3945389], sigma noise: [0.50171226 0.5015748  0.50144845 0.5008632 ]
[Epoch=100, n_hypersteps=8]: prior precision: [0.55348635 0.4826497  0.47317415 1.4267743 ], sigma noise: [0.45721868 0.45702052 0.45683965 0.45593378]
[Epoch=100, n_hypersteps=9]: prior precision: [0.5475446  0.4507252  0.43764883 1.4815826 ], sigma noise: [0.41829368 0.4180182  0.4177674  0.4164019 ]
[Epoch=100, n_hypersteps=10]: prior precision: [0.5501288  0.42430568 0.40696457 1.5548285 ], sigma noise: [0.38486314 0.3844885  0.38414782 0.38212368]
[Epoch=100, n_hypersteps=11]: prior precision: [0.5601123  0.40289044 0.38063166 1.639155  ], sigma noise: [0.3569829  0.3564798  0.35602313 0.35305995]
[Epoch=100, n_hypersteps=12]: prior precision: [0.5765575  0.38600168 0.3582014  1.7221481 ], sigma noise: [0.3347938  0.33412343 0.33351806 0.3292372 ]
[Epoch=100, n_hypersteps=13]: prior precision: [0.5986914  0.37318903 0.33926144 1.7863926 ], sigma noise: [0.31841028 0.31752422 0.3167309  0.31065828]
[Epoch=100, n_hypersteps=14]: prior precision: [0.6258057 0.3640361 0.3234356 1.819607 ], sigma noise: [0.30776936 0.3066126  0.3055883  0.29718193]
[Epoch=100, n_hypersteps=15]: prior precision: [0.6571797  0.35816115 0.31038734 1.822913  ], sigma noise: [0.3025415  0.30105725 0.29975665 0.28844547]
[Epoch=100, n_hypersteps=16]: prior precision: [0.69195753 0.35521805 0.29981372 1.8062153 ], sigma noise: [0.30217838 0.30030954 0.29868641 0.28389028]
[Epoch=100, n_hypersteps=17]: prior precision: [0.72902215 0.35489494 0.29143822 1.7816015 ], sigma noise: [0.30603978 0.30372846 0.3017343  0.28285858]
[Epoch=100, n_hypersteps=18]: prior precision: [0.7668929  0.35691118 0.2850169  1.7595431 ], sigma noise: [0.31349483 0.31068045 0.3082628  0.284682  ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.8036923  0.3610107  0.28034174 1.7464235 ], sigma noise: [0.32395303 0.32057217 0.31767383 0.28872374]
[Epoch=100, n_hypersteps=20]: prior precision: [0.83722883 0.36695364 0.2772221  1.7428645 ], sigma noise: [0.33684674 0.33283466 0.3293947  0.29438502]
[Epoch=100, n_hypersteps=21]: prior precision: [0.86520106 0.37450776 0.27549213 1.744923  ], sigma noise: [0.3515957  0.34689146 0.3428489  0.30109987]
[Epoch=100, n_hypersteps=22]: prior precision: [0.8855927  0.38343963 0.27500197 1.7462785 ], sigma noise: [0.36757722 0.36213136 0.35743043 0.30833346]
[Epoch=100, n_hypersteps=23]: prior precision: [0.89703435 0.3935082  0.27562073 1.7409867 ], sigma noise: [0.38411367 0.37789842 0.37249655 0.3155901 ]
[Epoch=100, n_hypersteps=24]: prior precision: [0.89905035 0.404458   0.27723178 1.7264146 ], sigma noise: [0.40048373 0.39350286 0.3873809  0.32242793]
[Epoch=100, n_hypersteps=25]: prior precision: [0.8920829  0.41601878 0.27972794 1.7041614 ], sigma noise: [0.41595593 0.4082524  0.40142316 0.3284754 ]
[Epoch=100, n_hypersteps=26]: prior precision: [0.8773117  0.42790356 0.2830095  1.6791904 ], sigma noise: [0.42983866 0.42149788 0.41401014 0.3334441 ]
[Epoch=100, n_hypersteps=27]: prior precision: [0.8563789  0.43981433 0.28698173 1.6576736 ], sigma noise: [0.44153553 0.43268207 0.42462224 0.33713484]
[Epoch=100, n_hypersteps=28]: prior precision: [0.8311476  0.4514475  0.29155153 1.6448581 ], sigma noise: [0.450595   0.4413827  0.43286917 0.33943638]
[Epoch=100, n_hypersteps=29]: prior precision: [0.8034686  0.46250775 0.29663065 1.6431242 ], sigma noise: [0.45674276 0.447341   0.4385153  0.34031788]
[Epoch=200, n_hypersteps=0]: prior precision: [0.7750666  0.47271824 0.30213466 1.6515493 ], sigma noise: [0.45989364 0.45047167 0.44148648 0.33981803]
[Epoch=200, n_hypersteps=1]: prior precision: [0.74368006 0.47877747 0.30766726 1.7436653 ], sigma noise: [0.4593584  0.45016775 0.4411731  0.3377413 ]
[Epoch=200, n_hypersteps=2]: prior precision: [0.71145004 0.48073548 0.31315702 1.8795803 ], sigma noise: [0.45551726 0.44676554 0.4378958  0.3342724 ]
[Epoch=200, n_hypersteps=3]: prior precision: [0.68016315 0.47888353 0.31853434 2.0522017 ], sigma noise: [0.44889233 0.44073474 0.43209797 0.32963103]
[Epoch=200, n_hypersteps=4]: prior precision: [0.6512272  0.47369954 0.32373923 2.2568038 ], sigma noise: [0.44009244 0.43263042 0.42430398 0.32405874]
[Epoch=200, n_hypersteps=5]: prior precision: [0.6256856  0.4657821  0.32871395 2.4850957 ], sigma noise: [0.4297641  0.42304933 0.41507736 0.31780905]
[Epoch=200, n_hypersteps=6]: prior precision: [0.60424936 0.45578638 0.33340892 2.7201602 ], sigma noise: [0.4185521  0.4125941  0.4049897  0.31113815]
[Epoch=200, n_hypersteps=7]: prior precision: [0.58733666 0.4443673  0.33778304 2.9338014 ], sigma noise: [0.40706915 0.4018455  0.39459333 0.30429778]
[Epoch=200, n_hypersteps=8]: prior precision: [0.5751337  0.43214047 0.3418021  3.093405  ], sigma noise: [0.3958757  0.39134106 0.384401   0.2975279 ]
[Epoch=200, n_hypersteps=9]: prior precision: [0.5676343  0.41965255 0.34543777 3.1774957 ], sigma noise: [0.385464   0.38155922 0.37487063 0.2910495 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.5647033  0.40736744 0.3486693  3.184514  ], sigma noise: [0.37624744 0.37290755 0.3663936  0.28505713]
[Epoch=200, n_hypersteps=11]: prior precision: [0.56608653 0.3956584  0.35148135 3.127693  ], sigma noise: [0.36855194 0.36571273 0.3592836  0.2797109 ]
[Epoch=200, n_hypersteps=12]: prior precision: [0.57145077 0.38481244 0.3538657  3.0262487 ], sigma noise: [0.36261055 0.36021334 0.35377032 0.27512932]
[Epoch=200, n_hypersteps=13]: prior precision: [0.5803844  0.375035   0.35581994 2.8997014 ], sigma noise: [0.35856065 0.35655585 0.3499934  0.2713835 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.5924193  0.36646143 0.35734794 2.7653773 ], sigma noise: [0.35644504 0.354794   0.34800327 0.2684942 ]
[Epoch=200, n_hypersteps=15]: prior precision: [0.6069646  0.35916862 0.35845664 2.6375072 ], sigma noise: [0.35621667 0.35489243 0.34776273 0.26643273]
[Epoch=200, n_hypersteps=16]: prior precision: [0.62335885 0.35318336 0.35915312 2.5268407 ], sigma noise: [0.35774642 0.3567334  0.34915468 0.26512572]
[Epoch=200, n_hypersteps=17]: prior precision: [0.6408228  0.34849322 0.3594538  2.4403567 ], sigma noise: [0.3608333  0.36012596 0.35199156 0.26446325]
[Epoch=200, n_hypersteps=18]: prior precision: [0.65846694 0.3450561  0.3593745  2.381661  ], sigma noise: [0.36521477 0.3648165  0.3560264  0.26430917]
[Epoch=200, n_hypersteps=19]: prior precision: [0.6753623  0.34280497 0.3589395  2.3515651 ], sigma noise: [0.37057933 0.37050027 0.36096615 0.2645127 ]
[Epoch=200, n_hypersteps=20]: prior precision: [0.6905581  0.3416563  0.35817277 2.3488193 ], sigma noise: [0.37658036 0.3768351  0.3664843  0.26492006]
[Epoch=200, n_hypersteps=21]: prior precision: [0.7031829  0.34151182 0.35710543 2.3706703 ], sigma noise: [0.38285288 0.3834574  0.37224013 0.26538464]
[Epoch=200, n_hypersteps=22]: prior precision: [0.7125308  0.3422636  0.35577315 2.4133933 ], sigma noise: [0.38903242 0.39000127 0.37789455 0.26577577]
[Epoch=200, n_hypersteps=23]: prior precision: [0.71812487 0.34379554 0.35421452 2.4723825 ], sigma noise: [0.39477625 0.39611915 0.38313124 0.265985  ]
[Epoch=200, n_hypersteps=24]: prior precision: [0.7197952  0.34598508 0.35246843 2.542192  ], sigma noise: [0.39978456 0.40150383 0.38767603 0.26592985]
[Epoch=200, n_hypersteps=25]: prior precision: [0.7176797  0.3487081  0.35057858 2.6165085 ], sigma noise: [0.40381968 0.40590817 0.39131254 0.2655551 ]
[Epoch=200, n_hypersteps=26]: prior precision: [0.71218693 0.35183915 0.34858975 2.6885183 ], sigma noise: [0.4067196  0.40916052 0.39389625 0.2648325 ]
[Epoch=200, n_hypersteps=27]: prior precision: [0.7039551  0.35525376 0.34654894 2.751343  ], sigma noise: [0.40840662 0.4111736  0.3953581  0.2637583 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.69374627 0.35883066 0.34450036 2.7990456 ], sigma noise: [0.40888736 0.4119466  0.3957069  0.2623506 ]
[Epoch=200, n_hypersteps=29]: prior precision: [0.6823799  0.36245528 0.34248903 2.827646  ], sigma noise: [0.4082472  0.41155943 0.39502317 0.26064536]
[Epoch=300, n_hypersteps=0]: prior precision: [0.6706555  0.36602116 0.34055352 2.8356917 ], sigma noise: [0.40663764 0.41016155 0.39344633 0.2586925 ]
[Epoch=300, n_hypersteps=1]: prior precision: [0.65853924 0.36669657 0.33860588 2.8486242 ], sigma noise: [0.40390575 0.4074016  0.3908416  0.25646564]
[Epoch=300, n_hypersteps=2]: prior precision: [0.64682066 0.3647209  0.33669615 2.8652725 ], sigma noise: [0.40034485 0.40360114 0.38747662 0.2540452 ]
[Epoch=300, n_hypersteps=3]: prior precision: [0.63616467 0.36044985 0.33487144 2.884219  ], sigma noise: [0.39627853 0.39911556 0.38364652 0.25151724]
[Epoch=300, n_hypersteps=4]: prior precision: [0.6270947  0.3543114  0.33317304 2.9039497 ], sigma noise: [0.39203694 0.39430603 0.379653   0.24896859]
[Epoch=300, n_hypersteps=5]: prior precision: [0.6199894  0.34676692 0.33163425 2.922912  ], sigma noise: [0.38793492 0.3895151  0.37578458 0.24648224]
[Epoch=300, n_hypersteps=6]: prior precision: [0.6150862  0.33827013 0.33028412 2.9397728 ], sigma noise: [0.3842536  0.3850467  0.37229973 0.2441327 ]
[Epoch=300, n_hypersteps=7]: prior precision: [0.61248034 0.32924584 0.32914078 2.9534514 ], sigma noise: [0.3812259  0.3811502  0.36941373 0.2419819 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.6121385  0.32006735 0.32822233 2.963235  ], sigma noise: [0.37902674 0.37801102 0.36728907 0.24007574]
[Epoch=300, n_hypersteps=9]: prior precision: [0.61392295 0.31104907 0.3275308  2.968851  ], sigma noise: [0.3777659  0.37574476 0.36602828 0.23844178]
[Epoch=300, n_hypersteps=10]: prior precision: [0.6175872  0.30244368 0.32706574 2.9703805 ], sigma noise: [0.37748674 0.37439656 0.36567223 0.23708825]
[Epoch=300, n_hypersteps=11]: prior precision: [0.62279606 0.29444352 0.3268178  2.9683774 ], sigma noise: [0.37816706 0.3739447  0.3662009  0.23600459]
[Epoch=300, n_hypersteps=12]: prior precision: [0.6291489  0.28718704 0.32677174 2.9636579 ], sigma noise: [0.37972492 0.37430757 0.36753875 0.23516355]
[Epoch=300, n_hypersteps=13]: prior precision: [0.6361675  0.28076667 0.32690597 2.9572103 ], sigma noise: [0.3820264  0.37535438 0.3695624  0.23452498]
[Epoch=300, n_hypersteps=14]: prior precision: [0.64336526 0.27523443 0.3271976  2.9500818 ], sigma noise: [0.384896   0.37691665 0.37211022 0.23403978]
[Epoch=300, n_hypersteps=15]: prior precision: [0.6502444  0.27061385 0.3276166  2.9432628 ], sigma noise: [0.38813028 0.37880266 0.3749963  0.2336548 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.6563374  0.26690242 0.3281351  2.9376156 ], sigma noise: [0.39151186 0.38081214 0.37802175 0.23331735]
[Epoch=300, n_hypersteps=17]: prior precision: [0.66124207 0.26407775 0.3287219  2.9337523 ], sigma noise: [0.39482573 0.38275117 0.38099185 0.23297895]
[Epoch=300, n_hypersteps=18]: prior precision: [0.66467035 0.26210517 0.32935014 2.9320276 ], sigma noise: [0.3978744  0.38444647 0.38372648 0.23259863]
[Epoch=300, n_hypersteps=19]: prior precision: [0.6664493  0.26093772 0.32999822 2.932582  ], sigma noise: [0.40049133 0.38575652 0.38607574 0.23214485]
[Epoch=300, n_hypersteps=20]: prior precision: [0.6665418  0.26051953 0.33063966 2.9352512 ], sigma noise: [0.40255275 0.3865812  0.3879281  0.23159647]
[Epoch=300, n_hypersteps=21]: prior precision: [0.6650486  0.2607905  0.33125103 2.9397006 ], sigma noise: [0.40398484 0.38686582 0.38921705 0.2309432 ]
[Epoch=300, n_hypersteps=22]: prior precision: [0.66218704 0.26168203 0.33181894 2.9454174 ], sigma noise: [0.40476704 0.38660228 0.38992447 0.23018475]
[Epoch=300, n_hypersteps=23]: prior precision: [0.6582715  0.26312387 0.33233052 2.9518287 ], sigma noise: [0.40492934 0.3858264  0.39007643 0.22932982]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.200 MB of 0.289 MB uploaded (0.000 MB deduped)wandb: \ 0.200 MB of 0.289 MB uploaded (0.000 MB deduped)wandb: | 0.200 MB of 0.289 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.48345
wandb:                       Metrics 0.47514
wandb:  Negative_marginal_likelihood 1229.18384
wandb: Predictive_posterior_std_mean 0.71804
wandb:                   Sigma_noise 0.71063
wandb: 
wandb: üöÄ View run fresh-sweep-2 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/ug0kzw9d
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165805-ug0kzw9d/logs
wandb: Agent Starting Run: pb4dekzl with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 64
wandb: 	lr: 0.001
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_165928-pb4dekzl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/pb4dekzl
[Epoch=300, n_hypersteps=24]: prior precision: [0.6536538  0.265041   0.33277753 2.9583652 ], sigma noise: [0.40454704 0.38461044 0.38974044 0.22839458]
[Epoch=300, n_hypersteps=25]: prior precision: [0.6487205  0.26735365 0.33315793 2.9644878 ], sigma noise: [0.40373105 0.383055   0.389015   0.22740069]
[Epoch=300, n_hypersteps=26]: prior precision: [0.6438439  0.2699797  0.33346304 2.9698093 ], sigma noise: [0.40261605 0.38127878 0.38802108 0.22637331]
[Epoch=300, n_hypersteps=27]: prior precision: [0.63935256 0.27283633 0.33370128 2.973975  ], sigma noise: [0.40134755 0.37940747 0.38688883 0.22533904]
[Epoch=300, n_hypersteps=28]: prior precision: [0.63551795 0.27583718 0.33387455 2.9769235 ], sigma noise: [0.40007004 0.37756318 0.38574848 0.22432384]
[Epoch=300, n_hypersteps=29]: prior precision: [0.63255346 0.27889827 0.33399007 2.978673  ], sigma noise: [0.39891493 0.37585595 0.38471824 0.22335118]
[Epoch=400, n_hypersteps=0]: prior precision: [0.6305872  0.28193614 0.33405066 2.9794023 ], sigma noise: [0.3979926  0.37437612 0.3838984  0.22244029]
[Epoch=400, n_hypersteps=1]: prior precision: [0.6286618  0.28386468 0.33482146 2.9154925 ], sigma noise: [0.39751542 0.37322176 0.38359854 0.22163773]
[Epoch=400, n_hypersteps=2]: prior precision: [0.6268912  0.2847108  0.33622494 2.8075297 ], sigma noise: [0.3975094  0.37241846 0.3838312  0.22094612]
[Epoch=400, n_hypersteps=3]: prior precision: [0.6253799  0.2845389  0.33817527 2.6784737 ], sigma noise: [0.3979588  0.37195718 0.3845722  0.22036064]
[Epoch=400, n_hypersteps=4]: prior precision: [0.6241957  0.28345054 0.34057978 2.5490053 ], sigma noise: [0.39881068 0.37179756 0.38576478 0.21986988]
[Epoch=400, n_hypersteps=5]: prior precision: [0.623384   0.2815732  0.34333876 2.4350815 ], sigma noise: [0.3999822  0.37187496 0.3873251  0.21945742]
[Epoch=400, n_hypersteps=6]: prior precision: [0.62293553 0.2790483  0.3463464  2.3473883 ], sigma noise: [0.40136877 0.37210837 0.38914943 0.21910349]
[Epoch=400, n_hypersteps=7]: prior precision: [0.62283105 0.27602687 0.34949973 2.2913997 ], sigma noise: [0.40285367 0.37240916 0.391123   0.21878694]
[Epoch=400, n_hypersteps=8]: prior precision: [0.62301373 0.27265936 0.35269728 2.2683887 ], sigma noise: [0.40431938 0.37268952 0.3931293  0.21848716]
[Epoch=400, n_hypersteps=9]: prior precision: [0.62342674 0.2690915  0.35583737 2.2766519 ], sigma noise: [0.40565708 0.37287    0.39505854 0.21818563]
[Epoch=400, n_hypersteps=10]: prior precision: [0.6239981 0.2654557 0.3588294 2.3123155], sigma noise: [0.4067756  0.3728867  0.39681774 0.21786727]
[Epoch=400, n_hypersteps=11]: prior precision: [0.6246669  0.26187015 0.3615935  2.369809  ], sigma noise: [0.40760815 0.3726951  0.3983355  0.21752124]
[Epoch=400, n_hypersteps=12]: prior precision: [0.6253539  0.25843683 0.36405832 2.4419584 ], sigma noise: [0.40811685 0.37227243 0.39956653 0.21714132]
[Epoch=400, n_hypersteps=13]: prior precision: [0.6260066  0.25524148 0.36616915 2.5202048 ], sigma noise: [0.40829366 0.37161925 0.40049422 0.21672592]
[Epoch=400, n_hypersteps=14]: prior precision: [0.6265829  0.25235063 0.3678876  2.5949478 ], sigma noise: [0.40815896 0.37075666 0.40112934 0.21627775]
[Epoch=400, n_hypersteps=15]: prior precision: [0.6270625  0.24981515 0.36918887 2.6567476 ], sigma noise: [0.40775776 0.3697231  0.40150717 0.21580313]
[Epoch=400, n_hypersteps=16]: prior precision: [0.6274036  0.24766812 0.37006456 2.6979265 ], sigma noise: [0.40715387 0.36856967 0.40168267 0.21531112]
[Epoch=400, n_hypersteps=17]: prior precision: [0.62762135 0.24593133 0.37052748 2.7141783 ], sigma noise: [0.40642226 0.36735377 0.4017228  0.21481247]
[Epoch=400, n_hypersteps=18]: prior precision: [0.62772024 0.24461208 0.37059847 2.705403  ], sigma noise: [0.40564197 0.36613545 0.40169966 0.21431856]
[Epoch=400, n_hypersteps=19]: prior precision: [0.6277193  0.24371015 0.37031096 2.6755023 ], sigma noise: [0.40488878 0.36497116 0.40168434 0.21384041]
[Epoch=400, n_hypersteps=20]: prior precision: [0.6276415  0.24320845 0.3697046  2.6310432 ], sigma noise: [0.4042284  0.3639084  0.40173918 0.21338755]
[Epoch=400, n_hypersteps=21]: prior precision: [0.62750095 0.24308741 0.36883077 2.5798025 ], sigma noise: [0.40371168 0.36298373 0.40191364 0.21296729]
[Epoch=400, n_hypersteps=22]: prior precision: [0.6273217  0.24331775 0.36774188 2.529302  ], sigma noise: [0.40337214 0.36222008 0.40224022 0.21258436]
[Epoch=400, n_hypersteps=23]: prior precision: [0.62713975 0.24386288 0.36649328 2.485842  ], sigma noise: [0.4032237  0.3616262  0.4027324  0.21224044]
[Epoch=400, n_hypersteps=24]: prior precision: [0.6269648  0.24468198 0.3651376  2.453878  ], sigma noise: [0.403261   0.36119705 0.403385   0.21193437]
[Epoch=400, n_hypersteps=25]: prior precision: [0.6268085  0.24572814 0.36372814 2.4359715 ], sigma noise: [0.40346244 0.3609152  0.40417555 0.21166235]
[Epoch=400, n_hypersteps=26]: prior precision: [0.6266858  0.24695626 0.3623127  2.4327116 ], sigma noise: [0.4037929  0.36075425 0.405069   0.21141864]
[Epoch=400, n_hypersteps=27]: prior precision: [0.62658244 0.24831566 0.36093247 2.4431393 ], sigma noise: [0.40420833 0.36068144 0.40601993 0.21119621]
[Epoch=400, n_hypersteps=28]: prior precision: [0.62649876 0.2497575  0.35962498 2.464882  ], sigma noise: [0.4046605  0.36066088 0.40697828 0.21098743]
[Epoch=400, n_hypersteps=29]: prior precision: [0.62642837 0.2512328  0.35842353 2.4944565 ], sigma noise: [0.40510166 0.36065784 0.40789452 0.21078485]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.001, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[64], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=64, bias=True)
        (1): ReLU()
        (2): Linear(in_features=64, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.81934196 0.81921995 0.81912714 0.81931734], sigma noise: [0.81886256 0.8188587  0.818852   0.8188533 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7429125  0.742468   0.74213743 0.74283946], sigma noise: [0.7413073  0.74129343 0.7412691  0.74127424]
[Epoch=100, n_hypersteps=4]: prior precision: [0.67494047 0.6739035  0.67314726 0.67481464], sigma noise: [0.67150027 0.67146814 0.67141    0.671423  ]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6148146  0.61285913 0.6114538  0.61467206], sigma noise: [0.6088692  0.6088086  0.60869426 0.608721  ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5619252  0.5586854  0.55638283 0.561858  ], sigma noise: [0.55294913 0.5528477  0.55264616 0.55269426]
[Epoch=100, n_hypersteps=7]: prior precision: [0.5156708  0.51075745 0.5072947  0.5158466 ], sigma noise: [0.50339705 0.50323945 0.5029067  0.5029862 ]
[Epoch=100, n_hypersteps=8]: prior precision: [0.47546366 0.46848342 0.46358913 0.47613   ], sigma noise: [0.46001223 0.45977908 0.45925203 0.45937547]
[Epoch=100, n_hypersteps=9]: prior precision: [0.44073725 0.43130645 0.42470825 0.44221705], sigma noise: [0.4227579  0.42242396 0.4216114  0.42179415]
[Epoch=100, n_hypersteps=10]: prior precision: [0.41095212 0.3987061  0.39013684 0.4136391 ], sigma noise: [0.39176175 0.3912934  0.39006564 0.3903254 ]
[Epoch=100, n_hypersteps=11]: prior precision: [0.38559946 0.37020403 0.35940808 0.38993365], sigma noise: [0.3672556  0.36660916 0.36479226 0.3651483 ]
[Epoch=100, n_hypersteps=12]: prior precision: [0.36420745 0.3453552  0.332093   0.37064585], sigma noise: [0.34941798 0.3485409  0.34591988 0.34639215]
[Epoch=100, n_hypersteps=13]: prior precision: [0.34634024 0.32375658 0.30781004 0.3553438 ], sigma noise: [0.3381622  0.33699736 0.33333278 0.33394244]
[Epoch=100, n_hypersteps=14]: prior precision: [0.33160886 0.30504364 0.28621197 0.34360406], sigma noise: [0.3330381  0.3315274  0.32657394 0.32734355]
[Epoch=100, n_hypersteps=15]: prior precision: [0.319667   0.28888422 0.26699588 0.3350291 ], sigma noise: [0.33332878 0.33141348 0.32492867 0.32588306]
[Epoch=100, n_hypersteps=16]: prior precision: [0.31018463 0.27498284 0.24989419 0.32925424], sigma noise: [0.33823517 0.33585376 0.32758626 0.32875472]
[Epoch=100, n_hypersteps=17]: prior precision: [0.30288967 0.2630692  0.23466411 0.32594207], sigma noise: [0.34699476 0.34408143 0.33376282 0.33517757]
[Epoch=100, n_hypersteps=18]: prior precision: [0.2975263  0.25291312 0.22108892 0.32481652], sigma noise: [0.35890713 0.3553878  0.3427249  0.34442395]
[Epoch=100, n_hypersteps=19]: prior precision: [0.2938833  0.2443091  0.20898655 0.32560265], sigma noise: [0.3732998  0.36909637 0.35377625 0.35580185]
[Epoch=100, n_hypersteps=20]: prior precision: [0.29176554 0.23707667 0.19819112 0.32805708], sigma noise: [0.3894863  0.38452163 0.36622718 0.36862668]
[Epoch=100, n_hypersteps=21]: prior precision: [0.29100737 0.23106143 0.18855067 0.33196425], sigma noise: [0.4067357 0.4009401 0.3793826 0.3822023]
[Epoch=100, n_hypersteps=22]: prior precision: [0.29146266 0.22612625 0.17993817 0.3371156 ], sigma noise: [0.42426836 0.41759157 0.3925468  0.39582852]
[Epoch=100, n_hypersteps=23]: prior precision: [0.29299688 0.22215414 0.17224507 0.3433041 ], sigma noise: [0.44127703 0.43369895 0.40504882 0.40882578]
[Epoch=100, n_hypersteps=24]: prior precision: [0.29548186 0.21904592 0.16537176 0.35034558], sigma noise: [0.4569733  0.44851327 0.41628176 0.42057028]
[Epoch=100, n_hypersteps=25]: prior precision: [0.29880598 0.21671388 0.15923257 0.35806018], sigma noise: [0.4706454  0.46136835 0.42573914 0.43053645]
[Epoch=100, n_hypersteps=26]: prior precision: [0.3028647  0.21508001 0.15374927 0.36625704], sigma noise: [0.48171577 0.47173083 0.43304905 0.43832895]
[Epoch=100, n_hypersteps=27]: prior precision: [0.3075567  0.21407938 0.14885603 0.37475657], sigma noise: [0.48978725 0.47923958 0.4379822  0.44370034]
[Epoch=100, n_hypersteps=28]: prior precision: [0.3127852  0.21365516 0.1444935  0.38338986], sigma noise: [0.49466482 0.48372582 0.4404618  0.44655776]
[Epoch=100, n_hypersteps=29]: prior precision: [0.3184572  0.21375819 0.14060895 0.3919918 ], sigma noise: [0.49635816 0.4852074  0.44055137 0.44695252]
[Epoch=200, n_hypersteps=0]: prior precision: [0.3244851  0.21434651 0.13715585 0.40041345], sigma noise: [0.49506122 0.48387164 0.43843108 0.44506022]
[Epoch=200, n_hypersteps=1]: prior precision: [0.32867154 0.21484198 0.13411076 0.40884393], sigma noise: [0.4885967  0.47791892 0.43280864 0.43948594]
[Epoch=200, n_hypersteps=2]: prior precision: [0.33104947 0.21524923 0.1314357  0.417164  ], sigma noise: [0.4779076  0.46816626 0.42429417 0.4308641 ]
[Epoch=200, n_hypersteps=3]: prior precision: [0.33171308 0.21558172 0.12910008 0.42527887], sigma noise: [0.46402794 0.4555171  0.41355118 0.41989285]
[Epoch=200, n_hypersteps=4]: prior precision: [0.33079267 0.21585096 0.12707688 0.43311098], sigma noise: [0.447994   0.4408953  0.40126395 0.40728876]
[Epoch=200, n_hypersteps=5]: prior precision: [0.32845807 0.21607731 0.12534362 0.4406044 ], sigma noise: [0.4307885  0.4251905  0.38810074 0.39375135]
[Epoch=200, n_hypersteps=6]: prior precision: [0.32490218 0.2162764  0.12387555 0.44771293], sigma noise: [0.41330397 0.40922812 0.37469473 0.3799422 ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.32034096 0.21646713 0.12265692 0.45439953], sigma noise: [0.39632437 0.39375222 0.36162534 0.3664682 ]
[Epoch=200, n_hypersteps=8]: prior precision: [0.31498107 0.21666105 0.12166505 0.46064097], sigma noise: [0.38051865 0.37941554 0.3494218  0.35387123]
[Epoch=200, n_hypersteps=9]: prior precision: [0.30902687 0.21687667 0.12088778 0.46644413], sigma noise: [0.36643276 0.3667693  0.33853406 0.3426181 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.3026735  0.21712516 0.12031443 0.4717992 ], sigma noise: [0.35448787 0.35625583 0.32933813 0.33308986]
[Epoch=200, n_hypersteps=11]: prior precision: [0.29609227 0.2174179  0.11992051 0.47669518], sigma noise: [0.3449722  0.34819922 0.32210925 0.32556885]
[Epoch=200, n_hypersteps=12]: prior precision: [0.2894291  0.21776013 0.11970051 0.48111424], sigma noise: [0.33803844 0.34279558 0.31702277 0.32022777]
[Epoch=200, n_hypersteps=13]: prior precision: [0.2828146  0.21814914 0.11964162 0.48503458], sigma noise: [0.33370623 0.34011105 0.31413692 0.31712502]
[Epoch=200, n_hypersteps=14]: prior precision: [0.276357   0.21858102 0.11973485 0.48842332], sigma noise: [0.33187237 0.34008843 0.31340298 0.31620428]
[Epoch=200, n_hypersteps=15]: prior precision: [0.27013558 0.21904339 0.11996727 0.49122813], sigma noise: [0.3323281  0.34255704 0.31467086 0.31730866]
[Epoch=200, n_hypersteps=16]: prior precision: [0.2642257  0.21953182 0.12031856 0.4934197 ], sigma noise: [0.33477747 0.34725034 0.31770718 0.32019353]
[Epoch=200, n_hypersteps=17]: prior precision: [0.25865766 0.22003284 0.12077779 0.49494502], sigma noise: [0.33885872 0.35382092 0.3222014  0.32454547]
[Epoch=200, n_hypersteps=18]: prior precision: [0.2534777  0.22052622 0.12134217 0.49577296], sigma noise: [0.3441605  0.36185515 0.32779983 0.32999882]
[Epoch=200, n_hypersteps=19]: prior precision: [0.24869607 0.22099285 0.12199415 0.49586713], sigma noise: [0.35024202 0.3708824  0.3341059  0.3361545 ]
[Epoch=200, n_hypersteps=20]: prior precision: [0.24432802 0.22141404 0.12273198 0.49521637], sigma noise: [0.3566542  0.38039628 0.3407152  0.34259975]
[Epoch=200, n_hypersteps=21]: prior precision: [0.24037342 0.22176896 0.1235364  0.49382317], sigma noise: [0.3629588  0.38987565 0.3472227  0.34893045]
[Epoch=200, n_hypersteps=22]: prior precision: [0.23682815 0.22204416 0.12440514 0.49172637], sigma noise: [0.3687548  0.398811   0.35325903 0.35477397]
[Epoch=200, n_hypersteps=23]: prior precision: [0.23368834 0.22223255 0.12531956 0.48900738], sigma noise: [0.37370116 0.40674162 0.35850143 0.35981154]
[Epoch=200, n_hypersteps=24]: prior precision: [0.23093407 0.22232588 0.12627536 0.48573974], sigma noise: [0.3775346  0.41328788 0.36270142 0.36379477]
[Epoch=200, n_hypersteps=25]: prior precision: [0.22855918 0.2223184  0.1272601  0.48204097], sigma noise: [0.38008487 0.41817614 0.365685   0.36655957]
[Epoch=200, n_hypersteps=26]: prior precision: [0.22654976 0.2222144  0.12826647 0.47802612], sigma noise: [0.38127548 0.4212596  0.36737302 0.3680316 ]
[Epoch=200, n_hypersteps=27]: prior precision: [0.22489403 0.22201714 0.12928934 0.47381058], sigma noise: [0.3811226  0.4225172  0.36777073 0.36822245]
[Epoch=200, n_hypersteps=28]: prior precision: [0.22358038 0.22173883 0.1303208  0.46953627], sigma noise: [0.37972683 0.4220535  0.36696362 0.36722198]
[Epoch=200, n_hypersteps=29]: prior precision: [0.22259177 0.22138979 0.13135156 0.4653602 ], sigma noise: [0.37725633 0.42007843 0.36510637 0.3651845 ]
[Epoch=300, n_hypersteps=0]: prior precision: [0.22191238 0.22098328 0.13238166 0.46140638], sigma noise: [0.3739298  0.41688353 0.36240092 0.3623141 ]
[Epoch=300, n_hypersteps=1]: prior precision: [0.22255097 0.21990453 0.13333178 0.45808345], sigma noise: [0.36990848 0.4124215  0.35881945 0.35862526]
[Epoch=300, n_hypersteps=2]: prior precision: [0.22439338 0.21824002 0.13420096 0.45545787], sigma noise: [0.3654736  0.4071188  0.35465363 0.35440215]
[Epoch=300, n_hypersteps=3]: prior precision: [0.22735618 0.21608776 0.13498455 0.4535836 ], sigma noise: [0.3609123  0.40141365 0.35019547 0.34993434]
[Epoch=300, n_hypersteps=4]: prior precision: [0.2313328  0.21355097 0.13569035 0.45246467], sigma noise: [0.35649872 0.3957221  0.34573188 0.3455016 ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.23624302 0.21073315 0.1363212  0.4521142 ], sigma noise: [0.35248277 0.3904167  0.3415306  0.34135568]
/scratch/work/zhangx18/Reproduced-LA-NAM/LANAM/utils/plotting.py:58: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig_indiv, axs = plt.subplots(rows, cols, figsize=figsize)
[Epoch=300, n_hypersteps=6]: prior precision: [0.24199118 0.2077221  0.13688068 0.4525403 ], sigma noise: [0.34907594 0.38580975 0.33780628 0.33770815]
[Epoch=300, n_hypersteps=7]: prior precision: [0.24847382 0.2046027  0.13736597 0.45369428], sigma noise: [0.34644282 0.38213944 0.33472893 0.3347246 ]
[Epoch=300, n_hypersteps=8]: prior precision: [0.25559875 0.20145047 0.13778393 0.45551735], sigma noise: [0.34469286 0.37956384 0.33241758 0.33251598]
[Epoch=300, n_hypersteps=9]: prior precision: [0.26326266 0.19833179 0.13813365 0.4579177 ], sigma noise: [0.34387773 0.37816137 0.33092454 0.3311342 ]
[Epoch=300, n_hypersteps=10]: prior precision: [0.27133805 0.19529966 0.13842162 0.46081463], sigma noise: [0.34399104 0.3779294  0.3302394  0.3305748 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.2796961  0.19239788 0.13865131 0.46409446], sigma noise: [0.34497526 0.37879285 0.33031535 0.33078232]
[Epoch=300, n_hypersteps=12]: prior precision: [0.28818813 0.1896578  0.1388197  0.46761256], sigma noise: [0.3467243  0.3806173  0.3310525  0.33165646]
[Epoch=300, n_hypersteps=13]: prior precision: [0.2966591  0.18710633 0.13892725 0.4712488 ], sigma noise: [0.34909147 0.38321212 0.3323098  0.3330599 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.30493978 0.18475965 0.13898163 0.47487348], sigma noise: [0.35190344 0.38635108 0.33392948 0.33483222]
[Epoch=300, n_hypersteps=15]: prior precision: [0.31286874 0.18262911 0.13898467 0.47834912], sigma noise: [0.35496986 0.38978708 0.3357372  0.336802  ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.320287   0.180724   0.1389405  0.48155764], sigma noise: [0.358098   0.393267   0.33756298 0.33879733]
[Epoch=300, n_hypersteps=17]: prior precision: [0.32703695 0.17904134 0.13886087 0.48438728], sigma noise: [0.36110517 0.39655003 0.3392467  0.34065995]
[Epoch=300, n_hypersteps=18]: prior precision: [0.33299088 0.17758653 0.13875434 0.48676014], sigma noise: [0.36383003 0.3994265  0.34065494 0.34225368]
[Epoch=300, n_hypersteps=19]: prior precision: [0.33803588 0.17635335 0.13861051 0.4885912 ], sigma noise: [0.36614373 0.40172783 0.34168124 0.34347185]
[Epoch=300, n_hypersteps=20]: prior precision: [0.34210157 0.17533217 0.13843949 0.4898588 ], sigma noise: [0.36795682 0.4033404  0.34225652 0.3442454 ]
[Epoch=300, n_hypersteps=21]: prior precision: [0.34512672 0.17451778 0.138251   0.49056342], sigma noise: [0.36922216 0.40420902 0.34235513 0.34454262]
[Epoch=300, n_hypersteps=22]: prior precision: [0.34711087 0.17390104 0.13805093 0.49070916], sigma noise: [0.36993447 0.40433556 0.34198764 0.3443682 ]
[Epoch=300, n_hypersteps=23]: prior precision: [0.3480839  0.17347033 0.13783146 0.49034327], sigma noise: [0.37013075 0.4037769  0.3411894  0.34376112]
[Epoch=300, n_hypersteps=24]: prior precision: [0.34810385 0.17322247 0.13759089 0.48954442], sigma noise: [0.36988223 0.4026368  0.34002933 0.342788  ]
[Epoch=300, n_hypersteps=25]: prior precision: [0.34725246 0.17314087 0.1373467  0.48839253], sigma noise: [0.3692865  0.40105283 0.33859935 0.34153607]
[Epoch=300, n_hypersteps=26]: prior precision: [0.3456504  0.17321461 0.13709733 0.486965  ], sigma noise: [0.36845875 0.3991828  0.3369943  0.34010577]
[Epoch=300, n_hypersteps=27]: prior precision: [0.34340584 0.17343207 0.13684595 0.4853628 ], sigma noise: [0.3675214  0.3971884  0.33531567 0.33860052]
[Epoch=300, n_hypersteps=28]: prior precision: [0.34064844 0.173779   0.13659234 0.48368928], sigma noise: [0.3665954  0.39522764 0.3336597  0.3371206 ]
[Epoch=300, n_hypersteps=29]: prior precision: [0.33751142 0.17424233 0.13634208 0.48202324], sigma noise: [0.36579    0.39344186 0.33211857 0.3357572 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.3341141  0.1748068  0.13610382 0.48045   ], sigma noise: [0.3651965  0.3919452  0.33076438 0.33458447]
[Epoch=400, n_hypersteps=1]: prior precision: [0.3301697  0.1751504  0.13588452 0.4792624 ], sigma noise: [0.36456293 0.3904208  0.32943186 0.33342537]
[Epoch=400, n_hypersteps=2]: prior precision: [0.3258335  0.17528006 0.13568558 0.4784811 ], sigma noise: [0.36398178 0.38898352 0.32819724 0.33235162]
[Epoch=400, n_hypersteps=3]: prior precision: [0.32126775 0.17521977 0.13551363 0.47810087], sigma noise: [0.36353043 0.3877311  0.3271165  0.33142266]
[Epoch=400, n_hypersteps=4]: prior precision: [0.31661463 0.1749925  0.13537252 0.4781259 ], sigma noise: [0.36327124 0.3867363  0.32622778 0.3306836 ]
[Epoch=400, n_hypersteps=5]: prior precision: [0.31199962 0.17461012 0.13526225 0.4785093 ], sigma noise: [0.36324385 0.3860468  0.3255564  0.3301619 ]
[Epoch=400, n_hypersteps=6]: prior precision: [0.3075276  0.174102   0.1351781  0.47921112], sigma noise: [0.363465   0.38568136 0.32511562 0.32986766]
[Epoch=400, n_hypersteps=7]: prior precision: [0.30328062 0.17349394 0.13511029 0.48018068], sigma noise: [0.36393175 0.38563165 0.32489404 0.32979405]
[Epoch=400, n_hypersteps=8]: prior precision: [0.29932225 0.17280339 0.13504817 0.48137364], sigma noise: [0.3646179  0.38586536 0.3248736  0.3299195 ]
[Epoch=400, n_hypersteps=9]: prior precision: [0.29572263 0.17205401 0.13499977 0.48272774], sigma noise: [0.3654829  0.38633072 0.3250202  0.33020762]
[Epoch=400, n_hypersteps=10]: prior precision: [0.2925223  0.17125976 0.13496102 0.48418704], sigma noise: [0.36647195 0.38696173 0.32528856 0.3306156 ]
[Epoch=400, n_hypersteps=11]: prior precision: [0.28972897 0.17044121 0.13492876 0.4856815 ], sigma noise: [0.36752567 0.38768536 0.32563096 0.3310939 ]
[Epoch=400, n_hypersteps=12]: prior precision: [0.2873709  0.16961983 0.13491422 0.48713535], sigma noise: [0.36858076 0.38842574 0.32599986 0.3315925 ]
[Epoch=400, n_hypersteps=13]: prior precision: [0.28546476 0.16880482 0.134915   0.48849377], sigma noise: [0.3695775  0.38911414 0.32634583 0.33206514]
[Epoch=400, n_hypersteps=14]: prior precision: [0.2839792  0.16801997 0.13493033 0.4897032 ], sigma noise: [0.3704635  0.38969    0.32663885 0.33247292]
[Epoch=400, n_hypersteps=15]: prior precision: [0.2829101  0.16726553 0.1349599  0.49073237], sigma noise: [0.3712002  0.39010814 0.32684472 0.3327851 ]
[Epoch=400, n_hypersteps=16]: prior precision: [0.28222921 0.16655159 0.13499962 0.49158394], sigma noise: [0.37176156 0.3903392  0.32694682 0.33298287]
[Epoch=400, n_hypersteps=17]: prior precision: [0.28191084 0.16588937 0.13503943 0.4922098 ], sigma noise: [0.37213764 0.3903709  0.32693958 0.33305728]
[Epoch=400, n_hypersteps=18]: prior precision: [0.28192854 0.16528249 0.13508786 0.4926003 ], sigma noise: [0.37233195 0.3902098  0.3268214  0.33301154]
[Epoch=400, n_hypersteps=19]: prior precision: [0.28224736 0.16473795 0.13514861 0.49274835], sigma noise: [0.3723633  0.38987568 0.32660466 0.33285826]
[Epoch=400, n_hypersteps=20]: prior precision: [0.28283498 0.16426067 0.13520731 0.49269813], sigma noise: [0.37226132 0.38940454 0.3263129  0.33261955]
[Epoch=400, n_hypersteps=21]: prior precision: [0.2836534  0.16385263 0.13527147 0.49249187], sigma noise: [0.37206244 0.38883868 0.32597315 0.33232197]
[Epoch=400, n_hypersteps=22]: prior precision: [0.28467423 0.1635189  0.13535099 0.49211535], sigma noise: [0.37180686 0.3882255  0.3256072  0.33199444]
[Epoch=400, n_hypersteps=23]: prior precision: [0.2858546  0.16325708 0.13543864 0.49162832], sigma noise: [0.37153527 0.38761246 0.3252439  0.33166683]
[Epoch=400, n_hypersteps=24]: prior precision: [0.28717262 0.16306445 0.13552712 0.49106702], sigma noise: [0.37128493 0.38704398 0.32491362 0.33136612]
[Epoch=400, n_hypersteps=25]: prior precision: [0.28857785 0.16294535 0.13562554 0.49045578], sigma noise: [0.37108833 0.386554   0.32463208 0.33111557]
[Epoch=400, n_hypersteps=26]: prior precision: [0.29002398 0.1628909  0.13572353 0.48981047], sigma noise: [0.370969   0.38616902 0.3244151  0.3309318 ]
[Epoch=400, n_hypersteps=27]: prior precision: [0.2914665  0.16289803 0.13582838 0.4891846 ], sigma noise: [0.37094015 0.38590387 0.32426935 0.33082566]
[Epoch=400, n_hypersteps=28]: prior precision: [0.2928789  0.1629664  0.13592955 0.48859176], sigma noise: [0.37100706 0.38576338 0.3242009  0.3307992 ]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.48796
wandb:                       Metrics 0.48207
wandb:  Negative_marginal_likelihood 1213.19568
wandb: Predictive_posterior_std_mean 0.71475
wandb:                   Sigma_noise 0.7079
wandb: 
wandb: üöÄ View run wild-sweep-3 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/pb4dekzl
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_165928-pb4dekzl/logs
wandb: Agent Starting Run: 5sss3ms2 with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.1
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_170052-5sss3ms2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/5sss3ms2
[Epoch=400, n_hypersteps=29]: prior precision: [0.29423422 0.1630857  0.13602121 0.48806646], sigma noise: [0.37116274 0.3857411  0.32420298 0.3308477 ]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.1, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8190829  0.8190694  0.81908417 0.8190797 ], sigma noise: [0.8188351  0.81883174 0.81883776 0.8188343 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.7419886  0.74194086 0.741994   0.7419795 ], sigma noise: [0.7412037 0.7411916 0.7412144 0.7412013]
[Epoch=100, n_hypersteps=4]: prior precision: [0.6728252 0.6727171 0.6728401 0.6728101], sigma noise: [0.67124546 0.6712167  0.6712727  0.6712404 ]
[Epoch=100, n_hypersteps=5]: prior precision: [0.6108905  0.61069167 0.610923   0.6108731 ], sigma noise: [0.6083527  0.6082968  0.60840946 0.608344  ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.55551577 0.555193   0.55557656 0.5555046 ], sigma noise: [0.5520109  0.5519133  0.55211586 0.5519972 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50607103 0.5055892  0.5061733  0.5060798 ], sigma noise: [0.50180495 0.5016459  0.50198454 0.50178415]
[Epoch=100, n_hypersteps=8]: prior precision: [0.46196815 0.4612912  0.4621268  0.462016  ], sigma noise: [0.45743096 0.45718262 0.45772266 0.4573994 ]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42266312 0.42175433 0.42289346 0.4227737 ], sigma noise: [0.41871148 0.4183338  0.41916782 0.41866225]
[Epoch=100, n_hypersteps=10]: prior precision: [0.38765606 0.38647848 0.38797304 0.38785666], sigma noise: [0.3856057  0.38504103 0.38629973 0.38552672]
[Epoch=100, n_hypersteps=11]: prior precision: [0.35649067 0.35500753 0.35690722 0.35681093], sigma noise: [0.35819727 0.3573646  0.35922801 0.3580688 ]
[Epoch=100, n_hypersteps=12]: prior precision: [0.32875207 0.32692754 0.32927862 0.32922247], sigma noise: [0.3366268  0.33541858 0.33812085 0.33642024]
[Epoch=100, n_hypersteps=13]: prior precision: [0.3040649  0.30186468 0.3047081  0.30471468], sigma noise: [0.32095528 0.31924087 0.32306132 0.32063377]
[Epoch=100, n_hypersteps=14]: prior precision: [0.28208962 0.27948242 0.28285268 0.2829455 ], sigma noise: [0.31101343 0.308649   0.31389117 0.3105366 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.26252005 0.25947887 0.26340312 0.2636055 ], sigma noise: [0.30635348 0.3031909  0.31016386 0.3056813 ]
[Epoch=100, n_hypersteps=16]: prior precision: [0.2450814  0.24158423 0.24608213 0.24641505], sigma noise: [0.30633828 0.30222705 0.31124339 0.30543274]
[Epoch=100, n_hypersteps=17]: prior precision: [0.2295277  0.22555795 0.2306422  0.2311233 ], sigma noise: [0.310275   0.30505812 0.31644484 0.30909982]
[Epoch=100, n_hypersteps=18]: prior precision: [0.21563983 0.21118665 0.21686308 0.21750632], sigma noise: [0.31749904 0.31100687 0.3251189  0.3160192 ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.20322329 0.1982812  0.20455006 0.20536536], sigma noise: [0.32738888 0.31943774 0.33666176 0.32557   ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.19210634 0.18667454 0.19353156 0.19452485], sigma noise: [0.33934548 0.32974073 0.35048681 0.33715612]
[Epoch=100, n_hypersteps=21]: prior precision: [0.18213813 0.1762193  0.18365644 0.18483037], sigma noise: [0.35276318 0.3413116  0.3659903  0.3501789 ]
[Epoch=100, n_hypersteps=22]: prior precision: [0.17318586 0.16678597 0.1747927  0.17614667], sigma noise: [0.3670129  0.35354015 0.38252446 0.36402184]
[Epoch=100, n_hypersteps=23]: prior precision: [0.16513334 0.1582607  0.1668243  0.16835594], sigma noise: [0.38144532 0.36581767 0.39939272 0.37805304]
[Epoch=100, n_hypersteps=24]: prior precision: [0.15787943 0.15054344 0.15965024 0.16135538], sigma noise: [0.39540964 0.37755746 0.4158699  0.39164427]
[Epoch=100, n_hypersteps=25]: prior precision: [0.1513355  0.1435464  0.15318243 0.15505594], sigma noise: [0.40828907 0.38822573 0.43123752 0.40420344]
[Epoch=100, n_hypersteps=26]: prior precision: [0.14542452 0.13719249 0.14734408 0.14938031], sigma noise: [0.4195391  0.3973723  0.44483483 0.41520968]
[Epoch=100, n_hypersteps=27]: prior precision: [0.14007942 0.13141401 0.1420684  0.14426178], sigma noise: [0.4287245  0.4046551  0.45611098 0.42424703]
[Epoch=100, n_hypersteps=28]: prior precision: [0.13524194 0.12615147 0.13729711 0.13964269], sigma noise: [0.43554693 0.40985417 0.4646646  0.4310286 ]
[Epoch=100, n_hypersteps=29]: prior precision: [0.13086118 0.12135273 0.13297963 0.1354733 ], sigma noise: [0.43985477 0.41287586 0.47027314 0.4354072 ]
[Epoch=200, n_hypersteps=0]: prior precision: [0.1268928  0.1169717  0.12907189 0.13171065], sigma noise: [0.44164222 0.41374534 0.47289497 0.4373724 ]
[Epoch=200, n_hypersteps=1]: prior precision: [0.12328677 0.11306999 0.12561104 0.12827986], sigma noise: [0.4408964  0.41277647 0.47270808 0.4367535 ]
[Epoch=200, n_hypersteps=2]: prior precision: [0.12001078 0.10959477 0.12255256 0.12515232], sigma noise: [0.4378734 0.4101602 0.4699802 0.4338068]
[Epoch=200, n_hypersteps=3]: prior precision: [0.11703673 0.10650044 0.11985806 0.12230314], sigma noise: [0.43291432 0.40614703 0.46508858 0.42887488]
[Epoch=200, n_hypersteps=4]: prior precision: [0.11433956 0.10374767 0.11749443 0.11971061], sigma noise: [0.42641577 0.40102884 0.45848405 0.4223567 ]
[Epoch=200, n_hypersteps=5]: prior precision: [0.1118971  0.10130218 0.11543308 0.11735571], sigma noise: [0.41880593 0.3951239  0.4506594  0.41467988]
[Epoch=200, n_hypersteps=6]: prior precision: [0.10968982 0.09913413 0.11364896 0.11522175], sigma noise: [0.4105182  0.38876027 0.44211844 0.4062774 ]
[Epoch=200, n_hypersteps=7]: prior precision: [0.10770025 0.09721759 0.11212014 0.11329393], sigma noise: [0.40197152 0.38226396 0.43335292 0.3975676 ]
[Epoch=200, n_hypersteps=8]: prior precision: [0.1059126  0.09552961 0.11082738 0.11155875], sigma noise: [0.3935551  0.37594646 0.42482242 0.38893643]
[Epoch=200, n_hypersteps=9]: prior precision: [0.10431282 0.09404988 0.10975336 0.11000419], sigma noise: [0.38561523 0.37009493 0.41693926 0.3807264 ]
[Epoch=200, n_hypersteps=10]: prior precision: [0.10288767 0.0927605  0.10888243 0.10861913], sigma noise: [0.3784469  0.36496225 0.4100563  0.37322578]
[Epoch=200, n_hypersteps=11]: prior precision: [0.1016254  0.09164526 0.10820038 0.1073933 ], sigma noise: [0.37228325 0.36075884 0.40445787 0.36666077]
[Epoch=200, n_hypersteps=12]: prior precision: [0.10051478 0.09068957 0.10769363 0.10631702], sigma noise: [0.36728898 0.35764295 0.40035325 0.36119118]
[Epoch=200, n_hypersteps=13]: prior precision: [0.09954541 0.08988015 0.10734935 0.10538089], sigma noise: [0.36356217 0.35571748 0.39787248 0.35690847]
[Epoch=200, n_hypersteps=14]: prior precision: [0.09870718 0.08920475 0.1071554  0.10457581], sigma noise: [0.36113232 0.35502568 0.39706603 0.35383657]
[Epoch=200, n_hypersteps=15]: prior precision: [0.09799038 0.08865201 0.10709992 0.10389277], sigma noise: [0.35996312 0.35555092 0.39790776 0.3519384 ]
[Epoch=200, n_hypersteps=16]: prior precision: [0.09738587 0.08821145 0.10717136 0.103323  ], sigma noise: [0.35996068 0.3572198  0.40029797 0.35111892]
[Epoch=200, n_hypersteps=17]: prior precision: [0.09688488 0.0878733  0.10735831 0.10285819], sigma noise: [0.36098164 0.3599061  0.40407032 0.35123846]
[Epoch=200, n_hypersteps=18]: prior precision: [0.09647883 0.08762836 0.10764965 0.10248999], sigma noise: [0.36284107 0.36344162 0.40900007 0.35212165]
[Epoch=200, n_hypersteps=19]: prior precision: [0.09615956 0.08746797 0.1080341  0.10221025], sigma noise: [0.365327   0.36762118 0.41481435 0.35356978]
[Epoch=200, n_hypersteps=20]: prior precision: [0.09591946 0.08738405 0.1085011  0.10201128], sigma noise: [0.3682119 0.3722172 0.4212025 0.3553729]
[Epoch=200, n_hypersteps=21]: prior precision: [0.09575138 0.08736915 0.10904038 0.10188571], sigma noise: [0.37126446 0.37698936 0.42783174 0.35732263]
[Epoch=200, n_hypersteps=22]: prior precision: [0.09564821 0.08741634 0.10964207 0.10182672], sigma noise: [0.37426445 0.38169962 0.43436444 0.3592247 ]
[Epoch=200, n_hypersteps=23]: prior precision: [0.09560373 0.08751913 0.11029678 0.10182793], sigma noise: [0.37701    0.38612518 0.44047675 0.3609075 ]
[Epoch=200, n_hypersteps=24]: prior precision: [0.09561225 0.08767172 0.11099601 0.10188345], sigma noise: [0.37933502 0.3900706  0.44587916 0.36222988]
[Epoch=200, n_hypersteps=25]: prior precision: [0.09566862 0.08786876 0.11173175 0.10198805], sigma noise: [0.38110873 0.3933792  0.4503347  0.36308792]
[Epoch=200, n_hypersteps=26]: prior precision: [0.09576807 0.08810532 0.11249705 0.10213683], sigma noise: [0.3822492  0.39594042 0.453674   0.36341673]
[Epoch=200, n_hypersteps=27]: prior precision: [0.09590609 0.08837713 0.11328553 0.10232558], sigma noise: [0.3827185  0.3976958  0.45580626 0.3631909 ]
[Epoch=200, n_hypersteps=28]: prior precision: [0.09607919 0.08868038 0.11409167 0.10255078], sigma noise: [0.38252398 0.39863837 0.4567205  0.3624233 ]
[Epoch=200, n_hypersteps=29]: prior precision: [0.09628399 0.08901163 0.1149107  0.10280913], sigma noise: [0.38171345 0.39880913 0.45648313 0.36115912]
[Epoch=300, n_hypersteps=0]: prior precision: [0.09651753 0.08936785 0.11573853 0.10309771], sigma noise: [0.38036925 0.3982928  0.4552275  0.35947278]
[Epoch=300, n_hypersteps=1]: prior precision: [0.09677907 0.08991496 0.11649623 0.10352465], sigma noise: [0.37872103 0.39797878 0.45316285 0.35772535]
[Epoch=300, n_hypersteps=2]: prior precision: [0.09706626 0.09063809 0.11718636 0.10407956], sigma noise: [0.3768714 0.3979222 0.45049   0.3559855]
[Epoch=300, n_hypersteps=3]: prior precision: [0.09737694 0.09152359 0.11781202 0.10475279], sigma noise: [0.3749224  0.3981816  0.4474114  0.35432094]
[Epoch=300, n_hypersteps=4]: prior precision: [0.09770905 0.09255876 0.11837666 0.10553531], sigma noise: [0.37296945 0.3988135  0.44411802 0.3527944 ]
[Epoch=300, n_hypersteps=5]: prior precision: [0.09806059 0.09373156 0.11888373 0.10641848], sigma noise: [0.37109622 0.39986694 0.4407787  0.3514598 ]
[Epoch=300, n_hypersteps=6]: prior precision: [0.09842988 0.09503037 0.11933704 0.10739399], sigma noise: [0.3693709  0.4013793  0.43753326 0.35035938]
[Epoch=300, n_hypersteps=7]: prior precision: [0.09881475 0.09644381 0.11974024 0.10845374], sigma noise: [0.36784387 0.40337202 0.43448696 0.34952158]
[Epoch=300, n_hypersteps=8]: prior precision: [0.09921335 0.0979606  0.12009694 0.10958973], sigma noise: [0.3665458  0.40584743 0.43170995 0.34895986]
[Epoch=300, n_hypersteps=9]: prior precision: [0.0996237  0.09956946 0.12041079 0.11079399], sigma noise: [0.36548778 0.40878654 0.42923814 0.34867245]
[Epoch=300, n_hypersteps=10]: prior precision: [0.10004385 0.10125896 0.12068498 0.11205854], sigma noise: [0.3646634  0.41214815 0.42707512 0.3486429 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.10047182 0.10301752 0.12092257 0.11337548], sigma noise: [0.36404973 0.41586924 0.4251984  0.34884205]
[Epoch=300, n_hypersteps=12]: prior precision: [0.10090596 0.10483343 0.12112649 0.11473683], sigma noise: [0.3636115  0.41986734 0.42356494 0.34923044]
[Epoch=300, n_hypersteps=13]: prior precision: [0.10134417 0.10669486 0.12129936 0.11613461], sigma noise: [0.36330536 0.42404345 0.42211783 0.34976116]
[Epoch=300, n_hypersteps=14]: prior precision: [0.10178446 0.1085899  0.12144382 0.11756092], sigma noise: [0.36308265 0.42828712 0.4207928  0.35038325]
[Epoch=300, n_hypersteps=15]: prior precision: [0.10222507 0.11050665 0.12156229 0.119008  ], sigma noise: [0.36289445 0.43248254 0.41952524 0.3510453 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.10266417 0.11243337 0.12165716 0.12046823], sigma noise: [0.3626963  0.4365151  0.41825593 0.35169876]
[Epoch=300, n_hypersteps=17]: prior precision: [0.1031     0.11435851 0.12173072 0.12193422], sigma noise: [0.36244807 0.44027823 0.41693544 0.3523003 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.10353122 0.11627097 0.12178526 0.12339887], sigma noise: [0.36212027 0.44368044 0.4155285  0.35281515]
[Epoch=300, n_hypersteps=19]: prior precision: [0.10395625 0.11816008 0.12182307 0.12485545], sigma noise: [0.36169377 0.4466504  0.41401544 0.35321823]
[Epoch=300, n_hypersteps=20]: prior precision: [0.10437395 0.12001579 0.1218464  0.12629755], sigma noise: [0.36116105 0.44914162 0.41239268 0.3534951 ]
[Epoch=300, n_hypersteps=21]: prior precision: [0.10478333 0.12182873 0.12185749 0.12771913], sigma noise: [0.3605242  0.45113456 0.4106723  0.35364246]
[Epoch=300, n_hypersteps=22]: prior precision: [0.10518377 0.1235904  0.12185849 0.12911475], sigma noise: [0.35979706 0.45263663 0.40888032 0.35366696]
[Epoch=300, n_hypersteps=23]: prior precision: [0.10557442 0.12529309 0.12185145 0.13047923], sigma noise: [0.35900065 0.4536802  0.40705368 0.3535845 ]
[Epoch=300, n_hypersteps=24]: prior precision: [0.10595453 0.12692997 0.12183838 0.13180797], sigma noise: [0.35816374 0.45431864 0.40523696 0.35341787]
[Epoch=300, n_hypersteps=25]: prior precision: [0.10632373 0.12849511 0.12182113 0.13309674], sigma noise: [0.35731813 0.4546208  0.4034786  0.35319498]
[Epoch=300, n_hypersteps=26]: prior precision: [0.10668176 0.1299835  0.12180144 0.13434188], sigma noise: [0.35649782 0.45466456 0.401828   0.35294625]
[Epoch=300, n_hypersteps=27]: prior precision: [0.10702816 0.13139096 0.12178082 0.13554005], sigma noise: [0.35573596 0.45453027 0.40033123 0.352702  ]
[Epoch=300, n_hypersteps=28]: prior precision: [0.10736271 0.13271415 0.12176061 0.13668832], sigma noise: [0.35506055 0.4542948  0.39902788 0.35249007]
[Epoch=300, n_hypersteps=29]: prior precision: [0.10768533 0.1339505  0.12174177 0.13778414], sigma noise: [0.354496   0.45402557 0.3979492  0.35233405]
[Epoch=400, n_hypersteps=0]: prior precision: [0.10799518 0.13509817 0.12172508 0.13882524], sigma noise: [0.35405973 0.45377702 0.3971165  0.3522516 ]
[Epoch=400, n_hypersteps=1]: prior precision: [0.10829841 0.13608386 0.1214909  0.13990588], sigma noise: [0.35251638 0.45086327 0.3943648  0.3510544 ]
[Epoch=400, n_hypersteps=2]: prior precision: [0.10859494 0.13691474 0.12106176 0.14101993], sigma noise: [0.35007814 0.44580603 0.39005607 0.34894517]
[Epoch=400, n_hypersteps=3]: prior precision: [0.10888515 0.13760005 0.12046061 0.14216249], sigma noise: [0.34700996 0.4392564  0.38462698 0.34618115]
[Epoch=400, n_hypersteps=4]: prior precision: [0.10916961 0.1381505  0.1197101  0.14332959], sigma noise: [0.34360647 0.43191728 0.37854424 0.34305134]
[Epoch=400, n_hypersteps=5]: prior precision: [0.10944919 0.13857773 0.11883207 0.14451781], sigma noise: [0.3401687  0.4244748  0.37226436 0.3398533 ]
[Epoch=400, n_hypersteps=6]: prior precision: [0.10972463 0.13889363 0.11784742 0.14572394], sigma noise: [0.33698204 0.4175446  0.36619958 0.3368709 ]
[Epoch=400, n_hypersteps=7]: prior precision: [0.10999662 0.13910988 0.11677565 0.14694467], sigma noise: [0.3342963  0.41163376 0.36069262 0.3343543 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.11026546 0.1392374  0.11563485 0.1481763 ], sigma noise: [0.3323093  0.40711856 0.35599962 0.33250248]
[Epoch=400, n_hypersteps=9]: prior precision: [0.11053123 0.13928601 0.11444139 0.14941444], sigma noise: [0.331154   0.4042343  0.3522804  0.33145007]
[Epoch=400, n_hypersteps=10]: prior precision: [0.11079346 0.13926439 0.1132099  0.150654  ], sigma noise: [0.33089164 0.40307584 0.34959838 0.33126   ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.183 MB of 0.299 MB uploaded (0.000 MB deduped)wandb: \ 0.183 MB of 0.299 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.512
wandb:                       Metrics 0.49883
wandb:  Negative_marginal_likelihood 1286.68237
wandb: Predictive_posterior_std_mean 0.73932
wandb:                   Sigma_noise 0.7291
wandb: 
wandb: üöÄ View run leafy-sweep-4 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/5sss3ms2
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_170052-5sss3ms2/logs
wandb: Agent Starting Run: 1gvhbv5s with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.01
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_171121-1gvhbv5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/1gvhbv5s
[Epoch=400, n_hypersteps=11]: prior precision: [0.11105141 0.13917989 0.11195328 0.15188898], sigma noise: [0.3315106  0.40360615 0.3479264  0.331922  ]
[Epoch=400, n_hypersteps=12]: prior precision: [0.11130375 0.13903844 0.11068273 0.15311268], sigma noise: [0.33293137 0.40566993 0.3471606  0.33335713]
[Epoch=400, n_hypersteps=13]: prior precision: [0.11154901 0.13884504 0.1094081  0.15431783], sigma noise: [0.33501634 0.40901148 0.34713605 0.33542815]
[Epoch=400, n_hypersteps=14]: prior precision: [0.11178546 0.13860366 0.10813771 0.15549682], sigma noise: [0.33758447 0.41329715 0.34764767 0.33795395]
[Epoch=400, n_hypersteps=15]: prior precision: [0.11201137 0.13831778 0.10687874 0.15664206], sigma noise: [0.3404285  0.41814065 0.34847173 0.34072706]
[Epoch=400, n_hypersteps=16]: prior precision: [0.11222501 0.13799055 0.10563734 0.15774629], sigma noise: [0.3433336  0.4231326  0.34938633 0.34353256]
[Epoch=400, n_hypersteps=17]: prior precision: [0.11242476 0.13762513 0.10441863 0.15880284], sigma noise: [0.34609553 0.42787355 0.35018942 0.34616667]
[Epoch=400, n_hypersteps=18]: prior precision: [0.11260941 0.13722484 0.10322702 0.15980601], sigma noise: [0.348537   0.43200755 0.35071492 0.34845337]
[Epoch=400, n_hypersteps=19]: prior precision: [0.11277795 0.13679338 0.10206621 0.16075122], sigma noise: [0.35052073 0.43525234 0.35084343 0.35025758]
[Epoch=400, n_hypersteps=20]: prior precision: [0.11292997 0.13633496 0.10093946 0.16163518], sigma noise: [0.35195825 0.43742263 0.35050663 0.35149375]
[Epoch=400, n_hypersteps=21]: prior precision: [0.11306541 0.13585432 0.09984946 0.16245584], sigma noise: [0.35281384 0.43844277 0.3496878  0.35212937]
[Epoch=400, n_hypersteps=22]: prior precision: [0.11318448 0.13535659 0.09879825 0.16321254], sigma noise: [0.35310304 0.438347   0.34841862 0.35218355]
[Epoch=400, n_hypersteps=23]: prior precision: [0.11328788 0.13484727 0.09778782 0.16390577], sigma noise: [0.35288724 0.43726793 0.34676972 0.35172102]
[Epoch=400, n_hypersteps=24]: prior precision: [0.11337659 0.13433202 0.09681955 0.1645371 ], sigma noise: [0.3522649  0.43541464 0.34484243 0.3508428 ]
[Epoch=400, n_hypersteps=25]: prior precision: [0.11345179 0.13381651 0.09589447 0.16510889], sigma noise: [0.35135952 0.43304583 0.34275627 0.34967434]
[Epoch=400, n_hypersteps=26]: prior precision: [0.11351472 0.13330606 0.09501322 0.16562407], sigma noise: [0.3503073  0.43044043 0.34063733 0.34835282]
[Epoch=400, n_hypersteps=27]: prior precision: [0.1135667  0.13280566 0.09417641 0.16608597], sigma noise: [0.34924367 0.42787012 0.33860663 0.34701425]
[Epoch=400, n_hypersteps=28]: prior precision: [0.11360902 0.13231975 0.0933841  0.16649802], sigma noise: [0.3482926  0.4255768  0.33677104 0.34578195]
[Epoch=400, n_hypersteps=29]: prior precision: [0.1136428  0.13185197 0.09263603 0.16686356], sigma noise: [0.34755576 0.42375365 0.33521616 0.34475684]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.01, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.83216476 0.8220816  0.82103026 0.8197483 ], sigma noise: [0.81888896 0.81890494 0.818912   0.81883   ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.80120635 0.75489384 0.75004786 0.744523  ], sigma noise: [0.7414003  0.74146265 0.74149114 0.74118614]
[Epoch=100, n_hypersteps=4]: prior precision: [0.80952966 0.7078146  0.6942439  0.6790671 ], sigma noise: [0.6717027  0.671867   0.6719424  0.67120564]
[Epoch=100, n_hypersteps=5]: prior precision: [0.8427558  0.68375367 0.656107   0.6234145 ], sigma noise: [0.60921603 0.60957175 0.60973674 0.6082785 ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.89286524 0.6810706  0.6365201  0.5777022 ], sigma noise: [0.5534629  0.55413413 0.55445606 0.5518857 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.95630354 0.69564193 0.6339311  0.5420651 ], sigma noise: [0.50408375 0.50523096 0.50580835 0.501603  ]
[Epoch=100, n_hypersteps=8]: prior precision: [1.0313672  0.72386295 0.6456096  0.51649207], sigma noise: [0.46085286 0.46268198 0.46365136 0.45710588]
[Epoch=100, n_hypersteps=9]: prior precision: [1.116861   0.76341563 0.66908735 0.50071204], sigma noise: [0.4236924  0.42647013 0.42801377 0.4181713 ]
[Epoch=100, n_hypersteps=10]: prior precision: [1.2111716  0.8129394  0.7026264  0.49411684], sigma noise: [0.39266282 0.39673457 0.39908734 0.38466555]
[Epoch=100, n_hypersteps=11]: prior precision: [1.3112587  0.87156624 0.74509513 0.4959289 ], sigma noise: [0.36790058 0.37369546 0.37714213 0.35649922]
[Epoch=100, n_hypersteps=12]: prior precision: [1.4114093  0.9384794  0.79567647 0.50532657], sigma noise: [0.3494786  0.3574889  0.36234495 0.33353916]
[Epoch=100, n_hypersteps=13]: prior precision: [1.5024039 1.0124357 0.8535369 0.5215893], sigma noise: [0.33723846 0.3479748  0.35455543 0.3154996 ]
[Epoch=100, n_hypersteps=14]: prior precision: [1.5730035  1.0911677  0.917451   0.54412246], sigma noise: [0.3307162  0.34467006 0.35326934 0.30188614]
[Epoch=100, n_hypersteps=15]: prior precision: [1.6144929 1.1706998 0.9853384 0.5724486], sigma noise: [0.32922196 0.34685886 0.3577564  0.29203296]
[Epoch=100, n_hypersteps=16]: prior precision: [1.6245142 1.2449355 1.0537927 0.6061418], sigma noise: [0.33198574 0.35376236 0.3672423  0.28520018]
[Epoch=100, n_hypersteps=17]: prior precision: [1.6065342 1.3062538 1.1178443 0.6447589], sigma noise: [0.33825696 0.364636   0.3810016  0.28066316]
[Epoch=100, n_hypersteps=18]: prior precision: [1.5669122 1.3476316 1.1714432 0.6877184], sigma noise: [0.3473314 0.3787751 0.3983473 0.2777653]
[Epoch=100, n_hypersteps=19]: prior precision: [1.5125916 1.3651601 1.2089105 0.7342115], sigma noise: [0.35853475 0.3954699  0.41856438 0.27594173]
[Epoch=100, n_hypersteps=20]: prior precision: [1.4499861 1.3589681 1.2267112 0.7830546], sigma noise: [0.37119776 0.41395187 0.440832   0.27472633]
[Epoch=100, n_hypersteps=21]: prior precision: [1.3846183  1.3322532  1.2243339  0.83270466], sigma noise: [0.38464382 0.43335885 0.4641665  0.27375337]
[Epoch=100, n_hypersteps=22]: prior precision: [1.3210306  1.2896912  1.2038516  0.88115644], sigma noise: [0.39819685 0.45273733 0.48741168 0.2727524 ]
[Epoch=100, n_hypersteps=23]: prior precision: [1.2627842  1.2362282  1.1688304  0.92611104], sigma noise: [0.41120648 0.47108907 0.50929457 0.27154008]
[Epoch=100, n_hypersteps=24]: prior precision: [1.2124869 1.1764387 1.1233315 0.9652184], sigma noise: [0.42308357 0.48745355 0.52854806 0.2700057 ]
[Epoch=100, n_hypersteps=25]: prior precision: [1.1718229 1.1142644 1.0712882 0.9964286], sigma noise: [0.43333495 0.5010064  0.5440708  0.2680959 ]
[Epoch=100, n_hypersteps=26]: prior precision: [1.1416337 1.0529566 1.0161997 1.018299 ], sigma noise: [0.4415904  0.51114625 0.5550759  0.26579958]
[Epoch=100, n_hypersteps=27]: prior precision: [1.1220533 0.9951092 0.9610197 1.0302014], sigma noise: [0.44761747 0.5175476  0.56118196 0.26313514]
[Epoch=100, n_hypersteps=28]: prior precision: [1.1126754 0.9427174 0.9081499 1.0324111], sigma noise: [0.451325   0.52017206 0.5624255  0.26014003]
[Epoch=100, n_hypersteps=29]: prior precision: [1.1127094  0.8972422  0.85947526 1.0259168 ], sigma noise: [0.45275632 0.51924145 0.5592063  0.25686425]
[Epoch=200, n_hypersteps=0]: prior precision: [1.1211048  0.85967684 0.81641597 1.0122333 ], sigma noise: [0.4520757  0.5151874  0.5521942  0.25336465]
[Epoch=200, n_hypersteps=1]: prior precision: [1.1143359  0.813974   0.77108276 0.9932121 ], sigma noise: [0.4477911  0.50581986 0.53927535 0.24948257]
[Epoch=200, n_hypersteps=2]: prior precision: [1.0952424  0.76438487 0.7258447  0.9705679 ], sigma noise: [0.44052467 0.49237424 0.5220421  0.24531014]
[Epoch=200, n_hypersteps=3]: prior precision: [1.0675734  0.71417826 0.68252367 0.9460485 ], sigma noise: [0.43100807 0.47613725 0.5020598  0.24094309]
[Epoch=200, n_hypersteps=4]: prior precision: [1.0353085  0.6657799  0.64245754 0.92119193], sigma noise: [0.42003152 0.4583515  0.48076892 0.23648211]
[Epoch=200, n_hypersteps=5]: prior precision: [1.0022247  0.62091357 0.60656923 0.8973675 ], sigma noise: [0.40840188 0.4401585  0.4594356  0.2320342 ]
[Epoch=200, n_hypersteps=6]: prior precision: [0.9716301  0.58072287 0.57543796 0.87566376], sigma noise: [0.3969086  0.42256588 0.43913358 0.22771314]
[Epoch=200, n_hypersteps=7]: prior precision: [0.94617635 0.54588604 0.54936403 0.8569593 ], sigma noise: [0.3862935  0.40642872 0.42073733 0.22363521]
[Epoch=200, n_hypersteps=8]: prior precision: [0.9277467  0.516713   0.5284304  0.84186286], sigma noise: [0.37721944 0.39243442 0.40492067 0.21991515]
[Epoch=200, n_hypersteps=9]: prior precision: [0.9174228  0.49323478 0.51255924 0.83082247], sigma noise: [0.37023723 0.38108957 0.3921535  0.21665515]
[Epoch=200, n_hypersteps=10]: prior precision: [0.9155141  0.47527876 0.50155616 0.824016  ], sigma noise: [0.36575305 0.37270957 0.38270172 0.2139346 ]
[Epoch=200, n_hypersteps=11]: prior precision: [0.9216678  0.46254617 0.49514833 0.82144874], sigma noise: [0.3640043  0.3674171  0.37663496 0.21179877]
[Epoch=200, n_hypersteps=12]: prior precision: [0.9349647  0.45465994 0.4930162  0.822994  ], sigma noise: [0.36505023 0.36515614 0.3738471  0.21025267]
[Epoch=200, n_hypersteps=13]: prior precision: [0.9539918  0.45120758 0.49480915 0.8283401 ], sigma noise: [0.36877933 0.36571604 0.3740843  0.20925908]
[Epoch=200, n_hypersteps=14]: prior precision: [0.9768699  0.45176828 0.50015455 0.83702743], sigma noise: [0.37492567 0.36876154 0.37697747 0.20874368]
[Epoch=200, n_hypersteps=15]: prior precision: [1.0012964  0.45591688 0.5086574  0.84852886], sigma noise: [0.38308793 0.37386024 0.38206926 0.20860545]
[Epoch=200, n_hypersteps=16]: prior precision: [1.0246403  0.46322736 0.51989615 0.8622516 ], sigma noise: [0.39274603 0.38050628 0.38883597 0.20873003]
[Epoch=200, n_hypersteps=17]: prior precision: [1.0441841  0.47326258 0.5334112  0.8775073 ], sigma noise: [0.40328267 0.38814318 0.39670864 0.2090016 ]
[Epoch=200, n_hypersteps=18]: prior precision: [1.0575142 0.4855631 0.5486949 0.8935122], sigma noise: [0.41401258 0.3961896  0.4050951  0.2093132 ]
[Epoch=200, n_hypersteps=19]: prior precision: [1.0629239  0.49963832 0.5651989  0.9094275 ], sigma noise: [0.42422646 0.40407073 0.41341034 0.20957468]
[Epoch=200, n_hypersteps=20]: prior precision: [1.0597426  0.5149616  0.582326   0.92451626], sigma noise: [0.43324855 0.4112547  0.42110944 0.20971553]
[Epoch=200, n_hypersteps=21]: prior precision: [1.0484005  0.53097135 0.5994544  0.93800616], sigma noise: [0.44050103 0.41728964 0.42772514 0.2096863 ]
[Epoch=200, n_hypersteps=22]: prior precision: [1.0302796  0.54707843 0.6159507  0.94929343], sigma noise: [0.4455619  0.4218361  0.43289915 0.20945752]
[Epoch=200, n_hypersteps=23]: prior precision: [1.0074136 0.5626915 0.6312107 0.9579594], sigma noise: [0.44820413 0.4246885  0.4364052  0.2090185 ]
[Epoch=200, n_hypersteps=24]: prior precision: [0.98214126 0.57724243 0.64469653 0.96375835], sigma noise: [0.44840816 0.42578357 0.43815884 0.20837265]
[Epoch=200, n_hypersteps=25]: prior precision: [0.9568244  0.59022343 0.6559677  0.96657854], sigma noise: [0.4463479  0.4251948  0.4382145  0.20753714]
[Epoch=200, n_hypersteps=26]: prior precision: [0.93362224 0.6012186  0.6647184  0.96656615], sigma noise: [0.44235486 0.4231144  0.4367502  0.20653877]
[Epoch=200, n_hypersteps=27]: prior precision: [0.91433775 0.60993326 0.6707915  0.96406406], sigma noise: [0.4368721  0.419828   0.43404308 0.20541182]
[Epoch=200, n_hypersteps=28]: prior precision: [0.9003354 0.6162103 0.6741858 0.9595444], sigma noise: [0.43040276 0.41568443 0.43044102 0.20419677]
[Epoch=200, n_hypersteps=29]: prior precision: [0.89250106 0.6200347  0.67504245 0.9535313 ], sigma noise: [0.42346355 0.4110637  0.42632937 0.20293799]
[Epoch=300, n_hypersteps=0]: prior precision: [0.8912627 0.6215215 0.6736204 0.9466227], sigma noise: [0.41654453 0.40634793 0.4221015  0.20168127]
[Epoch=300, n_hypersteps=1]: prior precision: [0.8930807  0.61484265 0.6702759  0.94577926], sigma noise: [0.41001463 0.40147257 0.41823354 0.20048481]
[Epoch=300, n_hypersteps=2]: prior precision: [0.8980339  0.60143316 0.6654125  0.9506517 ], sigma noise: [0.40424466 0.3968051  0.41504896 0.19938815]
[Epoch=300, n_hypersteps=3]: prior precision: [0.9059319  0.5829546  0.65944374 0.960556  ], sigma noise: [0.39951852 0.39264816 0.41281205 0.19842403]
[Epoch=300, n_hypersteps=4]: prior precision: [0.91632736 0.5610754  0.65277    0.97480536], sigma noise: [0.3960238  0.38922232 0.4117137  0.19761607]
[Epoch=300, n_hypersteps=5]: prior precision: [0.9285206  0.53732425 0.64575166 0.9924513 ], sigma noise: [0.3938497  0.38665873 0.41186094 0.19697629]
[Epoch=300, n_hypersteps=6]: prior precision: [0.9416056  0.5130023  0.63869536 1.0125194 ], sigma noise: [0.39299026 0.3849989  0.41327232 0.19650476]
[Epoch=300, n_hypersteps=7]: prior precision: [0.9545218  0.48914686 0.63184446 1.0338345 ], sigma noise: [0.39335227 0.38420188 0.415879   0.19618936]
[Epoch=300, n_hypersteps=8]: prior precision: [0.9661574  0.46653724 0.625381   1.0552301 ], sigma noise: [0.39476874 0.3841563  0.41953143 0.19600816]
[Epoch=300, n_hypersteps=9]: prior precision: [0.9754581  0.44571882 0.61943036 1.0754608 ], sigma noise: [0.39701384 0.3846977  0.4240109  0.19593145]
[Epoch=300, n_hypersteps=10]: prior precision: [0.981557   0.4270421  0.61406636 1.0933672 ], sigma noise: [0.39982176 0.38562813 0.42904449 0.1959257 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.9838993  0.41070184 0.60932535 1.1079366 ], sigma noise: [0.40290722 0.3867354  0.43432575 0.19595571]
[Epoch=300, n_hypersteps=12]: prior precision: [0.98231643 0.39677674 0.60521007 1.1184014 ], sigma noise: [0.40598738 0.38781297 0.43953782 0.19598874]
[Epoch=300, n_hypersteps=13]: prior precision: [0.9770513  0.38526186 0.601706   1.1244045 ], sigma noise: [0.4088033  0.38867816 0.44437775 0.19599672]
[Epoch=300, n_hypersteps=14]: prior precision: [0.96871847 0.37609354 0.5987846  1.1258935 ], sigma noise: [0.41114008 0.38918525 0.44858235 0.19595775]
[Epoch=300, n_hypersteps=15]: prior precision: [0.95820767 0.36917514 0.5964133  1.1231606 ], sigma noise: [0.41284168 0.38923523 0.45194802 0.19585674]
[Epoch=300, n_hypersteps=16]: prior precision: [0.94657165 0.3643877  0.594563   1.1167725 ], sigma noise: [0.41382056 0.3887803  0.45434797 0.19568636]
[Epoch=300, n_hypersteps=17]: prior precision: [0.93489814 0.3615967  0.5932064  1.1075304 ], sigma noise: [0.41406047 0.38782355 0.4557392  0.1954461 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.924205   0.36066318 0.5923212  1.096363  ], sigma noise: [0.4136118  0.38641354 0.45616183 0.19514178]
[Epoch=300, n_hypersteps=19]: prior precision: [0.915364   0.36144286 0.59189045 1.0842475 ], sigma noise: [0.41258183 0.38463646 0.45573008 0.19478416]
[Epoch=300, n_hypersteps=20]: prior precision: [0.9090312  0.36378744 0.5918986  1.072189  ], sigma noise: [0.41112012 0.38260555 0.4546163  0.19438869]
[Epoch=300, n_hypersteps=21]: prior precision: [0.90561765 0.36753964 0.59232897 1.0609983 ], sigma noise: [0.4094015  0.38044956 0.4530307  0.19397219]
[Epoch=300, n_hypersteps=22]: prior precision: [0.9052766  0.37253565 0.5931603  1.0513322 ], sigma noise: [0.4076089  0.37830055 0.45119905 0.19355325]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.208 MB of 0.297 MB uploaded (0.000 MB deduped)wandb: \ 0.297 MB of 0.297 MB uploaded (0.000 MB deduped)wandb: | 0.297 MB of 0.297 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÑ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÇ‚ñÅ‚ñÑ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.56352
wandb:                       Metrics 0.54689
wandb:  Negative_marginal_likelihood 1357.27502
wandb: Predictive_posterior_std_mean 0.83573
wandb:                   Sigma_noise 0.79159
wandb: 
wandb: üöÄ View run treasured-sweep-5 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/1gvhbv5s
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_171121-1gvhbv5s/logs
wandb: Agent Starting Run: l5uyrv4u with config:
wandb: 	activation_cls: relu
wandb: 	hidden_sizes: 1024
wandb: 	lr: 0.001
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /scratch/work/zhangx18/Reproduced-LA-NAM/wandb/run-20230815_172355-l5uyrv4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0
wandb: üßπ View sweep at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/sweeps/1vu0rcp3
wandb: üöÄ View run at https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/l5uyrv4u
[Epoch=300, n_hypersteps=23]: prior precision: [0.9079087  0.37859875 0.59436435 1.0436916 ], sigma noise: [0.40591648 0.3762833  0.44934183 0.19315019]
[Epoch=300, n_hypersteps=24]: prior precision: [0.9131768  0.38553783 0.59590083 1.0384072 ], sigma noise: [0.40447545 0.37450454 0.44765434 0.19277912]
[Epoch=300, n_hypersteps=25]: prior precision: [0.9205297  0.39314666 0.59771633 1.0356742 ], sigma noise: [0.40340364 0.37304702 0.44629353 0.19245307]
[Epoch=300, n_hypersteps=26]: prior precision: [0.9292461  0.40120313 0.59974444 1.035374  ], sigma noise: [0.40277764 0.3719628  0.44536757 0.19218113]
[Epoch=300, n_hypersteps=27]: prior precision: [0.9384809 0.4094737 0.6019054 1.03734  ], sigma noise: [0.4026302  0.37127197 0.44493026 0.19196719]
[Epoch=300, n_hypersteps=28]: prior precision: [0.94734013 0.41771647 0.60410935 1.0412941 ], sigma noise: [0.4029506  0.370964   0.44498283 0.19181047]
[Epoch=300, n_hypersteps=29]: prior precision: [0.9549709  0.42568687 0.606259   1.0468223 ], sigma noise: [0.40368864 0.37099984 0.4454785  0.19170587]
[Epoch=400, n_hypersteps=0]: prior precision: [0.9606449 0.4331475 0.608258  1.05347  ], sigma noise: [0.404762   0.37131792 0.44633037 0.19164447]
[Epoch=400, n_hypersteps=1]: prior precision: [0.9590002 0.440279  0.6109441 1.094666 ], sigma noise: [0.40808785 0.37361547 0.45027515 0.1920713 ]
[Epoch=400, n_hypersteps=2]: prior precision: [0.9506688  0.44682145 0.61407954 1.1639538 ], sigma noise: [0.41317004 0.37749383 0.4566933  0.1929026 ]
[Epoch=400, n_hypersteps=3]: prior precision: [0.936824   0.45252246 0.61738205 1.2559469 ], sigma noise: [0.41937143 0.38246286 0.4648068  0.1940414 ]
[Epoch=400, n_hypersteps=4]: prior precision: [0.9189989 0.4571596 0.6205512 1.3642528], sigma noise: [0.42597714 0.38798746 0.4737382  0.19538708]
[Epoch=400, n_hypersteps=5]: prior precision: [0.89888865 0.46055678 0.6232996  1.4796332 ], sigma noise: [0.43226647 0.39353663 0.48258182 0.19684511]
[Epoch=400, n_hypersteps=6]: prior precision: [0.87818253 0.46260265 0.62538147 1.5891066 ], sigma noise: [0.43758756 0.39862984 0.49048638 0.19833376]
[Epoch=400, n_hypersteps=7]: prior precision: [0.858428   0.46325952 0.62661904 1.6774799 ], sigma noise: [0.4414252  0.40287673 0.4967417  0.19978824]
[Epoch=400, n_hypersteps=8]: prior precision: [0.840936   0.46256748 0.62691903 1.7318583 ], sigma noise: [0.44345096 0.40600654 0.5008523  0.20116265]
[Epoch=400, n_hypersteps=9]: prior precision: [0.82674193 0.46063992 0.62627923 1.7461925 ], sigma noise: [0.4435469  0.4078837  0.50258297 0.20243075]
[Epoch=400, n_hypersteps=10]: prior precision: [0.8165841 0.4576516 0.6247853 1.7226695], sigma noise: [0.4417995  0.40850836 0.5019688  0.20358396]
[Epoch=400, n_hypersteps=11]: prior precision: [0.8109116  0.45382243 0.6225987  1.6696451 ], sigma noise: [0.4384691  0.4080036  0.49928632 0.20463046]
[Epoch=400, n_hypersteps=12]: prior precision: [0.80989623 0.44939843 0.6199347  1.5981102 ], sigma noise: [0.43394175 0.40659153 0.4949974  0.20559242]
[Epoch=400, n_hypersteps=13]: prior precision: [0.8134473  0.44463494 0.6170401  1.5190264 ], sigma noise: [0.4286753  0.40456447 0.4896772  0.20650332]
[Epoch=400, n_hypersteps=14]: prior precision: [0.82122266 0.4397785  0.6141659  1.4417119 ], sigma noise: [0.42314446 0.40224943 0.48393986 0.20740417]
[Epoch=400, n_hypersteps=15]: prior precision: [0.8326335  0.43505192 0.6115454  1.3731797 ], sigma noise: [0.41779345 0.399974   0.47837156 0.20833962]
[Epoch=400, n_hypersteps=16]: prior precision: [0.84685504 0.4306471  0.6093734  1.3179936 ], sigma noise: [0.41299808 0.39803421 0.47347614 0.20935303]
[Epoch=400, n_hypersteps=17]: prior precision: [0.8628436  0.42671528 0.6077939  1.2785351 ], sigma noise: [0.40903962 0.39666763 0.46963775 0.21048196]
[Epoch=400, n_hypersteps=18]: prior precision: [0.87938774 0.42336583 0.6068932  1.2554363 ], sigma noise: [0.40609097 0.39603382 0.46709913 0.21175264]
[Epoch=400, n_hypersteps=19]: prior precision: [0.89517456 0.42066422 0.60669565 1.2480493 ], sigma noise: [0.4042134 0.3962042 0.4659559 0.213177 ]
[Epoch=400, n_hypersteps=20]: prior precision: [0.9089112 0.4186385 0.6071667 1.2548234], sigma noise: [0.40336433 0.39716038 0.46616375 0.21475045]
[Epoch=400, n_hypersteps=21]: prior precision: [0.91946524 0.41727957 0.60822123 1.2735848 ], sigma noise: [0.40341297 0.39880264 0.46755594 0.21645316]
[Epoch=400, n_hypersteps=22]: prior precision: [0.9260138  0.41655067 0.6097324  1.3015901 ], sigma noise: [0.40416172 0.40096515 0.46986806 0.21825212]
[Epoch=400, n_hypersteps=23]: prior precision: [0.9281609  0.41639003 0.6115467  1.3356061 ], sigma noise: [0.4053718  0.403437   0.47277    0.22010493]
[Epoch=400, n_hypersteps=24]: prior precision: [0.92598367 0.41671893 0.6134965  1.3718903 ], sigma noise: [0.40679005 0.40598598 0.47590095 0.22196434]
[Epoch=400, n_hypersteps=25]: prior precision: [0.9200135  0.41744792 0.615417   1.4064728 ], sigma noise: [0.40817553 0.40838477 0.47890592 0.2237837 ]
[Epoch=400, n_hypersteps=26]: prior precision: [0.91113526 0.41848367 0.61716044 1.4355446 ], sigma noise: [0.4093216  0.41043302 0.48147067 0.22552125]
[Epoch=400, n_hypersteps=27]: prior precision: [0.900461   0.41973585 0.6186081  1.4560115 ], sigma noise: [0.41007406 0.4119763  0.48335183 0.22714356]
[Epoch=400, n_hypersteps=28]: prior precision: [0.889175   0.42111835 0.6196773  1.4658597 ], sigma noise: [0.41034144 0.41291863 0.48439646 0.22862749]
[Epoch=400, n_hypersteps=29]: prior precision: [0.8784086  0.42255664 0.6203288  1.4645461 ], sigma noise: [0.41009846 0.41322812 0.48455313 0.22996262]
MARGLIK: finished training. Recover best model and fit Laplace.
Configuration: 
 Config(experiment_name='LANAM-Grid-2', data_path='LANAM/data/datasets', likelihood='regression', prior_sigma_noise=0.7, num_epochs=400, batch_size=128, wandb=False, log_loss_frequency=100, lr=0.001, lr_hyp=0.1, n_epochs_burnin=50, n_hypersteps=30, marglik_frequency=100, hidden_sizes=[1024], activation=True, activation_cls='relu')
Model summary: 
 LaNAM(
  (lossfunc): MSELoss()
  (_feature_nns): ModuleList(
    (0-3): 4 x FeatureNN(
      (model): Sequential(
        (0): Linear(in_features=1, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=1, bias=True)
      )
    )
  )
)
[Epoch=100, n_hypersteps=0]: prior precision: [1. 1. 1. 1.], sigma noise: [1. 1. 1. 1.]
[Epoch=100, n_hypersteps=1]: prior precision: [0.9048374 0.9048374 0.9048374 0.9048374], sigma noise: [0.9048374 0.9048374 0.9048374 0.9048374]
[Epoch=100, n_hypersteps=2]: prior precision: [0.8191529  0.8191445  0.81915057 0.8191023 ], sigma noise: [0.81884116 0.8188458  0.81885326 0.8188222 ]
[Epoch=100, n_hypersteps=3]: prior precision: [0.74224216 0.7422117  0.7422353  0.74206054], sigma noise: [0.74122447 0.74124146 0.7412697  0.74115497]
[Epoch=100, n_hypersteps=4]: prior precision: [0.67341685 0.67334545 0.6734042  0.6729977 ], sigma noise: [0.6712907 0.6713308 0.6714    0.6711253]
[Epoch=100, n_hypersteps=5]: prior precision: [0.61201304 0.611876   0.61199343 0.6112264 ], sigma noise: [0.60843146 0.6085092  0.60864776 0.608109  ]
[Epoch=100, n_hypersteps=6]: prior precision: [0.5573967  0.5571623  0.55736834 0.55609334], sigma noise: [0.55212927 0.5522634  0.5525103  0.5515674 ]
[Epoch=100, n_hypersteps=7]: prior precision: [0.50896853 0.50859755 0.5089274  0.5069849 ], sigma noise: [0.50196415 0.5021762  0.50258577 0.5010516 ]
[Epoch=100, n_hypersteps=8]: prior precision: [0.4661677  0.46561086 0.46610436 0.46332797], sigma noise: [0.45762166 0.45794022 0.45858538 0.45620388]
[Epoch=100, n_hypersteps=9]: prior precision: [0.42847311 0.42767042 0.42836678 0.42459467], sigma noise: [0.41890535 0.41936466 0.42034683 0.41677186]
[Epoch=100, n_hypersteps=10]: prior precision: [0.39540258 0.39428228 0.39522156 0.39029855], sigma noise: [0.38574588 0.38639188 0.38784623 0.38260537]
[Epoch=100, n_hypersteps=11]: prior precision: [0.36651188 0.36498883 0.36620882 0.35999656], sigma noise: [0.35819137 0.35908097 0.36118555 0.35365254]
[Epoch=100, n_hypersteps=12]: prior precision: [0.341387   0.33936718 0.34090316 0.3332859 ], sigma noise: [0.33635142 0.33755645 0.34053785 0.32990512]
[Epoch=100, n_hypersteps=13]: prior precision: [0.3196446  0.3170306  0.31890756 0.30979976], sigma noise: [0.3202698  0.32187703 0.32599416 0.3113113 ]
[Epoch=100, n_hypersteps=14]: prior precision: [0.30092776 0.29762003 0.29985532 0.2891958 ], sigma noise: [0.3098066  0.31191412 0.31743118 0.2976721 ]
[Epoch=100, n_hypersteps=15]: prior precision: [0.2849041  0.28080565 0.28341174 0.27116603], sigma noise: [0.30456594 0.30727047 0.314452   0.2885787 ]
[Epoch=100, n_hypersteps=16]: prior precision: [0.2712635  0.26628634 0.26926297 0.25542614], sigma noise: [0.30396748 0.30736387 0.316477   0.28345698]
[Epoch=100, n_hypersteps=17]: prior precision: [0.2597247  0.25378633 0.25713193 0.24171771], sigma noise: [0.3073728  0.31155282 0.3228716  0.28166103]
[Epoch=100, n_hypersteps=18]: prior precision: [0.25002936 0.24305916 0.2467682  0.22980677], sigma noise: [0.31414908 0.31921726 0.33302924 0.282545  ]
[Epoch=100, n_hypersteps=19]: prior precision: [0.24194157 0.23388311 0.23794706 0.21948019], sigma noise: [0.32370362 0.32976744 0.34638733 0.2854928 ]
[Epoch=100, n_hypersteps=20]: prior precision: [0.23525536 0.2260638  0.2304685  0.21054581], sigma noise: [0.33547458 0.3426466  0.36239776 0.2899577 ]
[Epoch=100, n_hypersteps=21]: prior precision: [0.22979373 0.21942829 0.2241577  0.20283878], sigma noise: [0.3488883 0.3572736 0.3804702 0.2954388]
[Epoch=100, n_hypersteps=22]: prior precision: [0.22539468 0.21382496 0.21886252 0.19621597], sigma noise: [0.36334342 0.3730295  0.39993492 0.30147773]
[Epoch=100, n_hypersteps=23]: prior precision: [0.22191955 0.20912445 0.2144502  0.19054964], sigma noise: [0.37821472 0.38925368 0.42002973 0.30767444]
[Epoch=100, n_hypersteps=24]: prior precision: [0.21924582 0.20521362 0.21080509 0.1857216 ], sigma noise: [0.3928662  0.40526003 0.43989927 0.3136871 ]
[Epoch=100, n_hypersteps=25]: prior precision: [0.21726663 0.20199367 0.2078268  0.18164174], sigma noise: [0.40666443 0.42035404 0.4586396  0.31923258]
[Epoch=100, n_hypersteps=26]: prior precision: [0.21589331 0.19938    0.20543218 0.1782271 ], sigma noise: [0.41904104 0.43389702 0.47536927 0.32409745]
[Epoch=100, n_hypersteps=27]: prior precision: [0.21504563 0.19730142 0.20354694 0.1754073 ], sigma noise: [0.4295109  0.44534034 0.4893155  0.32812694]
[Epoch=100, n_hypersteps=28]: prior precision: [0.21465926 0.1956977  0.20211008 0.17312177], sigma noise: [0.43771666 0.4542743  0.4998872  0.33122912]
[Epoch=100, n_hypersteps=29]: prior precision: [0.21467702 0.19452022 0.20107313 0.1713208 ], sigma noise: [0.44344267 0.4604431  0.5067334  0.33336675]
[Epoch=200, n_hypersteps=0]: prior precision: [0.21505496 0.19372772 0.20039745 0.1699567 ], sigma noise: [0.44660884 0.46376115 0.50976175 0.33454192]
[Epoch=200, n_hypersteps=1]: prior precision: [0.21529028 0.19307214 0.19976893 0.16923153], sigma noise: [0.44644582 0.46373564 0.50819206 0.33485705]
[Epoch=200, n_hypersteps=2]: prior precision: [0.21539402 0.1925456  0.19918908 0.16909036], sigma noise: [0.44326544 0.46067193 0.50255525 0.33438176]
[Epoch=200, n_hypersteps=3]: prior precision: [0.21537825 0.1921432  0.19866492 0.16948737], sigma noise: [0.43750048 0.4550081  0.49355596 0.33320853]
[Epoch=200, n_hypersteps=4]: prior precision: [0.21525964 0.19186477 0.19820489 0.17038064], sigma noise: [0.4296561  0.44725692 0.48199174 0.33143854]
[Epoch=200, n_hypersteps=5]: prior precision: [0.21505994 0.19171289 0.1978215  0.17174058], sigma noise: [0.4202782  0.43798923 0.46867892 0.32920668]
[Epoch=200, n_hypersteps=6]: prior precision: [0.21479979 0.19168891 0.1975255  0.17353573], sigma noise: [0.40991932 0.42778072 0.45440686 0.32666457]
[Epoch=200, n_hypersteps=7]: prior precision: [0.21450174 0.19179772 0.19733208 0.17573689], sigma noise: [0.39911264 0.41719022 0.4398945  0.3239738 ]
[Epoch=200, n_hypersteps=8]: prior precision: [0.21418731 0.1920455  0.19725339 0.17832366], sigma noise: [0.38834524 0.4067409  0.42577672 0.32131362]
[Epoch=200, n_hypersteps=9]: prior precision: [0.21387881 0.192432   0.19730167 0.18126808], sigma noise: [0.37804732 0.39689675 0.4125824  0.31886175]
[Epoch=200, n_hypersteps=10]: prior precision: [0.21359521 0.19295703 0.19748491 0.18454131], sigma noise: [0.3685821  0.3880594  0.4007309  0.31681523]
[Epoch=200, n_hypersteps=11]: prior precision: [0.2133551  0.19362147 0.19781072 0.18812332], sigma noise: [0.36023143 0.38053977 0.39054313 0.31535646]
[Epoch=200, n_hypersteps=12]: prior precision: [0.2131745  0.19442663 0.19828118 0.19198266], sigma noise: [0.35321304 0.37457722 0.38222754 0.31464237]
[Epoch=200, n_hypersteps=13]: prior precision: [0.21305832 0.19536313 0.19889781 0.19608568], sigma noise: [0.34764743 0.3703241  0.37589628 0.3147958 ]
[Epoch=200, n_hypersteps=14]: prior precision: [0.21301238 0.19642282 0.19965623 0.20040108], sigma noise: [0.34358    0.36783454 0.37156472 0.3158811 ]
[Epoch=200, n_hypersteps=15]: prior precision: [0.21304007 0.1975958  0.20054904 0.20488569], sigma noise: [0.34097293 0.36709    0.36917588 0.31792662]
[Epoch=200, n_hypersteps=16]: prior precision: [0.21314162 0.19886597 0.20156251 0.20949471], sigma noise: [0.33973703 0.36800086 0.3686006  0.32089853]
[Epoch=200, n_hypersteps=17]: prior precision: [0.21331522 0.20021385 0.20268618 0.21417625], sigma noise: [0.33972257 0.3704043  0.36964825 0.32470748]
[Epoch=200, n_hypersteps=18]: prior precision: [0.2135509  0.20161864 0.20389739 0.21887952], sigma noise: [0.3407332  0.37407959 0.37208247 0.32921448]
[Epoch=200, n_hypersteps=19]: prior precision: [0.21384415 0.20306034 0.20517784 0.22354734], sigma noise: [0.342551   0.3787582  0.37562406 0.33422437]
[Epoch=200, n_hypersteps=20]: prior precision: [0.21418045 0.20451353 0.20650503 0.22812283], sigma noise: [0.34494776 0.38413727 0.37998152 0.3395149 ]
[Epoch=200, n_hypersteps=21]: prior precision: [0.21454854 0.205955   0.207857   0.23254399], sigma noise: [0.34768504 0.38989538 0.38484946 0.34485233]
[Epoch=200, n_hypersteps=22]: prior precision: [0.21493614 0.2073631  0.20920855 0.23675354], sigma noise: [0.35053515 0.39569372 0.389918   0.34999356]
[Epoch=200, n_hypersteps=23]: prior precision: [0.21533203 0.2087117  0.21053895 0.24070217], sigma noise: [0.3532878  0.40121293 0.39489877 0.35470104]
[Epoch=200, n_hypersteps=24]: prior precision: [0.21572499 0.209983   0.21182558 0.24434052], sigma noise: [0.35576132 0.4061694  0.3995286  0.3587601 ]
[Epoch=200, n_hypersteps=25]: prior precision: [0.21611015 0.21115941 0.21305312 0.24763213], sigma noise: [0.35780826 0.410326   0.40358794 0.36200225]
[Epoch=200, n_hypersteps=26]: prior precision: [0.21647832 0.21222721 0.21420707 0.25054383], sigma noise: [0.3593292  0.413498   0.40690574 0.364309  ]
[Epoch=200, n_hypersteps=27]: prior precision: [0.21682027 0.21317977 0.21527244 0.25305364], sigma noise: [0.360264   0.41557786 0.4093691  0.36561063]
[Epoch=200, n_hypersteps=28]: prior precision: [0.21713492 0.21401021 0.21624573 0.2551584 ], sigma noise: [0.3605986  0.41652948 0.41091725 0.36590874]
[Epoch=200, n_hypersteps=29]: prior precision: [0.21742293 0.21471724 0.21711686 0.256857  ], sigma noise: [0.3603521  0.4163854  0.4115656  0.36525425]
[Epoch=300, n_hypersteps=0]: prior precision: [0.21768217 0.21530484 0.21788234 0.25815815], sigma noise: [0.35958207 0.41524613 0.41137424 0.36373433]
[Epoch=300, n_hypersteps=1]: prior precision: [0.21791142 0.21560363 0.21840724 0.25963676], sigma noise: [0.35822523 0.41286838 0.4101226  0.36164844]
[Epoch=300, n_hypersteps=2]: prior precision: [0.21811312 0.2156368  0.21871158 0.26127028], sigma noise: [0.35640705 0.40950254 0.40800476 0.35913607]
[Epoch=300, n_hypersteps=3]: prior precision: [0.21829167 0.21543309 0.21881352 0.26304388], sigma noise: [0.35427067 0.4054352  0.40524647 0.3563686 ]
[Epoch=300, n_hypersteps=4]: prior precision: [0.21845067 0.2150225  0.21873379 0.26493979], sigma noise: [0.35197216 0.40094665 0.40209332 0.35351774]
[Epoch=300, n_hypersteps=5]: prior precision: [0.21860106 0.21443793 0.21849161 0.26694205], sigma noise: [0.34966567 0.3963212  0.39878994 0.35074615]
[Epoch=300, n_hypersteps=6]: prior precision: [0.21874245 0.21371113 0.21810865 0.2690361 ], sigma noise: [0.34749523 0.3918157  0.3955608  0.34820735]
[Epoch=300, n_hypersteps=7]: prior precision: [0.21888243 0.21287447 0.21760775 0.27120313], sigma noise: [0.34559512 0.38765198 0.3926103  0.34603336]
[Epoch=300, n_hypersteps=8]: prior precision: [0.2190212  0.2119582  0.21701044 0.27342042], sigma noise: [0.34407428 0.38400814 0.39010227 0.34433076]
[Epoch=300, n_hypersteps=9]: prior precision: [0.21916114 0.21098484 0.21633491 0.2756698 ], sigma noise: [0.34301054 0.38100934 0.3881469  0.34317654]
[Epoch=300, n_hypersteps=10]: prior precision: [0.21930431 0.209979   0.21560015 0.27792686], sigma noise: [0.34244725 0.37873015 0.38683155 0.3426116 ]
[Epoch=300, n_hypersteps=11]: prior precision: [0.21945193 0.2089592  0.21482149 0.28016654], sigma noise: [0.3424045  0.3772009  0.3861831  0.34264433]
[Epoch=300, n_hypersteps=12]: prior precision: [0.21960296 0.20794396 0.21401577 0.28236523], sigma noise: [0.3428613  0.37640372 0.3861829  0.34324786]
[Epoch=300, n_hypersteps=13]: prior precision: [0.21975568 0.2069435  0.21319294 0.2844904 ], sigma noise: [0.34377024 0.3762671  0.38677275 0.3443701 ]
[Epoch=300, n_hypersteps=14]: prior precision: [0.21990228 0.20596929 0.21236067 0.28651658], sigma noise: [0.34505734 0.37670875 0.38785684 0.34592158]
[Epoch=300, n_hypersteps=15]: prior precision: [0.22003847 0.2050316  0.21152742 0.28841597], sigma noise: [0.34663004 0.37760618 0.38932586 0.3477953 ]
[Epoch=300, n_hypersteps=16]: prior precision: [0.22016114 0.20413332 0.21069972 0.29015988], sigma noise: [0.34838954 0.37882292 0.39104286 0.3498647 ]
[Epoch=300, n_hypersteps=17]: prior precision: [0.22027205 0.20327476 0.2098822  0.29172298], sigma noise: [0.35022348 0.38022506 0.39286503 0.3520094 ]
[Epoch=300, n_hypersteps=18]: prior precision: [0.22035371 0.20245972 0.20907898 0.29308632], sigma noise: [0.35202953 0.3816741  0.3946518  0.35410324]
[Epoch=300, n_hypersteps=19]: prior precision: [0.22040835 0.20168997 0.20829207 0.2942296 ], sigma noise: [0.35371092 0.38304946 0.39627948 0.35603482]
[Epoch=300, n_hypersteps=20]: prior precision: [0.22043517 0.20096529 0.20752706 0.2951509 ], sigma noise: [0.35517487 0.38424674 0.39764416 0.35770586]
[Epoch=300, n_hypersteps=21]: prior precision: [0.22042866 0.20029187 0.20678611 0.29584205], sigma noise: [0.3563601  0.3851844  0.3986634  0.35904914]
[Epoch=300, n_hypersteps=22]: prior precision: [0.22038952 0.19966675 0.20607294 0.29630956], sigma noise: [0.35722303 0.38580352 0.3992865  0.36001402]
[Epoch=300, n_hypersteps=23]: prior precision: [0.22031875 0.19909213 0.20539273 0.29656044], sigma noise: [0.35775095 0.38608068 0.39949524 0.3605817 ]
[Epoch=300, n_hypersteps=24]: prior precision: [0.2202149  0.1985661  0.20475006 0.29660112], sigma noise: [0.3579462  0.38602692 0.3992984  0.3607555 ]
[Epoch=300, n_hypersteps=25]: prior precision: [0.22008662 0.19809406 0.20414834 0.2964507 ], sigma noise: [0.35782954 0.38567173 0.39874437 0.36055875]
[Epoch=300, n_hypersteps=26]: prior precision: [0.2199345  0.1976771  0.20358793 0.29612932], sigma noise: [0.35744703 0.38506398 0.39788797 0.36005095]
[Epoch=300, n_hypersteps=27]: prior precision: [0.21976551 0.19731943 0.20307891 0.29565874], sigma noise: [0.35686132 0.38427353 0.39680493 0.3593026 ]
[Epoch=300, n_hypersteps=28]: prior precision: [0.2195802  0.19701691 0.2026232  0.29507017], sigma noise: [0.35613042 0.3833826  0.39558688 0.35838926]
[Epoch=300, n_hypersteps=29]: prior precision: [0.21939085 0.19676983 0.20222367 0.29438347], sigma noise: [0.35531855 0.3824608  0.3943302  0.3573861 ]
[Epoch=400, n_hypersteps=0]: prior precision: [0.21919814 0.19658089 0.20187977 0.2936278 ], sigma noise: [0.35449782 0.38158408 0.39310822 0.35636222]
[Epoch=400, n_hypersteps=1]: prior precision: [0.21966742 0.19626416 0.20195876 0.2928393 ], sigma noise: [0.35399175 0.3803444  0.39215606 0.35505998]
[Epoch=400, n_hypersteps=2]: prior precision: [0.22074103 0.19583917 0.20241985 0.29203516], sigma noise: [0.35382053 0.37885508 0.391518   0.35358137]
[Epoch=400, n_hypersteps=3]: prior precision: [0.22235309 0.19532354 0.20322968 0.2912352 ], sigma noise: [0.35400102 0.37722456 0.39123005 0.3520057 ]
[Epoch=400, n_hypersteps=4]: prior precision: [0.22445114 0.19473411 0.20435297 0.29045942], sigma noise: [0.3545332  0.37553033 0.39132383 0.35041407]
[Epoch=400, n_hypersteps=5]: prior precision: [0.22697392 0.19409397 0.2057544  0.28972262], sigma noise: [0.355406   0.3738478  0.39180052 0.3488697 ]
[Epoch=400, n_hypersteps=6]: prior precision: [0.22986028 0.19342    0.2073958  0.28904104], sigma noise: [0.35660008 0.37222692 0.39265066 0.34741265]
[Epoch=400, n_hypersteps=7]: prior precision: [0.23305234 0.19272088 0.20924371 0.28842437], sigma noise: [0.35808903 0.37070587 0.39383674 0.3460639 ]
[Epoch=400, n_hypersteps=8]: prior precision: [0.23648544 0.19201383 0.21125738 0.28788096], sigma noise: [0.35981822 0.36929324 0.3953173  0.3448353 ]
[Epoch=400, n_hypersteps=9]: prior precision: [0.24009351 0.19130829 0.21340212 0.28741607], sigma noise: [0.3617262  0.3679926  0.3970224  0.34372047]
[Epoch=400, n_hypersteps=10]: prior precision: [0.24381803 0.1906197  0.21564189 0.28703323], sigma noise: [0.36375344 0.36678815 0.39888704 0.34270275]
[Epoch=400, n_hypersteps=11]: prior precision: [0.24758936 0.18995707 0.21794224 0.2867404 ], sigma noise: [0.3658233  0.36566362 0.40083438 0.34176296]
[Epoch=400, n_hypersteps=12]: prior precision: [0.25134864 0.189328   0.22026365 0.28652567], sigma noise: [0.36786103 0.36460045 0.40277845 0.34088287]
[Epoch=400, n_hypersteps=13]: prior precision: [0.25503686 0.18873736 0.22257623 0.28639978], sigma noise: [0.36979836 0.36357442 0.4046448  0.3400337 ]
[Epoch=400, n_hypersteps=14]: prior precision: [0.2585925  0.18819454 0.22484894 0.28635833], sigma noise: [0.37157327 0.3625614  0.40636602 0.3391989 ]
[Epoch=400, n_hypersteps=15]: prior precision: [0.26196292 0.18769898 0.22704767 0.28639686], sigma noise: [0.37313846 0.36154556 0.40787882 0.33836508]
[Epoch=400, n_hypersteps=16]: prior precision: [0.26510757 0.18725434 0.22914943 0.28651232], sigma noise: [0.37445694 0.36053357 0.40913814 0.33752364]
[Epoch=400, n_hypersteps=17]: prior precision: [0.26798552 0.18686497 0.2311294  0.28670073], sigma noise: [0.37550405 0.35952425 0.41012385 0.33667982]
[Epoch=400, n_hypersteps=18]: prior precision: [0.27056584 0.1865384  0.2329679  0.2869565 ], sigma noise: [0.37627822 0.35853165 0.41083145 0.33583257]
[Epoch=400, n_hypersteps=19]: prior precision: [0.2728182  0.18626906 0.23464523 0.28727183], sigma noise: [0.3767814  0.3575701  0.4112711  0.33500078]
[Epoch=400, n_hypersteps=20]: prior precision: [0.27473193 0.18605848 0.23615196 0.2876441 ], sigma noise: [0.37704018 0.35665897 0.4114642  0.33419868]
[Epoch=400, n_hypersteps=21]: prior precision: [0.276301   0.185902   0.23748149 0.28806698], sigma noise: [0.37708437 0.35582793 0.41144347 0.33345583]
[Epoch=400, n_hypersteps=22]: prior precision: [0.27752796 0.18580121 0.23862843 0.2885406 ], sigma noise: [0.37695804 0.35509688 0.411258   0.33278498]
[Epoch=400, n_hypersteps=23]: prior precision: [0.27841908 0.18575487 0.23959155 0.2890532 ], sigma noise: [0.3767     0.35448802 0.41096014 0.3322152 ]
[Epoch=400, n_hypersteps=24]: prior precision: [0.2789879  0.1857588  0.24037012 0.2895979 ], sigma noise: [0.3763529  0.35401747 0.4106036  0.33175674]
[Epoch=400, n_hypersteps=25]: prior precision: [0.27925456 0.18580788 0.24097143 0.29016075], sigma noise: [0.37595573 0.35370362 0.41022795 0.3314314 ]
[Epoch=400, n_hypersteps=26]: prior precision: [0.27924573 0.1859071  0.24140504 0.29072672], sigma noise: [0.3755447  0.35355502 0.40986896 0.3312436 ]
[Epoch=400, n_hypersteps=27]: prior precision: [0.27898964 0.1860445  0.24167928 0.2912995 ], sigma noise: [0.3751501  0.35357395 0.40955102 0.331199  ]
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.210 MB of 0.210 MB uploaded (0.000 MB deduped)wandb: \ 0.210 MB of 0.299 MB uploaded (0.000 MB deduped)wandb: | 0.299 MB of 0.299 MB uploaded (0.000 MB deduped)wandb: / 0.299 MB of 0.299 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                          Loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       Metrics ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  Negative_marginal_likelihood ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: Predictive_posterior_std_mean ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:                   Sigma_noise ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:                          Loss 0.48764
wandb:                       Metrics 0.46943
wandb:  Negative_marginal_likelihood 1376.94873
wandb: Predictive_posterior_std_mean 0.75438
wandb:                   Sigma_noise 0.7368
wandb: 
wandb: üöÄ View run visionary-sweep-6 at: https://wandb.ai/xinyu-zhang/LANAM-grid-basic-synthetic-3.0/runs/l5uyrv4u
wandb: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230815_172355-l5uyrv4u/logs
[Epoch=400, n_hypersteps=28]: prior precision: [0.2785123  0.18621573 0.24180801 0.2918642 ], sigma noise: [0.37478817 0.3537538  0.4092976  0.3312953 ]
[Epoch=400, n_hypersteps=29]: prior precision: [0.27784854 0.18640961 0.24179836 0.2924123 ], sigma noise: [0.37446898 0.35408556 0.4091067  0.33152148]
MARGLIK: finished training. Recover best model and fit Laplace.
